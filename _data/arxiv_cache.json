{
  "last_fetch_timestamp": 1771985055,
  "papers": [
    {
      "arxiv_id": "2602.20503",
      "title": "Error-Controlled Borrowing from External Data Using Wasserstein Ambiguity Sets",
      "authors": [
        "Yui Kimura",
        "Shu Tamano"
      ],
      "abstract": "Incorporating external data can improve the efficiency of clinical trials, but distributional mismatches between current and external populations threaten the validity of inference. While numerous dynamic borrowing methods exist, the calibration of their borrowing parameters relies mainly on ad hoc, simulation-based tuning. To overcome this, we propose BOND (Borrowing under Optimal Nonparametric Distributional robustness), a framework that formalizes data noncommensurability through Wasserstein ambiguity sets centered at the current-trial distribution. By deriving sharp, closed-form bounds on the worst-case mean drift for both continuous and binary outcomes, we construct a distributionally robust, bias-corrected Wald statistic that ensures asymptotic type I error control uniformly over the ambiguity set. Importantly, BOND determines the optimal borrowing strength by maximizing a worst-case power proxy, converting heuristic parameter tuning into a transparent, analytically tractable optimization problem. Furthermore, we demonstrate that many prominent borrowing methods can be reparameterized via an effective borrowing weight, rendering our calibration framework broadly applicable. Simulation studies and a real-world clinical trial application confirm that BOND preserves the nominal size under unmeasured heterogeneity while achieving efficiency gains over standard borrowing methods.",
      "published": "February 24, 2026",
      "published_raw": "2026-02-24T03:04:43Z",
      "categories": [
        "stat.ME",
        "stat.AP"
      ],
      "pdf_link": "https://arxiv.org/pdf/2602.20503v1",
      "arxiv_url": "https://arxiv.org/abs/2602.20503v1",
      "added_timestamp": 1771985055
    },
    {
      "arxiv_id": "2602.20403",
      "title": "Wasserstein Distributionally Robust Online Learning",
      "authors": [
        "Guixian Chen",
        "Salar Fattahi",
        "Soroosh Shafiee"
      ],
      "abstract": "We study distributionally robust online learning, where a risk-averse learner updates decisions sequentially to guard against worst-case distributions drawn from a Wasserstein ambiguity set centered at past observations. While this paradigm is well understood in the offline setting through Wasserstein Distributionally Robust Optimization (DRO), its online extension poses significant challenges in both convergence and computation. In this paper, we address these challenges. First, we formulate the problem as an online saddle-point stochastic game between a decision maker and an adversary selecting worst-case distributions, and propose a general framework that converges to a robust Nash equilibrium coinciding with the solution of the corresponding offline Wasserstein DRO problem. Second, we address the main computational bottleneck, which is the repeated solution of worst-case expectation problems. For the important class of piecewise concave loss functions, we propose a tailored algorithm that exploits problem geometry to achieve substantial speedups over state-of-the-art solvers such as Gurobi. The key insight is a novel connection between the worst-case expectation problem, an inherently infinite-dimensional optimization problem, and a classical and tractable budget allocation problem, which is of independent interest.",
      "published": "February 23, 2026",
      "published_raw": "2026-02-23T22:55:07Z",
      "categories": [
        "cs.LG",
        "math.OC",
        "stat.ML"
      ],
      "pdf_link": "https://arxiv.org/pdf/2602.20403v1",
      "arxiv_url": "https://arxiv.org/abs/2602.20403v1",
      "added_timestamp": 1771985055
    },
    {
      "arxiv_id": "2602.17743",
      "title": "Provable Adversarial Robustness in In-Context Learning",
      "authors": [
        "Di Zhang"
      ],
      "abstract": "Large language models adapt to new tasks through in-context learning (ICL) without parameter updates. Current theoretical explanations for this capability assume test tasks are drawn from a distribution similar to that seen during pretraining. This assumption overlooks adversarial distribution shifts that threaten real-world reliability. To address this gap, we introduce a distributionally robust meta-learning framework that provides worst-case performance guarantees for ICL under Wasserstein-based distribution shifts. Focusing on linear self-attention Transformers, we derive a non-asymptotic bound linking adversarial perturbation strength ($\u03c1$), model capacity ($m$), and the number of in-context examples ($N$). The analysis reveals that model robustness scales with the square root of its capacity ($\u03c1_{\\text{max}} \\propto \\sqrt{m}$), while adversarial settings impose a sample complexity penalty proportional to the square of the perturbation magnitude ($N_\u03c1- N_0 \\propto \u03c1^2$). Experiments on synthetic tasks confirm these scaling laws. These findings advance the theoretical understanding of ICL's limits under adversarial conditions and suggest that model capacity serves as a fundamental resource for distributional robustness.",
      "published": "February 19, 2026",
      "published_raw": "2026-02-19T12:37:00Z",
      "categories": [
        "cs.LG",
        "stat.ML"
      ],
      "pdf_link": "https://arxiv.org/pdf/2602.17743v1",
      "arxiv_url": "https://arxiv.org/abs/2602.17743v1",
      "added_timestamp": 1771812315
    },
    {
      "arxiv_id": "2602.08470",
      "title": "Learning Credal Ensembles via Distributionally Robust Optimization",
      "authors": [
        "Kaizheng Wang",
        "Ghifari Adam Faza",
        "Fabio Cuzzolin",
        "Siu Lun Chau",
        "David Moens",
        "Hans Hallez"
      ],
      "abstract": "Credal predictors are models that are aware of epistemic uncertainty and produce a convex set of probabilistic predictions. They offer a principled way to quantify predictive epistemic uncertainty (EU) and have been shown to improve model robustness in various settings. However, most state-of-the-art methods mainly define EU as disagreement caused by random training initializations, which mostly reflects sensitivity to optimization randomness rather than uncertainty from deeper sources. To address this, we define EU as disagreement among models trained with varying relaxations of the i.i.d. assumption between training and test data. Based on this idea, we propose CreDRO, which learns an ensemble of plausible models through distributionally robust optimization. As a result, CreDRO captures EU not only from training randomness but also from meaningful disagreement due to potential distribution shifts between training and test data. Empirical results show that CreDRO consistently outperforms existing credal methods on tasks such as out-of-distribution detection across multiple benchmarks and selective classification in medical applications.",
      "published": "February 09, 2026",
      "published_raw": "2026-02-09T10:16:43Z",
      "categories": [
        "cs.LG",
        "stat.ML"
      ],
      "pdf_link": "https://arxiv.org/pdf/2602.08470v1",
      "arxiv_url": "https://arxiv.org/abs/2602.08470v1",
      "added_timestamp": 1770775964
    },
    {
      "arxiv_id": "2602.01825",
      "title": "Learning Sequential Decisions from Multiple Sources via Group-Robust Markov Decision Processes",
      "authors": [
        "Mingyuan Xu",
        "Zongqi Xia",
        "Tianxi Cai",
        "Doudou Zhou",
        "Nian Si"
      ],
      "abstract": "We often collect data from multiple sites (e.g., hospitals) that share common structure but also exhibit heterogeneity. This paper aims to learn robust sequential decision-making policies from such offline, multi-site datasets. To model cross-site uncertainty, we study distributionally robust MDPs with a group-linear structure: all sites share a common feature map, and both the transition kernels and expected reward functions are linear in these shared features. We introduce feature-wise (d-rectangular) uncertainty sets, which preserve tractable robust Bellman recursions while maintaining key cross-site structure. Building on this, we then develop an offline algorithm based on pessimistic value iteration that includes: (i) per-site ridge regression for Bellman targets, (ii) feature-wise worst-case (row-wise minimization) aggregation, and (iii) a data-dependent pessimism penalty computed from the diagonals of the inverse design matrices. We further propose a cluster-level extension that pools similar sites to improve sample efficiency, guided by prior knowledge of site similarity. Under a robust partial coverage assumption, we prove a suboptimality bound for the resulting policy. Overall, our framework addresses multi-site learning with heterogeneous data sources and provides a principled approach to robust planning without relying on strong state-action rectangularity assumptions.",
      "published": "February 02, 2026",
      "published_raw": "2026-02-02T08:58:55Z",
      "categories": [
        "stat.ME",
        "cs.LG",
        "math.OC",
        "stat.ML"
      ],
      "pdf_link": "https://arxiv.org/pdf/2602.01825v1",
      "arxiv_url": "https://arxiv.org/abs/2602.01825v1",
      "added_timestamp": 1770170317
    },
    {
      "arxiv_id": "2602.01427",
      "title": "Robust Generalization with Adaptive Optimal Transport Priors for Decision-Focused Learning",
      "authors": [
        "Haixiang Sun",
        "Andrew L. Liu"
      ],
      "abstract": "Few-shot learning requires models to generalize under limited supervision while remaining robust to distribution shifts. Existing Sinkhorn Distributionally Robust Optimization (DRO) methods provide theoretical guarantees but rely on a fixed reference distribution, which limits their adaptability. We propose a Prototype-Guided Distributionally Robust Optimization (PG-DRO) framework that learns class-adaptive priors from abundant base data via hierarchical optimal transport and embeds them into the Sinkhorn DRO formulation. This design enables few-shot information to be organically integrated into producing class-specific robust decisions that are both theoretically grounded and efficient, and further aligns the uncertainty set with transferable structural knowledge. Experiments show that PG-DRO achieves stronger robust generalization in few-shot scenarios, outperforming both standard learners and DRO baselines.",
      "published": "February 01, 2026",
      "published_raw": "2026-02-01T20:22:41Z",
      "categories": [
        "stat.ML",
        "cs.LG",
        "stat.AP"
      ],
      "pdf_link": "https://arxiv.org/pdf/2602.01427v1",
      "arxiv_url": "https://arxiv.org/abs/2602.01427v1",
      "added_timestamp": 1770170317
    },
    {
      "arxiv_id": "2602.00844",
      "title": "Multivariate Time Series Data Imputation via Distributionally Robust Regularization",
      "authors": [
        "Che-Yi Liao",
        "Zheng Dong",
        "Gian-Gabriel Garcia",
        "Kamran Paynabar"
      ],
      "abstract": "Multivariate time series (MTS) imputation is often compromised by mismatch between observed and true data distributions -- a bias exacerbated by non-stationarity and systematic missingness. Standard methods that minimize reconstruction error or encourage distributional alignment risk overfitting these biased observations. We propose the Distributionally Robust Regularized Imputer Objective (DRIO), which jointly minimizes reconstruction error and the divergence between the imputer and a worst-case distribution within a Wasserstein ambiguity set. We derive a tractable dual formulation that reduces infinite-dimensional optimization over measures to adversarial search over sample trajectories, and propose an adversarial learning algorithm compatible with flexible deep learning backbones. Comprehensive experiments on diverse real-world datasets show DRIO consistently improves imputation under both missing-completely-at-random and missing-not-at-random settings, reaching Pareto-optimal trade-offs between reconstruction accuracy and distributional alignment.",
      "published": "January 31, 2026",
      "published_raw": "2026-01-31T18:15:03Z",
      "categories": [
        "stat.ML",
        "cs.LG",
        "stat.AP"
      ],
      "pdf_link": "https://arxiv.org/pdf/2602.00844v1",
      "arxiv_url": "https://arxiv.org/abs/2602.00844v1",
      "added_timestamp": 1770084228
    },
    {
      "arxiv_id": "2601.21324",
      "title": "Bulk-Calibrated Credal Ambiguity Sets: Fast, Tractable Decision Making under Out-of-Sample Contamination",
      "authors": [
        "Mengqi Chen",
        "Thomas B. Berrett",
        "Theodoros Damoulas",
        "Michele Caprio"
      ],
      "abstract": "Distributionally robust optimisation (DRO) minimises the worst-case expected loss over an ambiguity set that can capture distributional shifts in out-of-sample environments. While Huber (linear-vacuous) contamination is a classical minimal-assumption model for an $\\varepsilon$-fraction of arbitrary perturbations, including it in an ambiguity set can make the worst-case risk infinite and the DRO objective vacuous unless one imposes strong boundedness or support assumptions. We address these challenges by introducing bulk-calibrated credal ambiguity sets: we learn a high-mass bulk set from data while considering contamination inside the bulk and bounding the remaining tail contribution separately. This leads to a closed-form, finite $\\mathrm{mean}+\\sup$ robust objective and tractable linear or second-order cone programs for common losses and bulk geometries. Through this framework, we highlight and exploit the equivalence between the imprecise probability (IP) notion of upper expectation and the worst-case risk, demonstrating how IP credal sets translate into DRO objectives with interpretable tolerance levels. Experiments on heavy-tailed inventory control, geographically shifted house-price regression, and demographically shifted text classification show competitive robustness-accuracy trade-offs and efficient optimisation times, using Bayesian, frequentist, or empirical reference distributions.",
      "published": "January 29, 2026",
      "published_raw": "2026-01-29T06:37:36Z",
      "categories": [
        "stat.ML",
        "cs.LG"
      ],
      "pdf_link": "https://arxiv.org/pdf/2601.21324v1",
      "arxiv_url": "https://arxiv.org/abs/2601.21324v1",
      "added_timestamp": 1769824413
    }
  ]
}