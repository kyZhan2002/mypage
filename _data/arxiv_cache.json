{
  "timestamp": 1739457266,
  "papers": [
    {
      "title": "Multifidelity Simulation-based Inference for Computationally Expensive\n  Simulators",
      "authors": [
        "Anastasia N. Krouglova",
        "Hayden R. Johnson",
        "Basile Confavreux",
        "Michael Deistler",
        "Pedro J. Gon\u00e7alves"
      ],
      "abstract": "Across many domains of science, stochastic models are an essential tool to\nunderstand the mechanisms underlying empirically observed data. Models can be\nof different levels of detail and accuracy, with models of high-fidelity (i.e.,\nhigh accuracy) to the phenomena under study being often preferable. However,\ninferring parameters of high-fidelity models via simulation-based inference is\nchallenging, especially when the simulator is computationally expensive. We\nintroduce MF-NPE, a multifidelity approach to neural posterior estimation that\nleverages inexpensive low-fidelity simulations to infer parameters of\nhigh-fidelity simulators within a limited simulation budget. MF-NPE performs\nneural posterior estimation with limited high-fidelity resources by virtue of\ntransfer learning, with the ability to prioritize individual observations using\nactive learning. On one statistical task with analytical ground-truth and two\nreal-world tasks, MF-NPE shows comparable performance to current approaches\nwhile requiring up to two orders of magnitude fewer high-fidelity simulations.\nOverall, MF-NPE opens new opportunities to perform efficient Bayesian inference\non computationally expensive simulators.",
      "published": "February 12, 2025",
      "categories": [
        "stat.ML",
        "cs.LG"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.08416v1",
      "arxiv_url": "http://arxiv.org/abs/2502.08416v1"
    },
    {
      "title": "Hi-End-MAE: Hierarchical encoder-driven masked autoencoders are stronger\n  vision learners for medical image segmentation",
      "authors": [
        "Fenghe Tang",
        "Qingsong Yao",
        "Wenxin Ma",
        "Chenxu Wu",
        "Zihang Jiang",
        "S. Kevin Zhou"
      ],
      "abstract": "Medical image segmentation remains a formidable challenge due to the label\nscarcity. Pre-training Vision Transformer (ViT) through masked image modeling\n(MIM) on large-scale unlabeled medical datasets presents a promising solution,\nproviding both computational efficiency and model generalization for various\ndownstream tasks. However, current ViT-based MIM pre-training frameworks\npredominantly emphasize local aggregation representations in output layers and\nfail to exploit the rich representations across different ViT layers that\nbetter capture fine-grained semantic information needed for more precise\nmedical downstream tasks. To fill the above gap, we hereby present Hierarchical\nEncoder-driven MAE (Hi-End-MAE), a simple yet effective ViT-based pre-training\nsolution, which centers on two key innovations: (1) Encoder-driven\nreconstruction, which encourages the encoder to learn more informative features\nto guide the reconstruction of masked patches; and (2) Hierarchical dense\ndecoding, which implements a hierarchical decoding structure to capture rich\nrepresentations across different layers. We pre-train Hi-End-MAE on a\nlarge-scale dataset of 10K CT scans and evaluated its performance across seven\npublic medical image segmentation benchmarks. Extensive experiments demonstrate\nthat Hi-End-MAE achieves superior transfer learning capabilities across various\ndownstream tasks, revealing the potential of ViT in medical imaging\napplications. The code is available at:\nhttps://github.com/FengheTan9/Hi-End-MAE",
      "published": "February 12, 2025",
      "categories": [
        "cs.CV"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.08347v1",
      "arxiv_url": "http://arxiv.org/abs/2502.08347v1"
    },
    {
      "title": "Knowledge-Guided Wasserstein Distributionally Robust Optimization",
      "authors": [
        "Zitao Wang",
        "Ziyuan Wang",
        "Molei Liu",
        "Nian Si"
      ],
      "abstract": "Transfer learning is a popular strategy to leverage external knowledge and\nimprove statistical efficiency, particularly with a limited target sample. We\npropose a novel knowledge-guided Wasserstein Distributionally Robust\nOptimization (KG-WDRO) framework that adaptively incorporates multiple sources\nof external knowledge to overcome the conservativeness of vanilla WDRO, which\noften results in overly pessimistic shrinkage toward zero. Our method\nconstructs smaller Wasserstein ambiguity sets by controlling the transportation\nalong directions informed by the source knowledge. This strategy can alleviate\nperturbations on the predictive projection of the covariates and protect\nagainst information loss. Theoretically, we establish the equivalence between\nour WDRO formulation and the knowledge-guided shrinkage estimation based on\ncollinear similarity, ensuring tractability and geometrizing the feasible set.\nThis also reveals a novel and general interpretation for recent shrinkage-based\ntransfer learning approaches from the perspective of distributional robustness.\nIn addition, our framework can adjust for scaling differences in the regression\nmodels between the source and target and accommodates general types of\nregularization such as lasso and ridge. Extensive simulations demonstrate the\nsuperior performance and adaptivity of KG-WDRO in enhancing small-sample\ntransfer learning.",
      "published": "February 12, 2025",
      "categories": [
        "cs.LG",
        "stat.ME",
        "stat.ML"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.08146v1",
      "arxiv_url": "http://arxiv.org/abs/2502.08146v1"
    },
    {
      "title": "Instance-dependent Early Stopping",
      "authors": [
        "Suqin Yuan",
        "Runqi Lin",
        "Lei Feng",
        "Bo Han",
        "Tongliang Liu"
      ],
      "abstract": "In machine learning practice, early stopping has been widely used to\nregularize models and can save computational costs by halting the training\nprocess when the model's performance on a validation set stops improving.\nHowever, conventional early stopping applies the same stopping criterion to all\ninstances without considering their individual learning statuses, which leads\nto redundant computations on instances that are already well-learned. To\nfurther improve the efficiency, we propose an Instance-dependent Early Stopping\n(IES) method that adapts the early stopping mechanism from the entire training\nset to the instance level, based on the core principle that once the model has\nmastered an instance, the training on it should stop. IES considers an instance\nas mastered if the second-order differences of its loss value remain within a\nsmall range around zero. This offers a more consistent measure of an instance's\nlearning status compared with directly using the loss value, and thus allows\nfor a unified threshold to determine when an instance can be excluded from\nfurther backpropagation. We show that excluding mastered instances from\nbackpropagation can increase the gradient norms, thereby accelerating the\ndecrease of the training loss and speeding up the training process. Extensive\nexperiments on benchmarks demonstrate that IES method can reduce\nbackpropagation instances by 10%-50% while maintaining or even slightly\nimproving the test accuracy and transfer learning performance of a model.",
      "published": "February 11, 2025",
      "categories": [
        "cs.LG"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.07547v1",
      "arxiv_url": "http://arxiv.org/abs/2502.07547v1"
    },
    {
      "title": "Music for All: Exploring Multicultural Representations in Music\n  Generation Models",
      "authors": [
        "Atharva Mehta",
        "Shivam Chauhan",
        "Amirbek Djanibekov",
        "Atharva Kulkarni",
        "Gus Xia",
        "Monojit Choudhury"
      ],
      "abstract": "The advent of Music-Language Models has greatly enhanced the automatic music\ngeneration capability of AI systems, but they are also limited in their\ncoverage of the musical genres and cultures of the world. We present a study of\nthe datasets and research papers for music generation and quantify the bias and\nunder-representation of genres. We find that only 5.7% of the total hours of\nexisting music datasets come from non-Western genres, which naturally leads to\ndisparate performance of the models across genres. We then investigate the\nefficacy of Parameter-Efficient Fine-Tuning (PEFT) techniques in mitigating\nthis bias. Our experiments with two popular models -- MusicGen and Mustango,\nfor two underrepresented non-Western music traditions -- Hindustani Classical\nand Turkish Makam music, highlight the promises as well as the non-triviality\nof cross-genre adaptation of music through small datasets, implying the need\nfor more equitable baseline music-language models that are designed for\ncross-cultural transfer learning.",
      "published": "February 11, 2025",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.MM"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.07328v2",
      "arxiv_url": "http://arxiv.org/abs/2502.07328v2"
    },
    {
      "title": "Long-term simulation of physical and mechanical behaviors using\n  curriculum-transfer-learning based physics-informed neural networks",
      "authors": [
        "Yuan Guo",
        "Zhuojia Fu",
        "Jian Min",
        "Shiyu Lin",
        "Xiaoting Liu",
        "Youssef F. Rashed",
        "Xiaoying Zhuang"
      ],
      "abstract": "This paper proposes a Curriculum-Transfer-Learning based physics-informed\nneural network (CTL-PINN) for long-term simulation of physical and mechanical\nbehaviors. The main innovation of CTL-PINN lies in decomposing long-term\nproblems into a sequence of short-term subproblems. Initially, the standard\nPINN is employed to solve the first sub-problem. As the simulation progresses,\nsubsequent time-domain problems are addressed using a curriculum learning\napproach that integrates information from previous steps. Furthermore, transfer\nlearning techniques are incorporated, allowing the model to effectively utilize\nprior training data and solve sequential time domain transfer problems.\nCTL-PINN combines the strengths of curriculum learning and transfer learning,\novercoming the limitations of standard PINNs, such as local optimization\nissues, and addressing the inaccuracies over extended time domains encountered\nin CL-PINN and the low computational efficiency of TL-PINN. The efficacy and\nrobustness of CTL-PINN are demonstrated through applications to nonlinear wave\npropagation, Kirchhoff plate dynamic response, and the hydrodynamic model of\nthe Three Gorges Reservoir Area, showcasing its superior capability in\naddressing long-term computational challenges.",
      "published": "February 11, 2025",
      "categories": [
        "cs.LG",
        "cs.NA",
        "math.NA"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.07325v1",
      "arxiv_url": "http://arxiv.org/abs/2502.07325v1"
    },
    {
      "title": "Robust Indoor Localization in Dynamic Environments: A Multi-source\n  Unsupervised Domain Adaptation Framework",
      "authors": [
        "Jiyu Jiao",
        "Xiaojun Wang",
        "Chengpei Han"
      ],
      "abstract": "Fingerprint localization has gained significant attention due to its\ncost-effective deployment, low complexity, and high efficacy. However,\ntraditional methods, while effective for static data, often struggle in dynamic\nenvironments where data distributions and feature spaces evolve-a common\noccurrence in real-world scenarios. To address the challenges of robustness and\nadaptability in fingerprint localization for dynamic indoor environments, this\npaper proposes DF-Loc, an end-to-end dynamic fingerprint localization system\nbased on multi-source unsupervised domain adaptation (MUDA). DF-Loc leverages\nhistorical data from multiple time scales to facilitate knowledge transfer in\nspecific feature spaces, thereby enhancing generalization capabilities in the\ntarget domain and reducing reliance on labeled data. Specifically, the system\nincorporates a Quality Control (QC) module for CSI data preprocessing and\nemploys image processing techniques for CSI fingerprint feature reconstruction.\nAdditionally, a multi-scale attention-based feature fusion backbone network is\ndesigned to extract multi-level transferable fingerprint features. Finally, a\ndual-stage alignment model aligns the distributions of multiple source-target\ndomain pairs, improving regression characteristics in the target domain.\nExtensive experiments conducted in office and classroom environments\ndemonstrate that DF-Loc outperforms comparative methods in terms of both\nlocalization accuracy and robustness. With 60% of reference points used for\ntraining, DF-Loc achieves average localization errors of 0.79m and 3.72m in\n\"same-test\" scenarios, and 0.94m and 4.39m in \"different-test\" scenarios,\nrespectively. This work pioneers an end-to-end multi-source transfer learning\napproach for fingerprint localization, providing valuable insights for future\nresearch in dynamic environments.",
      "published": "February 11, 2025",
      "categories": [
        "cs.CV",
        "physics.pop-ph"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.07246v1",
      "arxiv_url": "http://arxiv.org/abs/2502.07246v1"
    },
    {
      "title": "Tab2Visual: Overcoming Limited Data in Tabular Data Classification Using\n  Deep Learning with Visual Representations",
      "authors": [
        "Ahmed Mamdouh",
        "Moumen El-Melegy",
        "Samia Ali",
        "Ron Kikinis"
      ],
      "abstract": "This research addresses the challenge of limited data in tabular data\nclassification, particularly prevalent in domains with constraints like\nhealthcare. We propose Tab2Visual, a novel approach that transforms\nheterogeneous tabular data into visual representations, enabling the\napplication of powerful deep learning models. Tab2Visual effectively addresses\ndata scarcity by incorporating novel image augmentation techniques and\nfacilitating transfer learning. We extensively evaluate the proposed approach\non diverse tabular datasets, comparing its performance against a wide range of\nmachine learning algorithms, including classical methods, tree-based ensembles,\nand state-of-the-art deep learning models specifically designed for tabular\ndata. We also perform an in-depth analysis of factors influencing Tab2Visual's\nperformance. Our experimental results demonstrate that Tab2Visual outperforms\nother methods in classification problems with limited tabular data.",
      "published": "February 11, 2025",
      "categories": [
        "cs.LG",
        "cs.CV"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.07181v1",
      "arxiv_url": "http://arxiv.org/abs/2502.07181v1"
    },
    {
      "title": "Cross-platform Learning-based Fault Tolerant Surfacing Controller for\n  Underwater Robots",
      "authors": [
        "Yuya Hamamatsu",
        "Walid Remmas",
        "Jaan Rebane",
        "Maarja Kruusmaa",
        "Asko Ristolainen"
      ],
      "abstract": "In this paper, we propose a novel cross-platform fault-tolerant surfacing\ncontroller for underwater robots, based on reinforcement learning (RL). Unlike\nconventional approaches, which require explicit identification of\nmalfunctioning actuators, our method allows the robot to surface using only the\nremaining operational actuators without needing to pinpoint the failures. The\nproposed controller learns a robust policy capable of handling diverse failure\nscenarios across different actuator configurations. Moreover, we introduce a\ntransfer learning mechanism that shares a part of the control policy across\nvarious underwater robots with different actuators, thus improving learning\nefficiency and generalization across platforms. To validate our approach, we\nconduct simulations on three different types of underwater robots: a\nhovering-type AUV, a torpedo shaped AUV, and a turtle-shaped robot (U-CAT).\nAdditionally, real-world experiments are performed, successfully transferring\nthe learned policy from simulation to a physical U-CAT in a controlled\nenvironment. Our RL-based controller demonstrates superior performance in terms\nof stability and success rate compared to a baseline controller, achieving an\n85.7 percent success rate in real-world tests compared to 57.1 percent with a\nbaseline controller. This research provides a scalable and efficient solution\nfor fault-tolerant control for diverse underwater platforms, with potential\napplications in real-world aquatic missions.",
      "published": "February 10, 2025",
      "categories": [
        "cs.RO"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.07133v1",
      "arxiv_url": "http://arxiv.org/abs/2502.07133v1"
    },
    {
      "title": "Generative Distribution Prediction: A Unified Approach to Multimodal\n  Learning",
      "authors": [
        "Xinyu Tian",
        "Xiaotong Shen"
      ],
      "abstract": "Accurate prediction with multimodal data-encompassing tabular, textual, and\nvisual inputs or outputs-is fundamental to advancing analytics in diverse\napplication domains. Traditional approaches often struggle to integrate\nheterogeneous data types while maintaining high predictive accuracy. We\nintroduce Generative Distribution Prediction (GDP), a novel framework that\nleverages multimodal synthetic data generation-such as conditional diffusion\nmodels-to enhance predictive performance across structured and unstructured\nmodalities. GDP is model-agnostic, compatible with any high-fidelity generative\nmodel, and supports transfer learning for domain adaptation. We establish a\nrigorous theoretical foundation for GDP, providing statistical guarantees on\nits predictive accuracy when using diffusion models as the generative backbone.\nBy estimating the data-generating distribution and adapting to various loss\nfunctions for risk minimization, GDP enables accurate point predictions across\nmultimodal settings. We empirically validate GDP on four supervised learning\ntasks-tabular data prediction, question answering, image captioning, and\nadaptive quantile regression-demonstrating its versatility and effectiveness\nacross diverse domains.",
      "published": "February 10, 2025",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.07090v1",
      "arxiv_url": "http://arxiv.org/abs/2502.07090v1"
    },
    {
      "title": "Model Diffusion for Certifiable Few-shot Transfer Learning",
      "authors": [
        "Fady Rezk",
        "Royson Lee",
        "Henry Gouk",
        "Timothy Hospedales",
        "Minyoung Kim"
      ],
      "abstract": "In modern large-scale deep learning, a prevalent and effective workflow for\nsolving low-data problems is adapting powerful pre-trained foundation models\n(FMs) to new tasks via parameter-efficient fine-tuning (PEFT). However, while\nempirically effective, the resulting solutions lack generalisation guarantees\nto certify their accuracy - which may be required for ethical or legal reasons\nprior to deployment in high-importance applications. In this paper we develop a\nnovel transfer learning approach that is designed to facilitate non-vacuous\nlearning theoretic generalisation guarantees for downstream tasks, even in the\nlow-shot regime. Specifically, we first use upstream tasks to train a\ndistribution over PEFT parameters. We then learn the downstream task by a\nsample-and-evaluate procedure -- sampling plausible PEFTs from the trained\ndiffusion model and selecting the one with the highest likelihood on the\ndownstream data. Crucially, this confines our model hypothesis to a finite set\nof PEFT samples. In contrast to learning in the typical continuous hypothesis\nspaces of neural network weights, this facilitates tighter risk certificates.\nWe instantiate our bound and show non-trivial generalization guarantees\ncompared to existing learning approaches which lead to vacuous bounds in the\nlow-shot regime.",
      "published": "February 10, 2025",
      "categories": [
        "cs.LG",
        "stat.ML"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.06970v1",
      "arxiv_url": "http://arxiv.org/abs/2502.06970v1"
    },
    {
      "title": "Institutional Preferences in the Laboratory",
      "authors": [
        "Qiankun Zhong",
        "Nori Jacoby",
        "Ofer Tchernichovski",
        "Seth Frey"
      ],
      "abstract": "Getting a group to adopt cooperative norms is an enduring challenge. But in\nreal-world settings, individuals don't just passively accept static\nenvironments, they act both within and upon the social systems that structure\ntheir interactions. Should we expect the dynamism of player-driven changes to\nthe \"rules of the game\" to hinder cooperation -- because of the substantial\nadded complexity -- or help it, as prosocial agents tweak their environment\ntoward non-zero-sum games? We introduce a laboratory setting to test whether\ngroups can guide themselves to cooperative outcomes by manipulating the\nenvironmental parameters that shape their emergent cooperation process. We test\nfor cooperation in a set of economic games that impose different social\ndilemmas. These games vary independently in the institutional features of\nstability, efficiency, and fairness. By offering agency over behavior along\nwith second-order agency over the rules of the game, we understand emergent\ncooperation in naturalistic settings in which the rules of the game are\nthemselves dynamic and subject to choice. The literature on transfer learning\nin games suggests that interactions between features are important and might\naid or hinder the transfer of cooperative learning to new settings.",
      "published": "February 10, 2025",
      "categories": [
        "cs.SI",
        "cs.GT"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.06748v1",
      "arxiv_url": "http://arxiv.org/abs/2502.06748v1"
    },
    {
      "title": "Hyperparameters in Score-Based Membership Inference Attacks",
      "authors": [
        "Gauri Pradhan",
        "Joonas J\u00e4lk\u00f6",
        "Marlon Tobaben",
        "Antti Honkela"
      ],
      "abstract": "Membership Inference Attacks (MIAs) have emerged as a valuable framework for\nevaluating privacy leakage by machine learning models. Score-based MIAs are\ndistinguished, in particular, by their ability to exploit the confidence scores\nthat the model generates for particular inputs. Existing score-based MIAs\nimplicitly assume that the adversary has access to the target model's\nhyperparameters, which can be used to train the shadow models for the attack.\nIn this work, we demonstrate that the knowledge of target hyperparameters is\nnot a prerequisite for MIA in the transfer learning setting. Based on this, we\npropose a novel approach to select the hyperparameters for training the shadow\nmodels for MIA when the attacker has no prior knowledge about them by matching\nthe output distributions of target and shadow models. We demonstrate that using\nthe new approach yields hyperparameters that lead to an attack near\nindistinguishable in performance from an attack that uses target\nhyperparameters to train the shadow models. Furthermore, we study the empirical\nprivacy risk of unaccounted use of training data for hyperparameter\noptimization (HPO) in differentially private (DP) transfer learning. We find no\nstatistically significant evidence that performing HPO using training data\nwould increase vulnerability to MIA.",
      "published": "February 10, 2025",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.06374v1",
      "arxiv_url": "http://arxiv.org/abs/2502.06374v1"
    },
    {
      "title": "A Data-Efficient Pan-Tumor Foundation Model for Oncology CT\n  Interpretation",
      "authors": [
        "Wenhui Lei",
        "Hanyu Chen",
        "Zitian Zhang",
        "Luyang Luo",
        "Qiong Xiao",
        "Yannian Gu",
        "Peng Gao",
        "Yankai Jiang",
        "Ci Wang",
        "Guangtao Wu",
        "Tongjia Xu",
        "Yingjie Zhang",
        "Xiaofan Zhang",
        "Pranav Rajpurkar",
        "Shaoting Zhang",
        "Zhenning Wang"
      ],
      "abstract": "Artificial intelligence-assisted imaging analysis has made substantial\nstrides in tumor diagnosis and management. Here we present PASTA, a pan-tumor\nCT foundation model that achieves state-of-the-art performance on 45 of 46\nrepresentative oncology tasks -- including lesion segmentation, tumor detection\nin plain CT, tumor staging, survival prediction, structured report generation,\nand cross-modality transfer learning, significantly outperforming the\nsecond-best models on 35 tasks. This remarkable advancement is driven by our\ndevelopment of PASTA-Gen, an innovative synthetic tumor generation framework\nthat produces a comprehensive dataset of 30,000 CT scans with pixel-level\nannotated lesions and paired structured reports, encompassing malignancies\nacross ten organs and five benign lesion types. By leveraging this rich,\nhigh-quality synthetic data, we overcome a longstanding bottleneck in the\ndevelopment of CT foundation models -- specifically, the scarcity of publicly\navailable, high-quality annotated datasets due to privacy constraints and the\nsubstantial labor required for scaling precise data annotation. Encouragingly,\nPASTA demonstrates exceptional data efficiency with promising practical value,\nmarkedly improving performance on various tasks with only a small amount of\nreal-world data. The open release of both the synthetic dataset and PASTA\nfoundation model effectively addresses the challenge of data scarcity, thereby\nadvancing oncological research and clinical translation.",
      "published": "February 10, 2025",
      "categories": [
        "eess.IV",
        "cs.CV"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.06171v1",
      "arxiv_url": "http://arxiv.org/abs/2502.06171v1"
    },
    {
      "title": "Low Tensor-Rank Adaptation of Kolmogorov--Arnold Networks",
      "authors": [
        "Yihang Gao",
        "Michael K. Ng",
        "Vincent Y. F. Tan"
      ],
      "abstract": "Kolmogorov--Arnold networks (KANs) have demonstrated their potential as an\nalternative to multi-layer perceptions (MLPs) in various domains, especially\nfor science-related tasks. However, transfer learning of KANs remains a\nrelatively unexplored area. In this paper, inspired by Tucker decomposition of\ntensors and evidence on the low tensor-rank structure in KAN parameter updates,\nwe develop low tensor-rank adaptation (LoTRA) for fine-tuning KANs. We study\nthe expressiveness of LoTRA based on Tucker decomposition approximations.\nFurthermore, we provide a theoretical analysis to select the learning rates for\neach LoTRA component to enable efficient training. Our analysis also shows that\nusing identical learning rates across all components leads to inefficient\ntraining, highlighting the need for an adaptive learning rate strategy. Beyond\ntheoretical insights, we explore the application of LoTRA for efficiently\nsolving various partial differential equations (PDEs) by fine-tuning KANs.\nAdditionally, we propose Slim KANs that incorporate the inherent\nlow-tensor-rank properties of KAN parameter tensors to reduce model size while\nmaintaining superior performance. Experimental results validate the efficacy of\nthe proposed learning rate selection strategy and demonstrate the effectiveness\nof LoTRA for transfer learning of KANs in solving PDEs. Further evaluations on\nSlim KANs for function representation and image classification tasks highlight\nthe expressiveness of LoTRA and the potential for parameter reduction through\nlow tensor-rank decomposition.",
      "published": "February 10, 2025",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.06153v1",
      "arxiv_url": "http://arxiv.org/abs/2502.06153v1"
    },
    {
      "title": "Protecting Intellectual Property of EEG-based Neural Networks with\n  Watermarking",
      "authors": [
        "Ahmed Abdelaziz",
        "Ahmed Fathi",
        "Ahmed Fares"
      ],
      "abstract": "EEG-based neural networks, pivotal in medical diagnosis and brain-computer\ninterfaces, face significant intellectual property (IP) risks due to their\nreliance on sensitive neurophysiological data and resource-intensive\ndevelopment. Current watermarking methods, particularly those using abstract\ntrigger sets, lack robust authentication and fail to address the unique\nchallenges of EEG models. This paper introduces a cryptographic wonder\nfilter-based watermarking framework tailored for EEG-based neural networks.\nLeveraging collision-resistant hashing and public-key encryption, the wonder\nfilter embeds the watermark during training, ensuring minimal distortion ($\\leq\n5\\%$ drop in EEG task accuracy) and high reliability (100\\% watermark\ndetection). The framework is rigorously evaluated against adversarial attacks,\nincluding fine-tuning, transfer learning, and neuron pruning. Results\ndemonstrate persistent watermark retention, with classification accuracy for\nwatermarked states remaining above 90\\% even after aggressive pruning, while\nprimary task performance degrades faster, deterring removal attempts. Piracy\nresistance is validated by the inability to embed secondary watermarks without\nsevere accuracy loss ( $>10\\%$ in EEGNet and CCNN models). Cryptographic\nhashing ensures authentication, reducing brute-force attack success\nprobabilities. Evaluated on the DEAP dataset across models (CCNN, EEGNet,\nTSception), the method achieves $>99.4\\%$ null-embedding accuracy, effectively\neliminating false positives. By integrating wonder filters with EEG-specific\nadaptations, this work bridges a critical gap in IP protection for\nneurophysiological models, offering a secure, tamper-proof solution for\nhealthcare and biometric applications. The framework's robustness against\nadversarial modifications underscores its potential to safeguard sensitive EEG\nmodels while maintaining diagnostic utility.",
      "published": "February 09, 2025",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "94A60, 68P25",
        "H.1.2; I.2.6; J.3; K.5.1"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.05931v1",
      "arxiv_url": "http://arxiv.org/abs/2502.05931v1"
    },
    {
      "title": "Target Speaker Lipreading by Audio-Visual Self-Distillation Pretraining\n  and Speaker Adaptation",
      "authors": [
        "Jing-Xuan Zhang",
        "Tingzhi Mao",
        "Longjiang Guo",
        "Jin Li",
        "Lichen Zhang"
      ],
      "abstract": "Lipreading is an important technique for facilitating human-computer\ninteraction in noisy environments. Our previously developed self-supervised\nlearning method, AV2vec, which leverages multimodal self-distillation, has\ndemonstrated promising performance in speaker-independent lipreading on the\nEnglish LRS3 dataset. However, AV2vec faces challenges such as high training\ncosts and a potential scarcity of audio-visual data for lipreading in languages\nother than English, such as Chinese. Additionally, most studies concentrate on\nspeakerindependent lipreading models, which struggle to account for the\nsubstantial variation in speaking styles across di?erent speakers. To address\nthese issues, we propose a comprehensive approach. First, we investigate\ncross-lingual transfer learning, adapting a pre-trained AV2vec model from a\nsource language and optimizing it for the lipreading task in a target language.\nSecond, we enhance the accuracy of lipreading for specific target speakers\nthrough a speaker adaptation strategy, which is not extensively explored in\nprevious research. Third, after analyzing the complementary performance of\nlipreading with lip region-of-interest (ROI) and face inputs, we introduce a\nmodel ensembling strategy that integrates both, signi?cantly boosting model\nperformance. Our method achieved a character error rate (CER) of 77.3% on the\nevaluation set of the ChatCLR dataset, which is lower than the top result from\nthe 2024 Chat-scenario Chinese Lipreading Challenge.",
      "published": "February 09, 2025",
      "categories": [
        "eess.AS"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.05758v1",
      "arxiv_url": "http://arxiv.org/abs/2502.05758v1"
    },
    {
      "title": "Topological derivative approach for deep neural network architecture\n  adaptation",
      "authors": [
        "C G Krishnanunni",
        "Tan Bui-Thanh",
        "Clint Dawson"
      ],
      "abstract": "This work presents a novel algorithm for progressively adapting neural\nnetwork architecture along the depth. In particular, we attempt to address the\nfollowing questions in a mathematically principled way: i) Where to add a new\ncapacity (layer) during the training process? ii) How to initialize the new\ncapacity? At the heart of our approach are two key ingredients: i) the\nintroduction of a ``shape functional\" to be minimized, which depends on neural\nnetwork topology, and ii) the introduction of a topological derivative of the\nshape functional with respect to the neural network topology. Using an optimal\ncontrol viewpoint, we show that the network topological derivative exists under\ncertain conditions, and its closed-form expression is derived. In particular,\nwe explore, for the first time, the connection between the topological\nderivative from a topology optimization framework with the Hamiltonian from\noptimal control theory. Further, we show that the optimality condition for the\nshape functional leads to an eigenvalue problem for deep neural architecture\nadaptation. Our approach thus determines the most sensitive location along the\ndepth where a new layer needs to be inserted during the training phase and the\nassociated parametric initialization for the newly added layer. We also\ndemonstrate that our layer insertion strategy can be derived from an optimal\ntransport viewpoint as a solution to maximizing a topological derivative in\n$p$-Wasserstein space, where $p>= 1$. Numerical investigations with fully\nconnected network, convolutional neural network, and vision transformer on\nvarious regression and classification problems demonstrate that our proposed\napproach can outperform an ad-hoc baseline network and other architecture\nadaptation strategies. Further, we also demonstrate other applications of\ntopological derivative in fields such as transfer learning.",
      "published": "February 08, 2025",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.06885v1",
      "arxiv_url": "http://arxiv.org/abs/2502.06885v1"
    },
    {
      "title": "Data-Driven Distributionally Robust Mixed-Integer Control through Lifted\n  Control Policy",
      "authors": [
        "Xutao Ma",
        "Chao Ning",
        "Wenli Du",
        "Yang Shi"
      ],
      "abstract": "This paper investigates the finite-horizon distributionally robust\nmixed-integer control (DRMIC) of uncertain linear systems. However, deriving an\noptimal causal feedback control policy to this DRMIC problem is computationally\nformidable for most ambiguity sets. To address the computational challenge, we\npropose a novel distributionally robust lifted control policy (DR-LCP) method\nto derive a high-quality approximate solution to this DRMIC problem for a rich\nclass of Wasserstein metric-based ambiguity sets, including the Wasserstein\nambiguity set and its variants. In theory, we analyze the asymptotic\nperformance and establish a tight non-asymptotic bound of the proposed method.\nIn numerical experiments, the proposed DR-LCP method empirically demonstrates\nsuperior performance compared with existing methods in the literature.",
      "published": "February 08, 2025",
      "categories": [
        "math.OC",
        "cs.SY",
        "eess.SY"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.05469v1",
      "arxiv_url": "http://arxiv.org/abs/2502.05469v1"
    },
    {
      "title": "Distributionally Robust Model Predictive Control with Mixture of\n  Gaussian Processes",
      "authors": [
        "Jingyi Wu",
        "Chao Ning"
      ],
      "abstract": "Despite the success of Gaussian process based Model Predictive Control (MPC)\nin robotic control, its applicability scope is greatly hindered by multimodal\ndisturbances that are prevalent in real-world settings. Here we propose a novel\nMixture of Gaussian Processes based Distributionally Robust MPC (MoGP-DR-MPC)\nframework for linear time invariant systems subject to potentially multimodal\nstate-dependent disturbances. This framework utilizes MoGP to automatically\ndetermine the number of modes from disturbance data. Using the mean and\nvariance information provided by each mode-specific predictive distribution, it\nconstructs a data-driven state-dependent ambiguity set, which allows for\nflexible and fine-grained disturbance modeling. Based on this ambiguity set, we\nimpose Distributionally Robust Conditional Value-at Risk (DR-CVaR) constraints\nto effectively achieve distributional robustness against errors in the\npredictive distributions. To address the computational challenge posed by these\nconstraints in the resulting MPC problem, we equivalently reformulate the\nDR-CVaR constraints into tractable second-order cone constraints. Furthermore,\nwe provide theoretical guarantees on the recursive feasibility and stability of\nthe proposed framework. The enhanced control performance of MoGP-DR-MPC is\nvalidated through both numerical experiments and simulations on a quadrotor\nsystem, demonstrating notable reductions in closed-loop cost by 17% and 4%\nrespectively compared against Gaussian process based MPC.",
      "published": "February 08, 2025",
      "categories": [
        "eess.SY",
        "cs.SY",
        "math.OC"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.05448v1",
      "arxiv_url": "http://arxiv.org/abs/2502.05448v1"
    },
    {
      "title": "Evaluating Standard and Dialectal Frisian ASR: Multilingual Fine-tuning\n  and Language Identification for Improved Low-resource Performance",
      "authors": [
        "Reihaneh Amooie",
        "Wietse de Vries",
        "Yun Hao",
        "Jelske Dijkstra",
        "Matt Coler",
        "Martijn Wieling"
      ],
      "abstract": "Automatic Speech Recognition (ASR) performance for low-resource languages is\nstill far behind that of higher-resource languages such as English, due to a\nlack of sufficient labeled data. State-of-the-art methods deploy\nself-supervised transfer learning where a model pre-trained on large amounts of\ndata is fine-tuned using little labeled data in a target low-resource language.\nIn this paper, we present and examine a method for fine-tuning an SSL-based\nmodel in order to improve the performance for Frisian and its regional dialects\n(Clay Frisian, Wood Frisian, and South Frisian). We show that Frisian ASR\nperformance can be improved by using multilingual (Frisian, Dutch, English and\nGerman) fine-tuning data and an auxiliary language identification task. In\naddition, our findings show that performance on dialectal speech suffers\nsubstantially, and, importantly, that this effect is moderated by the\nelicitation approach used to collect the dialectal data. Our findings also\nparticularly suggest that relying solely on standard language data for ASR\nevaluation may underestimate real-world performance, particularly in languages\nwith substantial dialectal variation.",
      "published": "February 07, 2025",
      "categories": [
        "cs.CL",
        "cs.LG",
        "cs.SD",
        "eess.AS"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.04883v1",
      "arxiv_url": "http://arxiv.org/abs/2502.04883v1"
    },
    {
      "title": "Self-Supervised Learning for Pre-training Capsule Networks: Overcoming\n  Medical Imaging Dataset Challenges",
      "authors": [
        "Heba El-Shimy",
        "Hind Zantout",
        "Michael A. Lones",
        "Neamat El Gayar"
      ],
      "abstract": "Deep learning techniques are increasingly being adopted in diagnostic medical\nimaging. However, the limited availability of high-quality, large-scale medical\ndatasets presents a significant challenge, often necessitating the use of\ntransfer learning approaches. This study investigates self-supervised learning\nmethods for pre-training capsule networks in polyp diagnostics for colon\ncancer. We used the PICCOLO dataset, comprising 3,433 samples, which\nexemplifies typical challenges in medical datasets: small size, class\nimbalance, and distribution shifts between data splits. Capsule networks offer\ninherent interpretability due to their architecture and inter-layer information\nrouting mechanism. However, their limited native implementation in mainstream\ndeep learning frameworks and the lack of pre-trained versions pose a\nsignificant challenge. This is particularly true if aiming to train them on\nsmall medical datasets, where leveraging pre-trained weights as initial\nparameters would be beneficial. We explored two auxiliary self-supervised\nlearning tasks, colourisation and contrastive learning, for capsule network\npre-training. We compared self-supervised pre-trained models against\nalternative initialisation strategies. Our findings suggest that contrastive\nlearning and in-painting techniques are suitable auxiliary tasks for\nself-supervised learning in the medical domain. These techniques helped guide\nthe model to capture important visual features that are beneficial for the\ndownstream task of polyp classification, increasing its accuracy by 5.26%\ncompared to other weight initialisation methods.",
      "published": "February 07, 2025",
      "categories": [
        "cs.CV",
        "cs.LG"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.04748v1",
      "arxiv_url": "http://arxiv.org/abs/2502.04748v1"
    },
    {
      "title": "Transfer learning in Scalable Graph Neural Network for Improved Physical\n  Simulation",
      "authors": [
        "Siqi Shen",
        "Yu Liu",
        "Daniel Biggs",
        "Omar Hafez",
        "Jiandong Yu",
        "Wentao Zhang",
        "Bin Cui",
        "Jiulong Shan"
      ],
      "abstract": "In recent years, Graph Neural Network (GNN) based models have shown promising\nresults in simulating physics of complex systems. However, training dedicated\ngraph network based physics simulators can be costly, as most models are\nconfined to fully supervised training, which requires extensive data generated\nfrom traditional physics simulators. To date, how transfer learning could\nimprove the model performance and training efficiency has remained unexplored.\nIn this work, we introduce a pre-training and transfer learning paradigm for\ngraph network simulators. We propose the scalable graph U-net (SGUNET).\nIncorporating an innovative depth-first search (DFS) pooling, the SGUNET is\nadaptable to different mesh sizes and resolutions for various simulation tasks.\nTo enable the transfer learning between differently configured SGUNETs, we\npropose a set of mapping functions to align the parameters between the\npre-trained model and the target model. An extra normalization term is also\nadded into the loss to constrain the difference between the pre-trained weights\nand target model weights for better generalization performance. To pre-train\nour physics simulator we created a dataset which includes 20,000 physical\nsimulations of randomly selected 3D shapes from the open source A Big CAD (ABC)\ndataset. We show that our proposed transfer learning methods allow the model to\nperform even better when fine-tuned with small amounts of training data than\nwhen it is trained from scratch with full extensive dataset. On the 2D\nDeformable Plate benchmark dataset, our pre-trained model fine-tuned on 1/16 of\nthe training data achieved an 11.05\\% improvement in position RMSE compared to\nthe model trained from scratch.",
      "published": "February 07, 2025",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.06848v1",
      "arxiv_url": "http://arxiv.org/abs/2502.06848v1"
    },
    {
      "title": "Performance Evaluation of Image Enhancement Techniques on Transfer\n  Learning for Touchless Fingerprint Recognition",
      "authors": [
        "S Sreehari",
        "Dilavar P D",
        "S M Anzar",
        "Alavikunhu Panthakkan",
        "Saad Ali Amin"
      ],
      "abstract": "Fingerprint recognition remains one of the most reliable biometric\ntechnologies due to its high accuracy and uniqueness. Traditional systems rely\non contact-based scanners, which are prone to issues such as image degradation\nfrom surface contamination and inconsistent user interaction. To address these\nlimitations, contactless fingerprint recognition has emerged as a promising\nalternative, providing non-intrusive and hygienic authentication. This study\nevaluates the impact of image enhancement tech-niques on the performance of\npre-trained deep learning models using transfer learning for touchless\nfingerprint recognition. The IIT-Bombay Touchless and Touch-Based Fingerprint\nDatabase, containing data from 200 subjects, was employed to test the\nper-formance of deep learning architectures such as VGG-16, VGG-19,\nInception-V3, and ResNet-50. Experimental results reveal that transfer learning\nmethods with fingerprint image enhance-ment (indirect method) significantly\noutperform those without enhancement (direct method). Specifically, VGG-16\nachieved an accuracy of 98% in training and 93% in testing when using the\nenhanced images, demonstrating superior performance compared to the direct\nmethod.\n  This paper provides a detailed comparison of the effectiveness of image\nenhancement in improving the accuracy of transfer learning models for touchless\nfingerprint recognition, offering key insights for developing more efficient\nbiometric systems.",
      "published": "February 07, 2025",
      "categories": [
        "cs.CV",
        "cs.LG"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.04680v1",
      "arxiv_url": "http://arxiv.org/abs/2502.04680v1"
    },
    {
      "title": "Provable Sample-Efficient Transfer Learning Conditional Diffusion Models\n  via Representation Learning",
      "authors": [
        "Ziheng Cheng",
        "Tianyu Xie",
        "Shiyue Zhang",
        "Cheng Zhang"
      ],
      "abstract": "While conditional diffusion models have achieved remarkable success in\nvarious applications, they require abundant data to train from scratch, which\nis often infeasible in practice. To address this issue, transfer learning has\nemerged as an essential paradigm in small data regimes. Despite its empirical\nsuccess, the theoretical underpinnings of transfer learning conditional\ndiffusion models remain unexplored. In this paper, we take the first step\ntowards understanding the sample efficiency of transfer learning conditional\ndiffusion models through the lens of representation learning. Inspired by\npractical training procedures, we assume that there exists a low-dimensional\nrepresentation of conditions shared across all tasks. Our analysis shows that\nwith a well-learned representation from source tasks, the samplecomplexity of\ntarget tasks can be reduced substantially. In addition, we investigate the\npractical implications of our theoretical results in several real-world\napplications of conditional diffusion models. Numerical experiments are also\nconducted to verify our results.",
      "published": "February 06, 2025",
      "categories": [
        "cs.LG",
        "math.ST",
        "stat.ML",
        "stat.TH"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.04491v1",
      "arxiv_url": "http://arxiv.org/abs/2502.04491v1"
    },
    {
      "title": "Multi-fidelity emulator for large-scale 21 cm lightcone images: a\n  few-shot transfer learning approach with generative adversarial network",
      "authors": [
        "Kangning Diao",
        "Yi Mao"
      ],
      "abstract": "Emulators using machine learning techniques have emerged to efficiently\ngenerate mock data matching the large survey volume for upcoming experiments,\nas an alternative approach to large-scale numerical simulations. However,\nhigh-fidelity emulators have become computationally expensive as the simulation\nvolume grows to hundreds of megaparsecs. Here, we present a {\\it\nmulti-fidelity} emulation of large-scale 21~cm lightcone images from the epoch\nof reionization, which is realized by applying the {\\it few-shot transfer\nlearning} to training generative adversarial networks (GAN) from small-scale to\nlarge-scale simulations. Specifically, a GAN emulator is first trained with a\nhuge number of small-scale simulations, and then transfer-learned with only a\nlimited number of large-scale simulations, to emulate large-scale 21~cm\nlightcone images. We test the precision of our transfer-learned GAN emulator in\nterms of representative statistics including global 21~cm brightness\ntemperature history, 2D power spectrum, and scattering transform coefficients.\nWe demonstrate that the lightcone images generated by the transfer-learned GAN\nemulator can reach the percentage level precision in most cases on small\nscales, and the error on large scales only increases mildly to the level of a\nfew tens of per cent. Nevertheless, our multi-fidelity emulation technique\nsaves a significant portion of computational resources that are mostly consumed\nfor generating training samples for GAN. On estimate, the computational\nresource by training GAN completely with large-scale simulations would be one\nto two orders of magnitude larger than using our multi-fidelity technique. This\nimplies that our technique allows for emulating high-fidelity, traditionally\ncomputationally prohibitive, images in an economic manner.",
      "published": "February 06, 2025",
      "categories": [
        "astro-ph.IM",
        "astro-ph.CO"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.04246v1",
      "arxiv_url": "http://arxiv.org/abs/2502.04246v1"
    },
    {
      "title": "A Theoretical Framework for Data Efficient Multi-Source Transfer\n  Learning Based on Cram\u00e9r-Rao Bound",
      "authors": [
        "Qingyue Zhang",
        "Haohao Fu",
        "Guanbo Huang",
        "Yaoyuan Liang",
        "Chang Chu",
        "Tianren Peng",
        "Yanru Wu",
        "Qi Li",
        "Yang Li",
        "Shao-Lun Huang"
      ],
      "abstract": "Multi-source transfer learning provides an effective solution to data\nscarcity in real-world supervised learning scenarios by leveraging multiple\nsource tasks. In this field, existing works typically use all available samples\nfrom sources in training, which constrains their training efficiency and may\nlead to suboptimal results. To address this, we propose a theoretical framework\nthat answers the question: what is the optimal quantity of source samples\nneeded from each source task to jointly train the target model? Specifically,\nwe introduce a generalization error measure that aligns with cross-entropy\nloss, and minimize it based on the Cram\\'er-Rao Bound to determine the optimal\ntransfer quantity for each source task. Additionally, we develop an\narchitecture-agnostic and data-efficient algorithm OTQMS to implement our\ntheoretical results for training deep multi-source transfer learning models.\nExperimental studies on diverse architectures and two real-world benchmark\ndatasets show that our proposed algorithm significantly outperforms\nstate-of-the-art approaches in both accuracy and data efficiency. The code and\nsupplementary materials are available in\nhttps://anonymous.4open.science/r/Materials.",
      "published": "February 06, 2025",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.04242v1",
      "arxiv_url": "http://arxiv.org/abs/2502.04242v1"
    },
    {
      "title": "Transfer Learning for Covert Speech Classification Using EEG Hilbert\n  Envelope and Temporal Fine Structure",
      "authors": [
        "Saravanakumar Duraisamy",
        "Mateusz Dubiel",
        "Maurice Rekrut",
        "Luis A. Leiva"
      ],
      "abstract": "Brain-Computer Interfaces (BCIs) can decode imagined speech from neural\nactivity. However, these systems typically require extensive training sessions\nwhere participants imaginedly repeat words, leading to mental fatigue and\ndifficulties identifying the onset of words, especially when imagining\nsequences of words. This paper addresses these challenges by transferring a\nclassifier trained in overt speech data to covert speech classification. We\nused electroencephalogram (EEG) features derived from the Hilbert envelope and\ntemporal fine structure, and used them to train a bidirectional long-short-term\nmemory (BiLSTM) model for classification. Our method reduces the burden of\nextensive training and achieves state-of-the-art classification accuracy:\n86.44% for overt speech and 79.82% for covert speech using the overt speech\nclassifier.",
      "published": "February 06, 2025",
      "categories": [
        "cs.LG"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.04132v1",
      "arxiv_url": "http://arxiv.org/abs/2502.04132v1"
    },
    {
      "title": "Generalize Drug Response Prediction by Latent Independent Projection for\n  Asymmetric Constrained Domain Generalization",
      "authors": [
        "Ran Song",
        "Yinpu Bai",
        "Hui Liu"
      ],
      "abstract": "The accurate prediction of drug responses remains a formidable challenge,\nparticularly at the single-cell level and in clinical treatment contexts. Some\nstudies employ transfer learning techniques to predict drug responses in\nindividual cells and patients, but they require access to target-domain data\nduring training, which is often unavailable or only obtainable in future. In\nthis study, we propose a novel domain generalization framework, termed\npanCancerDR, to address this challenge. We conceptualize each cancer type as a\ndistinct source domain, with its cell lines serving as domain-specific samples.\nOur primary objective is to extract domain-invariant features from the\nexpression profiles of cell lines across diverse cancer types, thereby\ngeneralize the predictive capacity to out-of-distribution samples. To enhance\nrobustness, we introduce a latent independence projection (LIP) module that\nencourages the encoder to extract informative yet non-redundant features. Also,\nwe propose an asymmetric adaptive clustering constraint, which clusters\ndrug-sensitive samples into a compact group while drives resistant samples\ndispersed across separate clusters in the latent space. Our empirical\nexperiments demonstrate that panCancerDR effectively learns task-relevant\nfeatures from diverse source domains, and achieves accurate predictions of drug\nresponse for unseen cancer type during training. Furthermore, when evaluated on\nsingle-cell and patient-level prediction tasks, our model-trained solely on in\nvitro cell line data without access to target-domain information-consistently\noutperforms and matched current state-of-the-art methods. These findings\nhighlights the potential of our method for real-world clinical applications.",
      "published": "February 06, 2025",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.04034v1",
      "arxiv_url": "http://arxiv.org/abs/2502.04034v1"
    },
    {
      "title": "ICGNN: Graph Neural Network Enabled Scalable Beamforming for MISO\n  Interference Channels",
      "authors": [
        "Changpeng He",
        "Yang Lu",
        "Bo Ai",
        "Octavia A. Dobre",
        "Zhiguo Ding",
        "Dusit Niyato"
      ],
      "abstract": "This paper investigates the graph neural network (GNN)-enabled beamforming\ndesign for interference channels. We propose a model termed interference\nchannel GNN (ICGNN) to solve a quality-of-service constrained energy efficiency\nmaximization problem. The ICGNN is two-stage, where the direction and power\nparts of beamforming vectors are learned separately but trained jointly via\nunsupervised learning. By formulating the dimensionality of features\nindependent of the transceiver pairs, the ICGNN is scalable with the number of\ntransceiver pairs. Besides, to improve the performance of the ICGNN, the hybrid\nmaximum ratio transmission and zero-forcing scheme reduces the output ports,\nthe feature enhancement module unifies the two types of links into one type,\nthe subgraph representation enhances the message passing efficiency, and the\nmulti-head attention and residual connection facilitate the feature extracting.\nFurthermore, we present the over-the-air distributed implementation of the\nICGNN. Ablation studies validate the effectiveness of key components in the\nICGNN. Numerical results also demonstrate the capability of ICGNN in achieving\nnear-optimal performance with an average inference time less than 0.1 ms. The\nscalability of ICGNN for unseen problem sizes is evaluated and enhanced by\ntransfer learning with limited fine-tuning cost. The results of the centralized\nand distributed implementations of ICGNN are illustrated.",
      "published": "February 06, 2025",
      "categories": [
        "eess.SP"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.03936v1",
      "arxiv_url": "http://arxiv.org/abs/2502.03936v1"
    },
    {
      "title": "SWIPTNet: A Unified Deep Learning Framework for SWIPT based on GNN and\n  Transfer Learning",
      "authors": [
        "Hong Han",
        "Yang Lu",
        "Zihan Song",
        "Ruichen Zhang",
        "Wei Chen",
        "Bo Ai",
        "Dusit Niyato",
        "Dong In Kim"
      ],
      "abstract": "This paper investigates the deep learning based approaches for simultaneous\nwireless information and power transfer (SWIPT). The quality-of-service (QoS)\nconstrained sum-rate maximization problems are, respectively, formulated for\npower-splitting (PS) receivers and time-switching (TS) receivers and solved by\na unified graph neural network (GNN) based model termed SWIPT net (SWIPTNet).\nTo improve the performance of SWIPTNet, we first propose a single-type output\nmethod to reduce the learning complexity and facilitate the satisfaction of QoS\nconstraints, and then, utilize the Laplace transform to enhance input features\nwith the structural information. Besides, we adopt the multi-head attention and\nlayer connection to enhance feature extracting. Furthermore, we present the\nimplementation of transfer learning to the SWIPTNet between PS and TS\nreceivers. Ablation studies show the effectiveness of key components in the\nSWIPTNet. Numerical results also demonstrate the capability of SWIPTNet in\nachieving near-optimal performance with millisecond-level inference speed which\nis much faster than the traditional optimization algorithms. We also show the\neffectiveness of transfer learning via fast convergence and expressive\ncapability improvement.",
      "published": "February 06, 2025",
      "categories": [
        "eess.SP"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.03928v1",
      "arxiv_url": "http://arxiv.org/abs/2502.03928v1"
    },
    {
      "title": "Self-Supervised Learning for Solar Radio Spectrum Classification",
      "authors": [
        "Siqi Li",
        "Guowu Yuan",
        "Jian Chen",
        "Chengming Tan",
        "Hao Zhou"
      ],
      "abstract": "Solar radio observation is an important way to study the Sun. Solar radio\nbursts contain important information about solar activity. Therefore, real-time\nautomatic detection and classification of solar radio bursts are of great value\nfor subsequent solar physics research and space weather warnings. Traditional\nimage classification methods based on deep learning often require consid-erable\ntraining data. To address insufficient solar radio spectrum images, transfer\nlearning is generally used. However, the large difference between natural\nimages and solar spectrum images has a large impact on the transfer learning\neffect. In this paper, we propose a self-supervised learning method for solar\nradio spectrum classification. Our method uses self-supervised training with a\nself-masking approach in natural language processing. Self-supervised learning\nis more conducive to learning the essential information about images compared\nwith supervised methods, and it is more suitable for transfer learning. First,\nthe method pre-trains using a large amount of other existing data. Then, the\ntrained model is fine-tuned on the solar radio spectrum dataset. Experiments\nshow that the method achieves a classification accuracy similar to that of\nconvolutional neural networks and Transformer networks with supervised\ntraining.",
      "published": "February 06, 2025",
      "categories": [
        "astro-ph.IM",
        "astro-ph.SR"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.03778v1",
      "arxiv_url": "http://arxiv.org/abs/2502.03778v1"
    },
    {
      "title": "Prediction of the Most Fire-Sensitive Point in Building Structures with\n  Differentiable Agents for Thermal Simulators",
      "authors": [
        "Yuan Xinjie",
        "Khalid M. Mosalam"
      ],
      "abstract": "Fire safety is a critical area of research in civil and mechanical\nengineering, particularly in ensuring the structural stability of buildings\nduring fire events. The Most Fire-Sensitive Point (MFSP) in a structure is the\nlocation where a fire would cause the greatest impact on structural stability.\nAccurate prediction of the MFSP is vital for streamlining structural\nassessments and optimizing the design process. This paper presents a novel\nframework for MFSP prediction using a neural network-based approach that\nintegrates fire dynamics and finite element analysis through a differentiable\nagent model. The framework focuses on predicting the Maximum Interstory Drift\nRatio (MIDR), a key indicator of structural performance under fire conditions.\nBy leveraging the differentiable agent model, we efficiently generate labeled\ndata for MFSP and directly train a predictor for this critical metric. To\nachieve this, we generated extensive simulation data encompassing structural\nand fire scenarios and employed graph neural networks to represent the building\nstructures. Transfer learning was applied to optimize the training process, and\nan edge update mechanism was introduced to dynamically adjust edge attributes,\nreflecting property changes under fire conditions. The proposed model was\nrigorously evaluated on simulation data, demonstrating strong performance in\naccurately predicting both MIDR and MFSP, thus advancing fire safety analysis\nfor building structures.",
      "published": "February 05, 2025",
      "categories": [
        "cs.LG"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.03424v1",
      "arxiv_url": "http://arxiv.org/abs/2502.03424v1"
    },
    {
      "title": "DES to HSC: Detecting low surface brightness galaxies in the Abell 194\n  cluster using transfer learning",
      "authors": [
        "H. Thuruthipilly",
        "Junais",
        "J. Koda",
        "A. Pollo",
        "M. Yagi",
        "H. Yamanoi",
        "Y. Komiyama",
        "M. Romano",
        "K. Ma\u0142ek",
        "D. Donevski"
      ],
      "abstract": "Low surface brightness galaxies (LSBGs) are important for understanding\ngalaxy evolution and cosmological models. The upcoming large-scale surveys are\nexpected to uncover a large number of LSBGs, requiring accurate automated or\nmachine learning-based methods for their detection. We study the scope of\ntransfer learning for the identification of LSBGs. We use transformer models\ndivided into two categories: LSBG Detection Transformer (LSBG DETR) and LSBG\nVision Transformer (LSBG ViT), trained on Dark Energy Survey (DES) data, to\nidentify LSBGs from dedicated Hyper Suprime-Cam (HSC) observations of the Abell\n194 cluster, which are two magnitudes deeper than DES. The data from DES and\nHSC were standardized based on pixel-level surface brightness. We used two\ntransformer ensembles to detect LSBGs. This was followed by a single-component\nS\\'ersic model fit and a final visual inspection to filter out potential false\npositives and improve sample purity. We present a sample of 171 low surface\nbrightness galaxies (LSBGs) in the Abell 194 cluster using HSC data, including\n87 new discoveries. Of these, 159 were identified using transformer models, and\n12 additional LSBGs were found through visual inspection. The transformer model\nachieved a true positive rate (TPR) of 93% in HSC data without any fine-tuning.\nAmong the LSBGs, 28 were classified as ultra-diffuse galaxies (UDGs). The\nnumber of UDGs and the radial UDG number density suggest a linear relationship\nbetween UDG numbers and cluster mass on a log scale. UDGs share similar\nS\\'ersic parameters with dwarf galaxies and occupy the extended end of the\n$R_{\\mathrm{eff}}-M_g$ plane, suggesting they might be an extended\nsubpopulation of dwarf galaxies. We have demonstrated that transformer models\ntrained on shallower surveys can be successfully applied to deeper surveys with\nappropriate data normalization.",
      "published": "February 05, 2025",
      "categories": [
        "astro-ph.GA"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.03142v1",
      "arxiv_url": "http://arxiv.org/abs/2502.03142v1"
    },
    {
      "title": "Transferring Graph Neural Networks for Soft Sensor Modeling using\n  Process Topologies",
      "authors": [
        "Maximilian F. Theisen",
        "Gabrie M. H. Meesters",
        "Artur M. Schweidtmann"
      ],
      "abstract": "Data-driven soft sensors help in process operations by providing real-time\nestimates of otherwise hard- to-measure process quantities, e.g., viscosities\nor product concentrations. Currently, soft sensors need to be developed\nindividually per plant. Using transfer learning, machine learning-based soft\nsensors could be reused and fine-tuned across plants and applications. However,\ntransferring data-driven soft sensor models is in practice often not possible,\nbecause the fixed input structure of standard soft sensor models prohibits\ntransfer if, e.g., the sensor information is not identical in all plants. We\npropose a topology-aware graph neural network approach for transfer learning of\nsoft sensor models across multiple plants. In our method, plants are modeled as\ngraphs: Unit operations are nodes, streams are edges, and sensors are embedded\nas attributes. Our approach brings two advantages for transfer learning: First,\nwe not only include sensor data but also crucial information on the plant\ntopology. Second, the graph neural network algorithm is flexible with respect\nto its sensor inputs. This allows us to model data from different plants with\ndifferent sensor networks. We test the transfer learning capabilities of our\nmodeling approach on ammonia synthesis loops with different process topologies.\nWe build a soft sensor predicting the ammonia concentration in the product.\nAfter training on data from one process, we successfully transfer our soft\nsensor model to a previously unseen process with a different topology. Our\napproach promises to extend the data-driven soft sensors to cases to leverage\ndata from multiple plants.",
      "published": "February 05, 2025",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.06826v1",
      "arxiv_url": "http://arxiv.org/abs/2502.06826v1"
    },
    {
      "title": "Cross-Lingual Transfer for Low-Resource Natural Language Processing",
      "authors": [
        "Iker Garc\u00eda-Ferrero"
      ],
      "abstract": "Natural Language Processing (NLP) has seen remarkable advances in recent\nyears, particularly with the emergence of Large Language Models that have\nachieved unprecedented performance across many tasks. However, these\ndevelopments have mainly benefited a small number of high-resource languages\nsuch as English. The majority of languages still face significant challenges\ndue to the scarcity of training data and computational resources. To address\nthis issue, this thesis focuses on cross-lingual transfer learning, a research\narea aimed at leveraging data and models from high-resource languages to\nimprove NLP performance for low-resource languages. Specifically, we focus on\nSequence Labeling tasks such as Named Entity Recognition, Opinion Target\nExtraction, and Argument Mining.\n  The research is structured around three main objectives: (1) advancing\ndata-based cross-lingual transfer learning methods through improved translation\nand annotation projection techniques, (2) developing enhanced model-based\ntransfer learning approaches utilizing state-of-the-art multilingual models,\nand (3) applying these methods to real-world problems while creating\nopen-source resources that facilitate future research in low-resource NLP.\n  More specifically, this thesis presents a new method to improve data-based\ntransfer with T-Projection, a state-of-the-art annotation projection method\nthat leverages text-to-text multilingual models and machine translation\nsystems. T-Projection significantly outperforms previous annotation projection\nmethods by a wide margin. For model-based transfer, we introduce a constrained\ndecoding algorithm that enhances cross-lingual Sequence Labeling in zero-shot\nsettings using text-to-text models. Finally, we develop Medical mT5, the first\nmultilingual text-to-text medical model, demonstrating the practical impact of\nour research on real-world applications.",
      "published": "February 04, 2025",
      "categories": [
        "cs.CL"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.02722v1",
      "arxiv_url": "http://arxiv.org/abs/2502.02722v1"
    },
    {
      "title": "Beyond English: Evaluating Automated Measurement of Moral Foundations in\n  Non-English Discourse with a Chinese Case Study",
      "authors": [
        "Calvin Yixiang Cheng",
        "Scott A Hale"
      ],
      "abstract": "This study explores computational approaches for measuring moral foundations\n(MFs) in non-English corpora. Since most resources are developed primarily for\nEnglish, cross-linguistic applications of moral foundation theory remain\nlimited. Using Chinese as a case study, this paper evaluates the effectiveness\nof applying English resources to machine translated text, local language\nlexicons, multilingual language models, and large language models (LLMs) in\nmeasuring MFs in non-English texts. The results indicate that machine\ntranslation and local lexicon approaches are insufficient for complex moral\nassessments, frequently resulting in a substantial loss of cultural\ninformation. In contrast, multilingual models and LLMs demonstrate reliable\ncross-language performance with transfer learning, with LLMs excelling in terms\nof data efficiency. Importantly, this study also underscores the need for\nhuman-in-the-loop validation of automated MF assessment, as the most advanced\nmodels may overlook cultural nuances in cross-language measurements. The\nfindings highlight the potential of LLMs for cross-language MF measurements and\nother complex multilingual deductive coding tasks.",
      "published": "February 04, 2025",
      "categories": [
        "cs.CL",
        "cs.SI"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.02451v2",
      "arxiv_url": "http://arxiv.org/abs/2502.02451v2"
    },
    {
      "title": "Self-Supervised Convolutional Audio Models are Flexible Acoustic Feature\n  Learners: A Domain Specificity and Transfer-Learning Study",
      "authors": [
        "Mattson Ogg"
      ],
      "abstract": "Self-supervised learning (SSL) algorithms have emerged as powerful tools that\ncan leverage large quantities of unlabeled audio data to pre-train robust\nrepresentations that support strong performance on diverse downstream tasks. Up\nto now these have mostly been developed separately for speech and non-speech\napplications. Here, we explored the domain specificity of a convolutional\nmodel's pre-training data relative to different downstream speech and\nnon-speech tasks using a self-supervised pre-training approach (BYOL-A). We\nfound that these pre-trained models (regardless of whether they were\npre-trained on speech data, non-speech data or both) enabled good performance\non nearly all downstream tasks, beating or nearly matching the performance of\npopular domain-specific models. Only small domain-specificity advantages were\nobserved between the different pre-training datasets. The popular\ndomain-specific models used as baselines performed very well in their target\ndomains, but generally faltered outside of them. Together, these results\ndemonstrate that SSL methods can be a powerful way to learn flexible\nrepresentations for domain specific data without labels. These models can be a\npowerful resource for later transfer learning, fine-tuning or data exploration\napplications when the downstream data are similar, but also perhaps when there\nmay be a domain mismatch.",
      "published": "February 04, 2025",
      "categories": [
        "eess.AS"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.02366v1",
      "arxiv_url": "http://arxiv.org/abs/2502.02366v1"
    },
    {
      "title": "Transfer Risk Map: Mitigating Pixel-level Negative Transfer in Medical\n  Segmentation",
      "authors": [
        "Shutong Duan",
        "Jingyun Yang",
        "Yang Tan",
        "Guoqing Zhang",
        "Yang Li",
        "Xiao-Ping Zhang"
      ],
      "abstract": "How to mitigate negative transfer in transfer learning is a long-standing and\nchallenging issue, especially in the application of medical image segmentation.\nExisting methods for reducing negative transfer focus on classification or\nregression tasks, ignoring the non-uniform negative transfer risk in different\nimage regions. In this work, we propose a simple yet effective weighted\nfine-tuning method that directs the model's attention towards regions with\nsignificant transfer risk for medical semantic segmentation. Specifically, we\ncompute a transferability-guided transfer risk map to quantify the transfer\nhardness for each pixel and the potential risks of negative transfer. During\nthe fine-tuning phase, we introduce a map-weighted loss function, normalized\nwith image foreground size to counter class imbalance. Extensive experiments on\nbrain segmentation datasets show our method significantly improves the target\ntask performance, with gains of 4.37% on FeTS2021 and 1.81% on iSeg2019,\navoiding negative transfer across modalities and tasks. Meanwhile, a 2.9% gain\nunder a few-shot scenario validates the robustness of our approach.",
      "published": "February 04, 2025",
      "categories": [
        "cs.CV"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.02340v1",
      "arxiv_url": "http://arxiv.org/abs/2502.02340v1"
    },
    {
      "title": "Distributionally Robust Direct Preference Optimization",
      "authors": [
        "Zaiyan Xu",
        "Sushil Vemuri",
        "Kishan Panaganti",
        "Dileep Kalathil",
        "Rahul Jain",
        "Deepak Ramachandran"
      ],
      "abstract": "A major challenge in aligning large language models (LLMs) with human\npreferences is the issue of distribution shift. LLM alignment algorithms rely\non static preference datasets, assuming that they accurately represent\nreal-world user preferences. However, user preferences vary significantly\nacross geographical regions, demographics, linguistic patterns, and evolving\ncultural trends. This preference distribution shift leads to catastrophic\nalignment failures in many real-world applications. We address this problem\nusing the principled framework of distributionally robust optimization, and\ndevelop two novel distributionally robust direct preference optimization (DPO)\nalgorithms, namely, Wasserstein DPO (WDPO) and Kullback-Leibler DPO (KLDPO). We\ncharacterize the sample complexity of learning the optimal policy parameters\nfor WDPO and KLDPO. Moreover, we propose scalable gradient descent-style\nlearning algorithms by developing suitable approximations for the challenging\nminimax loss functions of WDPO and KLDPO. Our empirical experiments demonstrate\nthe superior performance of WDPO and KLDPO in substantially improving the\nalignment when there is a preference distribution shift.",
      "published": "February 04, 2025",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.01930v1",
      "arxiv_url": "http://arxiv.org/abs/2502.01930v1"
    },
    {
      "title": "Geometric Framework for 3D Cell Segmentation Correction",
      "authors": [
        "Peter Chen",
        "Bryan Chang",
        "Olivia Annette Creasey",
        "Julie Beth Sneddon",
        "Yining Liu"
      ],
      "abstract": "3D cellular image segmentation methods are commonly divided into non-2D-based\nand 2D-based approaches, the latter reconstructing 3D shapes from the\nsegmentation results of 2D layers. However, errors in 2D results often\npropagate, leading to oversegmentations in the final 3D results. To tackle this\nissue, we introduce an interpretable geometric framework that addresses the\noversegmentations by correcting the 2D segmentation results based on geometric\ninformation from adjacent layers. Leveraging both geometric (layer-to-layer,\n2D) and topological (3D shape) features, we use binary classification to\ndetermine whether neighboring cells should be stitched. We develop a\npre-trained classifier on public plant cell datasets and validate its\nperformance on animal cell datasets, confirming its effectiveness in correcting\noversegmentations under the transfer learning setting. Furthermore, we\ndemonstrate that our framework can be extended to correcting oversegmentation\non non-2D-based methods. A clear pipeline is provided for end-users to build\nthe pre-trained model to any labeled dataset.",
      "published": "February 03, 2025",
      "categories": [
        "cs.CV",
        "cs.LG"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.01890v1",
      "arxiv_url": "http://arxiv.org/abs/2502.01890v1"
    },
    {
      "title": "Learning Hyperparameters via a Data-Emphasized Variational Objective",
      "authors": [
        "Ethan Harvey",
        "Mikhail Petrov",
        "Michael C. Hughes"
      ],
      "abstract": "When training large flexible models, practitioners often rely on grid search\nto select hyperparameters that control over-fitting. This grid search has\nseveral disadvantages: the search is computationally expensive, requires\ncarving out a validation set that reduces the available data for training, and\nrequires users to specify candidate values. In this paper, we propose an\nalternative: directly learning regularization hyperparameters on the full\ntraining set via the evidence lower bound (\"ELBo\") objective from variational\nmethods. For deep neural networks with millions of parameters, we recommend a\nmodified ELBo that upweights the influence of the data likelihood relative to\nthe prior. Our proposed technique overcomes all three disadvantages of grid\nsearch. In a case study on transfer learning of image classifiers, we show how\nour method reduces the 88+ hour grid search of past work to under 3 hours while\ndelivering comparable accuracy. We further demonstrate how our approach enables\nefficient yet accurate approximations of Gaussian processes with learnable\nlength-scale kernels.",
      "published": "February 03, 2025",
      "categories": [
        "cs.LG",
        "stat.ML"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.01861v1",
      "arxiv_url": "http://arxiv.org/abs/2502.01861v1"
    },
    {
      "title": "CTC-DRO: Robust Optimization for Reducing Language Disparities in Speech\n  Recognition",
      "authors": [
        "Martijn Bartelds",
        "Ananjan Nandi",
        "Moussa Koulako Bala Doumbouya",
        "Dan Jurafsky",
        "Tatsunori Hashimoto",
        "Karen Livescu"
      ],
      "abstract": "Modern deep learning models often achieve high overall performance, but\nconsistently fail on specific subgroups. Group distributionally robust\noptimization (group DRO) addresses this problem by minimizing the worst-group\nloss, but it fails when group losses misrepresent performance differences\nbetween groups. This is common in domains like speech, where the widely used\nconnectionist temporal classification (CTC) loss scales with input length and\nvaries with linguistic and acoustic properties, leading to spurious differences\nbetween group losses. We present CTC-DRO, which addresses the shortcomings of\nthe group DRO objective by smoothing the group weight update to prevent\noveremphasis on consistently high-loss groups, while using input length-matched\nbatching to mitigate CTC's scaling issues. We evaluate CTC-DRO on the task of\nmultilingual automatic speech recognition (ASR) across five language sets from\nthe ML-SUPERB 2.0 benchmark. CTC-DRO consistently outperforms group DRO and\nCTC-based baseline models, reducing the worst-language error by up to 65.9% and\nthe average error by up to 47.7%. CTC-DRO can be applied to ASR with minimal\ncomputational costs, and offers the potential for reducing group disparities in\nother domains with similar challenges.",
      "published": "February 03, 2025",
      "categories": [
        "cs.LG",
        "cs.CL",
        "eess.AS"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.01777v1",
      "arxiv_url": "http://arxiv.org/abs/2502.01777v1"
    },
    {
      "title": "Grokking Explained: A Statistical Phenomenon",
      "authors": [
        "Breno W. Carvalho",
        "Artur S. d'Avila Garcez",
        "Lu\u00eds C. Lamb",
        "Em\u00edlio Vital Brazil"
      ],
      "abstract": "Grokking, or delayed generalization, is an intriguing learning phenomenon\nwhere test set loss decreases sharply only after a model's training set loss\nhas converged. This challenges conventional understanding of the training\ndynamics in deep learning networks. In this paper, we formalize and investigate\ngrokking, highlighting that a key factor in its emergence is a distribution\nshift between training and test data. We introduce two synthetic datasets\nspecifically designed to analyze grokking. One dataset examines the impact of\nlimited sampling, and the other investigates transfer learning's role in\ngrokking. By inducing distribution shifts through controlled imbalanced\nsampling of sub-categories, we systematically reproduce the phenomenon,\ndemonstrating that while small-sampling is strongly associated with grokking,\nit is not its cause. Instead, small-sampling serves as a convenient mechanism\nfor achieving the necessary distribution shift. We also show that when classes\nform an equivariant map, grokking can be explained by the model's ability to\nlearn from similar classes or sub-categories. Unlike earlier work suggesting\nthat grokking primarily arises from high regularization and sparse data, we\ndemonstrate that it can also occur with dense data and minimal hyper-parameter\ntuning. Our findings deepen the understanding of grokking and pave the way for\ndeveloping better stopping criteria in future training processes.",
      "published": "February 03, 2025",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.01774v1",
      "arxiv_url": "http://arxiv.org/abs/2502.01774v1"
    },
    {
      "title": "Towards Robust and Generalizable Lensless Imaging with Modular Learned\n  Reconstruction",
      "authors": [
        "Eric Bezzam",
        "Yohann Perron",
        "Martin Vetterli"
      ],
      "abstract": "Lensless cameras disregard the conventional design that imaging should mimic\nthe human eye. This is done by replacing the lens with a thin mask, and moving\nimage formation to the digital post-processing. State-of-the-art lensless\nimaging techniques use learned approaches that combine physical modeling and\nneural networks. However, these approaches make simplifying modeling\nassumptions for ease of calibration and computation. Moreover, the\ngeneralizability of learned approaches to lensless measurements of new masks\nhas not been studied. To this end, we utilize a modular learned reconstruction\nin which a key component is a pre-processor prior to image recovery. We\ntheoretically demonstrate the pre-processor's necessity for standard image\nrecovery techniques (Wiener filtering and iterative algorithms), and through\nextensive experiments show its effectiveness for multiple lensless imaging\napproaches and across datasets of different mask types (amplitude and phase).\nWe also perform the first generalization benchmark across mask types to\nevaluate how well reconstructions trained with one system generalize to others.\nOur modular reconstruction enables us to use pre-trained components and\ntransfer learning on new systems to cut down weeks of tedious measurements and\ntraining. As part of our work, we open-source four datasets, and software for\nmeasuring datasets and for training our modular reconstruction.",
      "published": "February 03, 2025",
      "categories": [
        "eess.IV",
        "cs.CV"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.01102v1",
      "arxiv_url": "http://arxiv.org/abs/2502.01102v1"
    },
    {
      "title": "Fruit Fly Classification (Diptera: Tephritidae) in Images, Applying\n  Transfer Learning",
      "authors": [
        "Erick Andrew Bustamante Flores",
        "Harley Vera Olivera",
        "Ivan Cesar Medrano Valencia",
        "Carlos Fernando Montoya Cubas"
      ],
      "abstract": "This study develops a transfer learning model for the automated\nclassification of two species of fruit flies, Anastrepha fraterculus and\nCeratitis capitata, in a controlled laboratory environment. The research\naddresses the need to optimize identification and classification, which are\ncurrently performed manually by experts, being affected by human factors and\nfacing time challenges. The methodological process of this study includes the\ncapture of high-quality images using a mobile phone camera and a stereo\nmicroscope, followed by segmentation to reduce size and focus on relevant\nmorphological areas. The images were carefully labeled and preprocessed to\nensure the quality and consistency of the dataset used to train the pre-trained\nconvolutional neural network models VGG16, VGG19, and Inception-v3. The results\nwere evaluated using the F1-score, achieving 82% for VGG16 and VGG19, while\nInception-v3 reached an F1-score of 93%. Inception-v3's reliability was\nverified through model testing in uncontrolled environments, with positive\nresults, complemented by the Grad-CAM technique, demonstrating its ability to\ncapture essential morphological features. These findings indicate that\nInception-v3 is an effective and replicable approach for classifying Anastrepha\nfraterculus and Ceratitis capitata, with potential for implementation in\nautomated monitoring systems.",
      "published": "February 02, 2025",
      "categories": [
        "cs.CV",
        "cs.AI",
        "68T10",
        "I.2.10"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.00939v1",
      "arxiv_url": "http://arxiv.org/abs/2502.00939v1"
    }
  ]
}