{
  "timestamp": 1756516598,
  "papers": [
    {
      "title": "Transfer Learning for Classification under Decision Rule Drift with\n  Application to Optimal Individualized Treatment Rule Estimation",
      "authors": [
        "Xiaohan Wang",
        "Yang Ning"
      ],
      "abstract": "In this paper, we extend the transfer learning classification framework from\nregression function-based methods to decision rules. We propose a novel\nmethodology for modeling posterior drift through Bayes decision rules. By\nexploiting the geometric transformation of the Bayes decision boundary, our\nmethod reformulates the problem as a low-dimensional empirical risk\nminimization problem. Under mild regularity conditions, we establish the\nconsistency of our estimators and derive the risk bounds. Moreover, we\nillustrate the broad applicability of our method by adapting it to the\nestimation of optimal individualized treatment rules. Extensive simulation\nstudies and analyses of real-world data further demonstrate both superior\nperformance and robustness of our approach.",
      "published": "August 28, 2025",
      "categories": [
        "stat.ML",
        "cs.LG",
        "math.ST",
        "stat.ME",
        "stat.TH"
      ],
      "pdf_link": "http://arxiv.org/pdf/2508.20942v1",
      "arxiv_url": "http://arxiv.org/abs/2508.20942v1"
    },
    {
      "title": "A nonstationary spatial model of PM2.5 with localized transfer learning\n  from numerical model output",
      "authors": [
        "Wenlong Gong",
        "Brian J. Reich",
        "Joseph Guinness"
      ],
      "abstract": "Ambient air pollution measurements from regulatory monitoring networks are\nroutinely used to support epidemiologic studies and environmental policy\ndecision making. However, regulatory monitors are spatially sparse and\npreferentially located in areas with large populations. Numerical air pollution\nmodel output can be leveraged into the inference and prediction of air\npollution data combining with measurements from monitors. Nonstationary\ncovariance functions allow the model to adapt to spatial surfaces whose\nvariability changes with location like air pollution data. In the paper, we\nemploy localized covariance parameters learned from the numerical output model\nto knit together into a global nonstationary covariance, to incorporate in a\nfully Bayesian model. We model the nonstationary structure in a computationally\nefficient way to make the Bayesian model scalable.",
      "published": "August 21, 2025",
      "categories": [
        "stat.AP",
        "stat.CO",
        "stat.ME"
      ],
      "pdf_link": "http://arxiv.org/pdf/2508.15978v1",
      "arxiv_url": "http://arxiv.org/abs/2508.15978v1"
    },
    {
      "title": "Diffusion-Driven High-Dimensional Variable Selection",
      "authors": [
        "Minjie Wang",
        "Xiaotong Shen",
        "Wei Pan"
      ],
      "abstract": "Variable selection for high-dimensional, highly correlated data has long been\na challenging problem, often yielding unstable and unreliable models. We\npropose a resample-aggregate framework that exploits diffusion models' ability\nto generate high-fidelity synthetic data. Specifically, we draw multiple\npseudo-data sets from a diffusion model fitted to the original data, apply any\noff-the-shelf selector (e.g., lasso or SCAD), and store the resulting inclusion\nindicators and coefficients. Aggregating across replicas produces a stable\nsubset of predictors with calibrated stability scores for variable selection.\nTheoretically, we show that the proposed method is selection consistent under\nmild assumptions. Because the generative model imports knowledge from large\npre-trained weights, the procedure naturally benefits from transfer learning,\nboosting power when the observed sample is small or noisy. We also extend the\nframework of aggregating synthetic data to other model selection problems,\nincluding graphical model selection, and statistical inference that supports\nvalid confidence intervals and hypothesis tests. Extensive simulations show\nconsistent gains over the lasso, stability selection, and knockoff baselines,\nespecially when predictors are strongly correlated, achieving higher\ntrue-positive rates and lower false-discovery proportions. By coupling\ndiffusion-based data augmentation with principled aggregation, our method\nadvances variable selection methodology and broadens the toolkit for\ninterpretable, statistically rigorous analysis in complex scientific\napplications.",
      "published": "August 19, 2025",
      "categories": [
        "stat.ME",
        "stat.ML"
      ],
      "pdf_link": "http://arxiv.org/pdf/2508.13890v1",
      "arxiv_url": "http://arxiv.org/abs/2508.13890v1"
    },
    {
      "title": "Robust Data Fusion via Subsampling",
      "authors": [
        "Jing Wang",
        "HaiYing Wang",
        "Kun Chen"
      ],
      "abstract": "Data fusion and transfer learning are rapidly growing fields that enhance\nmodel performance for a target population by leveraging other related data\nsources or tasks. The challenges lie in the various potential heterogeneities\nbetween the target and external data, as well as various practical concerns\nthat prevent a na\\\"ive data integration. We consider a realistic scenario where\nthe target data is limited in size while the external data is large but\ncontaminated with outliers; such data contamination, along with other\ncomputational and operational constraints, necessitates proper selection or\nsubsampling of the external data for transfer learning. To our\nknowledge,transfer learning and subsampling under data contamination have not\nbeen thoroughly investigated. We address this gap by studying various transfer\nlearning methods with subsamples of the external data, accounting for outliers\ndeviating from the underlying true model due to arbitrary mean shifts. Two\nsubsampling strategies are investigated: one aimed at reducing biases and the\nother at minimizing variances. Approaches to combine these strategies are also\nintroduced to enhance the performance of the estimators. We provide\nnon-asymptotic error bounds for the transfer learning estimators, clarifying\nthe roles of sample sizes, signal strength, sampling rates, magnitude of\noutliers, and tail behaviors of model error distributions, among other factors.\nExtensive simulations show the superior performance of the proposed methods.\nAdditionally, we apply our methods to analyze the risk of hard landings in A380\nairplanes by utilizing data from other airplane types,demonstrating that robust\ntransfer learning can improve estimation efficiency for relatively rare\nairplane types with the help of data from other types of airplanes.",
      "published": "August 16, 2025",
      "categories": [
        "stat.ML",
        "cs.LG",
        "62K05"
      ],
      "pdf_link": "http://arxiv.org/pdf/2508.12048v1",
      "arxiv_url": "http://arxiv.org/abs/2508.12048v1"
    },
    {
      "title": "Deconfounding via Profiled Transfer Learning",
      "authors": [
        "Ziyuan Chen",
        "Yifan Jiang",
        "Jingyuan Liu",
        "Fang Yao"
      ],
      "abstract": "Unmeasured confounders are a major source of bias in regression-based effect\nestimation and causal inference. In this paper, we advocate a new profiled\ntransfer learning framework, ProTrans, to address confounding effects in the\ntarget dataset, when additional source datasets that possess similar\nconfounding structures are available. We introduce the concept of profiled\nresiduals to characterize the shared confounding patterns between source and\ntarget datasets. By incorporating these profiled residuals into the target\ndebiasing step, we effectively mitigates the latent confounding effects. We\nalso propose a source selection strategy to enhance robustness of ProTrans\nagainst noninformative sources. As a byproduct, ProTrans can also be utilized\nto estimate treatment effects when potential confounders exist, without the use\nof auxiliary features such as instrumental or proxy variables, which are often\nchallenging to select in practice. Theoretically, we prove that the resulting\nestimated model shift from sources to target is confounding-free without any\nassumptions imposed on the true confounding structure, and that the target\nparameter estimation achieves the minimax optimal rate under mild conditions.\nSimulated and real-world experiments validate the effectiveness of ProTrans and\nsupport the theoretical findings.",
      "published": "August 15, 2025",
      "categories": [
        "stat.ME"
      ],
      "pdf_link": "http://arxiv.org/pdf/2508.11622v1",
      "arxiv_url": "http://arxiv.org/abs/2508.11622v1"
    },
    {
      "title": "Holistic Bioprocess Development Across Scales Using Multi-Fidelity Batch\n  Bayesian Optimization",
      "authors": [
        "Adrian Martens",
        "Mathias Neufang",
        "Alessandro Butt\u00e9",
        "Moritz von Stosch",
        "Antonio del Rio Chanona",
        "Laura Marie Helleckes"
      ],
      "abstract": "Bioprocesses are central to modern biotechnology, enabling sustainable\nproduction in pharmaceuticals, specialty chemicals, cosmetics, and food.\nHowever, developing high-performing processes is costly and complex, requiring\niterative, multi-scale experimentation from microtiter plates to pilot\nreactors. Conventional Design of Experiments (DoE) approaches often struggle to\naddress process scale-up and the joint optimization of reaction conditions and\nbiocatalyst selection.\n  We propose a multi-fidelity batch Bayesian optimization framework to\naccelerate bioprocess development and reduce experimental costs. The method\nintegrates Gaussian Processes tailored for multi-fidelity modeling and\nmixed-variable optimization, guiding experiment selection across scales and\nbiocatalysts. A custom simulation of a Chinese Hamster Ovary bioprocess,\ncapturing non-linear and coupled scale-up dynamics, is used for benchmarking\nagainst multiple simulated industrial DoE baselines. Multiple case studies show\nhow the proposed workflow can achieve a reduction in experimental costs and\nincreased yield.\n  This work provides a data-efficient strategy for bioprocess optimization and\nhighlights future opportunities in transfer learning and uncertainty-aware\ndesign for sustainable biotechnology.",
      "published": "August 14, 2025",
      "categories": [
        "q-bio.QM",
        "stat.ML"
      ],
      "pdf_link": "http://arxiv.org/pdf/2508.10970v1",
      "arxiv_url": "http://arxiv.org/abs/2508.10970v1"
    }
  ]
}