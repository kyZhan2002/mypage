{
  "timestamp": 1763429073,
  "papers": [
    {
      "title": "Heterogeneous Multisource Transfer Learning via Model Averaging for Positive-Unlabeled Data",
      "authors": [
        "Jialei Liu",
        "Jun Liao",
        "Kuangnan Fang"
      ],
      "abstract": "Positive-Unlabeled (PU) learning presents unique challenges due to the lack of explicitly labeled negative samples, particularly in high-stakes domains such as fraud detection and medical diagnosis. To address data scarcity and privacy constraints, we propose a novel transfer learning with model averaging framework that integrates information from heterogeneous data sources - including fully binary labeled, semi-supervised, and PU data sets - without direct data sharing. For each source domain type, a tailored logistic regression model is conducted, and knowledge is transferred to the PU target domain through model averaging. Optimal weights for combining source models are determined via a cross-validation criterion that minimizes the Kullback-Leibler divergence. We establish theoretical guarantees for weight optimality and convergence, covering both misspecified and correctly specified target models, with further extensions to high-dimensional settings using sparsity-penalized estimators. Extensive simulations and real-world credit risk data analyses demonstrate that our method outperforms other comparative methods in terms of predictive accuracy and robustness, especially under limited labeled data and heterogeneous environments.",
      "published": "November 14, 2025",
      "categories": [
        "stat.ML",
        "cs.LG"
      ],
      "pdf_link": "https://arxiv.org/pdf/2511.10919v1",
      "arxiv_url": "https://arxiv.org/abs/2511.10919v1"
    },
    {
      "title": "Reluctant Transfer Learning in Penalized Regressions for Individualized Treatment Rules under Effect Heterogeneity",
      "authors": [
        "Eun Jeong Oh",
        "Min Qian"
      ],
      "abstract": "Estimating individualized treatment rules (ITRs) is fundamental to precision medicine, where the goal is to tailor treatment decisions to individual patient characteristics. While numerous methods have been developed for ITR estimation, there is limited research on model updating that accounts for shifted treatment-covariate relationships in the ITR setting. In real-world practice, models trained on source data must be updated for new (target) datasets that exhibit shifts in treatment effects. To address this challenge, we propose a Reluctant Transfer Learning (RTL) framework that enables efficient model adaptation by selectively transferring essential model components (e.g., regression coefficients) from source to target data, without requiring access to individual-level source data. Leveraging the principle of reluctant modeling, the RTL approach incorporates model adjustments only when they improve performance on the target dataset, thereby controlling complexity and enhancing generalizability. Our method supports multi-armed treatment settings, performs variable selection for interpretability, and provides theoretical guarantees for the value convergence. Through simulation studies and an application to a real data example from the Best Apnea Interventions for Research (BestAIR) trial, we demonstrate that RTL outperforms existing alternatives. The proposed framework offers an efficient, practically feasible approach to adaptive treatment decision-making under evolving treatment effect conditions.",
      "published": "November 11, 2025",
      "categories": [
        "stat.ME"
      ],
      "pdf_link": "https://arxiv.org/pdf/2511.08559v1",
      "arxiv_url": "https://arxiv.org/abs/2511.08559v1"
    },
    {
      "title": "Source-Optimal Training is Transfer-Suboptimal",
      "authors": [
        "C. Evans Hedges"
      ],
      "abstract": "We prove a fundamental misalignment in transfer learning: the source regularization that minimizes source risk almost never coincides with the regularization maximizing transfer benefit. Through sharp phase boundaries for L2-SP ridge regression, we characterize the transfer-optimal source penalty $\u03c4_0^*$ and show it diverges predictably from task-optimal values, requiring stronger regularization in high-SNR regimes and weaker regularization in low-SNR regimes. Additionally, in isotropic settings the decision to transfer is remarkably independent of target sample size and noise, depending only on task alignment and source characteristics. CIFAR-10 and MNIST experiments confirm this counterintuitive pattern persists in non-linear networks.",
      "published": "November 11, 2025",
      "categories": [
        "stat.ML",
        "cs.LG",
        "math.ST"
      ],
      "pdf_link": "https://arxiv.org/pdf/2511.08401v1",
      "arxiv_url": "https://arxiv.org/abs/2511.08401v1"
    }
  ]
}