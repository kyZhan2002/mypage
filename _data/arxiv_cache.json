{
  "timestamp": 1753407700,
  "papers": [
    {
      "title": "On the Interaction of Compressibility and Adversarial Robustness",
      "authors": [
        "Melih Barsbey",
        "Ant\u00f4nio H. Ribeiro",
        "Umut \u015eim\u015fekli",
        "Tolga Birdal"
      ],
      "abstract": "Modern neural networks are expected to simultaneously satisfy a host of\ndesirable properties: accurate fitting to training data, generalization to\nunseen inputs, parameter and computational efficiency, and robustness to\nadversarial perturbations. While compressibility and robustness have each been\nstudied extensively, a unified understanding of their interaction still remains\nelusive. In this work, we develop a principled framework to analyze how\ndifferent forms of compressibility - such as neuron-level sparsity and spectral\ncompressibility - affect adversarial robustness. We show that these forms of\ncompression can induce a small number of highly sensitive directions in the\nrepresentation space, which adversaries can exploit to construct effective\nperturbations. Our analysis yields a simple yet instructive robustness bound,\nrevealing how neuron and spectral compressibility impact $L_\\infty$ and $L_2$\nrobustness via their effects on the learned representations. Crucially, the\nvulnerabilities we identify arise irrespective of how compression is achieved -\nwhether via regularization, architectural bias, or implicit learning dynamics.\nThrough empirical evaluations across synthetic and realistic tasks, we confirm\nour theoretical predictions, and further demonstrate that these vulnerabilities\npersist under adversarial training and transfer learning, and contribute to the\nemergence of universal adversarial perturbations. Our findings show a\nfundamental tension between structured compressibility and robustness, and\nsuggest new pathways for designing models that are both efficient and secure.",
      "published": "July 23, 2025",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "stat.ML"
      ],
      "pdf_link": "http://arxiv.org/pdf/2507.17725v1",
      "arxiv_url": "http://arxiv.org/abs/2507.17725v1"
    },
    {
      "title": "Sufficiency-principled Transfer Learning via Model Averaging",
      "authors": [
        "Xiyuan Zhang",
        "Huihang Liu",
        "Xinyu Zhang"
      ],
      "abstract": "When the transferable set is unknowable, transfering informative knowledge as\nmuch as possible\\textemdash a principle we refer to as \\emph{sufficiency},\nbecomes crucial for enhancing transfer learning effectiveness. However,\nexisting transfer learning methods not only overlook the sufficiency principle,\nbut also rely on restrictive single-similarity assumptions (\\eg individual or\ncombinatorial similarity), leading to suboptimal performance. To address these\nlimitations, we propose a sufficiency-principled transfer learning framework\nvia unified model averaging algorithms, accommodating both individual and\ncombinatorial similarities. Theoretically, we establish the\nasymptotic/high-probability optimality, enhanced convergence rate and\nasymptotic normality for multi-source linear regression models with a diverging\nnumber of parameters, achieving sufficiency, robustness to negative transfer,\nprivacy protection and feasible statistical inference. Extensive simulations\nand an empirical data analysis of Beijing housing rental data demonstrate the\npromising superiority of our framework over conventional alternatives.",
      "published": "July 21, 2025",
      "categories": [
        "stat.ME",
        "math.ST",
        "stat.TH"
      ],
      "pdf_link": "http://arxiv.org/pdf/2507.15416v1",
      "arxiv_url": "http://arxiv.org/abs/2507.15416v1"
    },
    {
      "title": "Parameter-transfer in spatial autoregressive models via model averaging",
      "authors": [
        "Fen Jiang",
        "Wenhui Li",
        "Xinyu Zhang"
      ],
      "abstract": "Econometric modeling in spatial autoregressive models often suffers from\ninsufficient samples in practice, such as spatial analysis of infectious\ndiseases at the country level with limited data. Transfer learning offers a\npromising solution by leveraging information from regions or domains with\nsimilar spatial spillover effects to improve the analysis of the target data.\nIn this paper, we propose a parameter-transfer approach based on Mallows model\naveraging for spatial autoregressive models to improve the prediction accuracy.\nOur approach does not require sharing multi-source spatial data and can be\ncombined with various parameter estimation methods, such as the maximum\nlikelihood and the two-stage least squares. Theoretical analyses demonstrate\nthat our method achieves asymptotic optimality and ensures weight convergence\nwith an explicit convergence rate. Simulation studies and the application of\ninfection count prediction in Africa further demonstrate the effectiveness of\nour approach.",
      "published": "July 19, 2025",
      "categories": [
        "stat.ME"
      ],
      "pdf_link": "http://arxiv.org/pdf/2507.14453v1",
      "arxiv_url": "http://arxiv.org/abs/2507.14453v1"
    },
    {
      "title": "Improving physics-informed neural network extrapolation via transfer\n  learning and adaptive activation functions",
      "authors": [
        "Athanasios Papastathopoulos-Katsaros",
        "Alexandra Stavrianidi",
        "Zhandong Liu"
      ],
      "abstract": "Physics-Informed Neural Networks (PINNs) are deep learning models that\nincorporate the governing physical laws of a system into the learning process,\nmaking them well-suited for solving complex scientific and engineering\nproblems. Recently, PINNs have gained widespread attention as a powerful\nframework for combining physical principles with data-driven modeling to\nimprove prediction accuracy. Despite their successes, however, PINNs often\nexhibit poor extrapolation performance outside the training domain and are\nhighly sensitive to the choice of activation functions (AFs). In this paper, we\nintroduce a transfer learning (TL) method to improve the extrapolation\ncapability of PINNs. Our approach applies transfer learning (TL) within an\nextended training domain, using only a small number of carefully selected\ncollocation points. Additionally, we propose an adaptive AF that takes the form\nof a linear combination of standard AFs, which improves both the robustness and\naccuracy of the model. Through a series of experiments, we demonstrate that our\nmethod achieves an average of 40% reduction in relative L2 error and an average\nof 50% reduction in mean absolute error in the extrapolation domain, all\nwithout a significant increase in computational cost. The code is available at\nhttps://github.com/LiuzLab/PINN-extrapolation .",
      "published": "July 16, 2025",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NA",
        "math.DS",
        "math.NA",
        "stat.ML"
      ],
      "pdf_link": "http://arxiv.org/pdf/2507.12659v1",
      "arxiv_url": "http://arxiv.org/abs/2507.12659v1"
    },
    {
      "title": "Statistical Inference for Conditional Group Distributionally Robust\n  Optimization with Cross-Entropy Loss",
      "authors": [
        "Zijian Guo",
        "Zhenyu Wang",
        "Yifan Hu",
        "Francis Bach"
      ],
      "abstract": "In multi-source learning with discrete labels, distributional heterogeneity\nacross domains poses a central challenge to developing predictive models that\ntransfer reliably to unseen domains. We study multi-source unsupervised domain\nadaptation, where labeled data are drawn from multiple source domains and only\nunlabeled data from a target domain. To address potential distribution shifts,\nwe propose a novel Conditional Group Distributionally Robust Optimization\n(CG-DRO) framework that learns a classifier by minimizing the worst-case\ncross-entropy loss over the convex combinations of the conditional outcome\ndistributions from the sources. To solve the resulting minimax problem, we\ndevelop an efficient Mirror Prox algorithm, where we employ a double machine\nlearning procedure to estimate the risk function. This ensures that the errors\nof the machine learning estimators for the nuisance models enter only at\nhigher-order rates, thereby preserving statistical efficiency under covariate\nshift. We establish fast statistical convergence rates for the estimator by\nconstructing two surrogate minimax optimization problems that serve as\ntheoretical bridges. A distinguishing challenge for CG-DRO is the emergence of\nnonstandard asymptotics: the empirical estimator may fail to converge to a\nstandard limiting distribution due to boundary effects and system instability.\nTo address this, we introduce a perturbation-based inference procedure that\nenables uniformly valid inference, including confidence interval construction\nand hypothesis testing.",
      "published": "July 14, 2025",
      "categories": [
        "stat.ME",
        "math.OC",
        "math.ST",
        "stat.ML",
        "stat.TH"
      ],
      "pdf_link": "http://arxiv.org/pdf/2507.09905v1",
      "arxiv_url": "http://arxiv.org/abs/2507.09905v1"
    },
    {
      "title": "The Bayesian Approach to Continual Learning: An Overview",
      "authors": [
        "Tameem Adel"
      ],
      "abstract": "Continual learning is an online paradigm where a learner continually\naccumulates knowledge from different tasks encountered over sequential time\nsteps. Importantly, the learner is required to extend and update its knowledge\nwithout forgetting about the learning experience acquired from the past, and\nwhile avoiding the need to retrain from scratch. Given its sequential nature\nand its resemblance to the way humans think, continual learning offers an\nopportunity to address several challenges which currently stand in the way of\nwidening the range of applicability of deep models to further real-world\nproblems. The continual need to update the learner with data arriving\nsequentially strikes inherent congruence between continual learning and\nBayesian inference which provides a principal platform to keep updating the\nprior beliefs of a model given new data, without completely forgetting the\nknowledge acquired from the old data. This survey inspects different settings\nof Bayesian continual learning, namely task-incremental learning and\nclass-incremental learning. We begin by discussing definitions of continual\nlearning along with its Bayesian setting, as well as the links with related\nfields, such as domain adaptation, transfer learning and meta-learning.\nAfterwards, we introduce a taxonomy offering a comprehensive categorization of\nalgorithms belonging to the Bayesian continual learning paradigm. Meanwhile, we\nanalyze the state-of-the-art while zooming in on some of the most prominent\nBayesian continual learning algorithms to date. Furthermore, we shed some light\non links between continual learning and developmental psychology, and\ncorrespondingly introduce analogies between both fields. We follow that with a\ndiscussion of current challenges, and finally conclude with potential areas for\nfuture research on Bayesian continual learning.",
      "published": "July 11, 2025",
      "categories": [
        "stat.ML",
        "cs.LG"
      ],
      "pdf_link": "http://arxiv.org/pdf/2507.08922v1",
      "arxiv_url": "http://arxiv.org/abs/2507.08922v1"
    }
  ]
}