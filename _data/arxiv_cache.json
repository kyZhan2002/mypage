{
  "timestamp": 1761960443,
  "papers": [
    {
      "title": "Gradient Flow Sampler-based Distributionally Robust Optimization",
      "authors": [
        "Zusen Xu",
        "Jia-Jie Zhu"
      ],
      "abstract": "We propose a mathematically principled PDE gradient flow framework for\ndistributionally robust optimization (DRO). Exploiting the recent advances in\nthe intersection of Markov Chain Monte Carlo sampling and gradient flow theory,\nwe show that our theoretical framework can be implemented as practical\nalgorithms for sampling from worst-case distributions and, consequently, DRO.\nWhile numerous previous works have proposed various reformulation techniques\nand iterative algorithms, we contribute a sound gradient flow view of the\ndistributional optimization that can be used to construct new algorithms. As an\nexample of applications, we solve a class of Wasserstein and Sinkhorn DRO\nproblems using the recently-discovered Wasserstein Fisher-Rao and Stein\nvariational gradient flows. Notably, we also show some simple reductions of our\nframework recover exactly previously proposed popular DRO methods, and provide\nnew insights into their theoretical limit and optimization dynamics. Numerical\nstudies based on stochastic gradient descent provide empirical backing for our\ntheoretical findings.",
      "published": "October 29, 2025",
      "categories": [
        "math.OC",
        "math.AP",
        "stat.ML"
      ],
      "pdf_link": "http://arxiv.org/pdf/2510.25956v1",
      "arxiv_url": "http://arxiv.org/abs/2510.25956v1"
    },
    {
      "title": "Improving time series estimation and prediction via transfer learning",
      "authors": [
        "Yuchang Lin",
        "Qianqian Zhu",
        "Guodong Li"
      ],
      "abstract": "There are many time series in the literature with high dimension yet limited\nsample sizes, such as macroeconomic variables, and it is almost impossible to\nobtain efficient estimation and accurate prediction by using the corresponding\ndatasets themselves. This paper fills the gap by introducing a novel\nrepresentation-based transfer learning framework for vector autoregressive\nmodels, and information from related source datasets with rich observations can\nbe leveraged to enhance estimation efficiency through representation learning.\nA two-stage regularized estimation procedure is proposed with well established\nnon-asymptotic properties, and algorithms with alternating updates are\nsuggested to search for the estimates. Our transfer learning framework can\nhandle time series with varying sample sizes and asynchronous starting and/or\nending time points, thereby offering remarkable flexibility in integrating\ninformation from diverse datasets. Simulation experiments are conducted to\nevaluate the finite-sample performance of the proposed methodology, and its\nusefulness is demonstrated by an empirical analysis on 20 macroeconomic\nvariables from Japan and another nine countries.",
      "published": "October 29, 2025",
      "categories": [
        "stat.ME"
      ],
      "pdf_link": "http://arxiv.org/pdf/2510.25236v1",
      "arxiv_url": "http://arxiv.org/abs/2510.25236v1"
    },
    {
      "title": "Machine-Learning-Assisted Comparison of Regression Functions",
      "authors": [
        "Jian Yan",
        "Zhuoxi Li",
        "Yang Ning",
        "Yong Chen"
      ],
      "abstract": "We revisit the classical problem of comparing regression functions, a\nfundamental question in statistical inference with broad relevance to modern\napplications such as data integration, transfer learning, and causal inference.\nExisting approaches typically rely on smoothing techniques and are thus\nhindered by the curse of dimensionality. We propose a generalized notion of\nkernel-based conditional mean dependence that provides a new characterization\nof the null hypothesis of equal regression functions. Building on this\nreformulation, we develop two novel tests that leverage modern machine learning\nmethods for flexible estimation. We establish the asymptotic properties of the\ntest statistics, which hold under both fixed- and high-dimensional regimes.\nUnlike existing methods that often require restrictive distributional\nassumptions, our framework only imposes mild moment conditions. The efficacy of\nthe proposed tests is demonstrated through extensive numerical studies.",
      "published": "October 28, 2025",
      "categories": [
        "stat.ME",
        "econ.EM",
        "stat.ML"
      ],
      "pdf_link": "http://arxiv.org/pdf/2510.24714v1",
      "arxiv_url": "http://arxiv.org/abs/2510.24714v1"
    },
    {
      "title": "$\u03b1$-LoRA: Effective Fine-Tuning via Base Model Rescaling",
      "authors": [
        "Aymane El Firdoussi",
        "El Mahdi Chayti",
        "Mohamed El Amine Seddik",
        "Martin Jaggi"
      ],
      "abstract": "Fine-tuning has proven to be highly effective in adapting pre-trained models\nto perform better on new desired tasks with minimal data samples. Among the\nmost widely used approaches are reparameterization methods, which update a\ntarget module by augmenting its frozen weight matrix with an additional\ntrainable weight matrix. The most prominent example is Low Rank Adaption\n(LoRA), which gained significant attention in recent years. In this paper, we\nintroduce a new class of reparameterization methods for transfer learning,\ndesigned to enhance the generalization ability of fine-tuned models. We\nestablish the effectiveness of our approach in a high-dimensional binary\nclassification setting using tools from Random Matrix Theory, and further\nvalidate our theoretical findings through more realistic experiments, such as\nfine-tuning LLMs.",
      "published": "October 24, 2025",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "pdf_link": "http://arxiv.org/pdf/2510.21345v1",
      "arxiv_url": "http://arxiv.org/abs/2510.21345v1"
    },
    {
      "title": "What Does It Take to Build a Performant Selective Classifier?",
      "authors": [
        "Stephan Rabanser",
        "Nicolas Papernot"
      ],
      "abstract": "Selective classifiers improve model reliability by abstaining on inputs the\nmodel deems uncertain. However, few practical approaches achieve the\ngold-standard performance of a perfect-ordering oracle that accepts examples\nexactly in order of correctness. Our work formalizes this shortfall as the\nselective-classification gap and present the first finite-sample decomposition\nof this gap to five distinct sources of looseness: Bayes noise, approximation\nerror, ranking error, statistical noise, and implementation- or shift-induced\nslack. Crucially, our analysis reveals that monotone post-hoc calibration --\noften believed to strengthen selective classifiers -- has limited impact on\nclosing this gap, since it rarely alters the model's underlying score ranking.\nBridging the gap therefore requires scoring mechanisms that can effectively\nreorder predictions rather than merely rescale them. We validate our\ndecomposition on synthetic two-moons data and on real-world vision and language\nbenchmarks, isolating each error component through controlled experiments. Our\nresults confirm that (i) Bayes noise and limited model capacity can account for\nsubstantial gaps, (ii) only richer, feature-aware calibrators meaningfully\nimprove score ordering, and (iii) data shift introduces a separate slack that\ndemands distributionally robust training. Together, our decomposition yields a\nquantitative error budget as well as actionable design guidelines that\npractitioners can use to build selective classifiers which approximate ideal\noracle behavior more closely.",
      "published": "October 23, 2025",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "pdf_link": "http://arxiv.org/pdf/2510.20242v2",
      "arxiv_url": "http://arxiv.org/abs/2510.20242v2"
    },
    {
      "title": "Policy Learning with Abstention",
      "authors": [
        "Ayush Sawarni",
        "Jikai Jin",
        "Justin Whitehouse",
        "Vasilis Syrgkanis"
      ],
      "abstract": "Policy learning algorithms are widely used in areas such as personalized\nmedicine and advertising to develop individualized treatment regimes. However,\nmost methods force a decision even when predictions are uncertain, which is\nrisky in high-stakes settings. We study policy learning with abstention, where\na policy may defer to a safe default or an expert. When a policy abstains, it\nreceives a small additive reward on top of the value of a random guess. We\npropose a two-stage learner that first identifies a set of near-optimal\npolicies and then constructs an abstention rule from their disagreements. We\nestablish fast O(1/n)-type regret guarantees when propensities are known, and\nextend these guarantees to the unknown-propensity case via a doubly robust (DR)\nobjective. We further show that abstention is a versatile tool with direct\napplications to other core problems in policy learning: it yields improved\nguarantees under margin conditions without the common realizability assumption,\nconnects to distributionally robust policy learning by hedging against small\ndata shifts, and supports safe policy improvement by ensuring improvement over\na baseline policy with high probability.",
      "published": "October 22, 2025",
      "categories": [
        "cs.LG",
        "econ.EM",
        "stat.ML"
      ],
      "pdf_link": "http://arxiv.org/pdf/2510.19672v1",
      "arxiv_url": "http://arxiv.org/abs/2510.19672v1"
    },
    {
      "title": "Transfer Learning for Benign Overfitting in High-Dimensional Linear\n  Regression",
      "authors": [
        "Yeichan Kim",
        "Ilmun Kim",
        "Seyoung Park"
      ],
      "abstract": "Transfer learning is a key component of modern machine learning, enhancing\nthe performance of target tasks by leveraging diverse data sources.\nSimultaneously, overparameterized models such as the minimum-$\\ell_2$-norm\ninterpolator (MNI) in high-dimensional linear regression have garnered\nsignificant attention for their remarkable generalization capabilities, a\nproperty known as benign overfitting. Despite their individual importance, the\nintersection of transfer learning and MNI remains largely unexplored. Our\nresearch bridges this gap by proposing a novel two-step Transfer MNI approach\nand analyzing its trade-offs. We characterize its non-asymptotic excess risk\nand identify conditions under which it outperforms the target-only MNI. Our\nanalysis reveals free-lunch covariate shift regimes, where leveraging\nheterogeneous data yields the benefit of knowledge transfer at limited cost. To\noperationalize our findings, we develop a data-driven procedure to detect\ninformative sources and introduce an ensemble method incorporating multiple\ninformative Transfer MNIs. Finite-sample experiments demonstrate the robustness\nof our methods to model and data heterogeneity, confirming their advantage.",
      "published": "October 17, 2025",
      "categories": [
        "stat.ML",
        "cs.LG",
        "math.ST",
        "stat.TH"
      ],
      "pdf_link": "http://arxiv.org/pdf/2510.15337v1",
      "arxiv_url": "http://arxiv.org/abs/2510.15337v1"
    }
  ]
}