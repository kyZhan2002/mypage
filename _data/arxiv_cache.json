{
  "timestamp": 1747790726,
  "papers": [
    {
      "title": "A Finite-Sample Analysis of Distributionally Robust Average-Reward\n  Reinforcement Learning",
      "authors": [
        "Zachary Roch",
        "Chi Zhang",
        "George Atia",
        "Yue Wang"
      ],
      "abstract": "Robust reinforcement learning (RL) under the average-reward criterion is\ncrucial for long-term decision making under potential environment mismatches,\nyet its finite-sample complexity study remains largely unexplored. Existing\nworks offer algorithms with asymptotic guarantees, but the absence of\nfinite-sample analysis hinders its principled understanding and practical\ndeployment, especially in data-limited settings. We close this gap by proposing\nRobust Halpern Iteration (RHI), the first algorithm with provable finite-sample\ncomplexity guarantee. Under standard uncertainty sets -- including\ncontamination sets and $\\ell_p$-norm balls -- RHI attains an $\\epsilon$-optimal\npolicy with near-optimal sample complexity of $\\tilde{\\mathcal\nO}\\left(\\frac{SA\\mathcal H^{2}}{\\epsilon^{2}}\\right)$, where $S$ and $A$ denote\nthe numbers of states and actions, and $\\mathcal H$ is the robust optimal bias\nspan. This result gives the first polynomial sample complexity guarantee for\nrobust average-reward RL. Moreover, our RHI's independence from prior knowledge\ndistinguishes it from many previous average-reward RL studies. Our work thus\nconstitutes a significant advancement in enhancing the practical applicability\nof robust average-reward methods to complex, real-world problems.",
      "published": "May 18, 2025",
      "categories": [
        "cs.LG",
        "stat.ML"
      ],
      "pdf_link": "http://arxiv.org/pdf/2505.12462v1",
      "arxiv_url": "http://arxiv.org/abs/2505.12462v1"
    },
    {
      "title": "Near-Optimal Sample Complexities of Divergence-based S-rectangular\n  Distributionally Robust Reinforcement Learning",
      "authors": [
        "Zhenghao Li",
        "Shengbo Wang",
        "Nian Si"
      ],
      "abstract": "Distributionally robust reinforcement learning (DR-RL) has recently gained\nsignificant attention as a principled approach that addresses discrepancies\nbetween training and testing environments. To balance robustness, conservatism,\nand computational traceability, the literature has introduced DR-RL models with\nSA-rectangular and S-rectangular adversaries. While most existing statistical\nanalyses focus on SA-rectangular models, owing to their algorithmic simplicity\nand the optimality of deterministic policies, S-rectangular models more\naccurately capture distributional discrepancies in many real-world applications\nand often yield more effective robust randomized policies. In this paper, we\nstudy the empirical value iteration algorithm for divergence-based\nS-rectangular DR-RL and establish near-optimal sample complexity bounds of\n$\\widetilde{O}(|\\mathcal{S}||\\mathcal{A}|(1-\\gamma)^{-4}\\varepsilon^{-2})$,\nwhere $\\varepsilon$ is the target accuracy, $|\\mathcal{S}|$ and $|\\mathcal{A}|$\ndenote the cardinalities of the state and action spaces, and $\\gamma$ is the\ndiscount factor. To the best of our knowledge, these are the first sample\ncomplexity results for divergence-based S-rectangular models that achieve\noptimal dependence on $|\\mathcal{S}|$, $|\\mathcal{A}|$, and $\\varepsilon$\nsimultaneously. We further validate this theoretical dependence through\nnumerical experiments on a robust inventory control problem and a theoretical\nworst-case example, demonstrating the fast learning performance of our proposed\nalgorithm.",
      "published": "May 18, 2025",
      "categories": [
        "cs.LG",
        "stat.ML"
      ],
      "pdf_link": "http://arxiv.org/pdf/2505.12202v1",
      "arxiv_url": "http://arxiv.org/abs/2505.12202v1"
    },
    {
      "title": "Residual Feature Integration is Sufficient to Prevent Negative Transfer",
      "authors": [
        "Yichen Xu",
        "Ryumei Nakada",
        "Linjun Zhang",
        "Lexin Li"
      ],
      "abstract": "Transfer learning typically leverages representations learned from a source\ndomain to improve performance on a target task. A common approach is to extract\nfeatures from a pre-trained model and directly apply them for target\nprediction. However, this strategy is prone to negative transfer where the\nsource representation fails to align with the target distribution. In this\narticle, we propose Residual Feature Integration (REFINE), a simple yet\neffective method designed to mitigate negative transfer. Our approach combines\na fixed source-side representation with a trainable target-side encoder and\nfits a shallow neural network on the resulting joint representation, which\nadapts to the target domain while preserving transferable knowledge from the\nsource domain. Theoretically, we prove that REFINE is sufficient to prevent\nnegative transfer under mild conditions, and derive the generalization bound\ndemonstrating its theoretical benefit. Empirically, we show that REFINE\nconsistently enhances performance across diverse application and data\nmodalities including vision, text, and tabular data, and outperforms numerous\nalternative solutions. Our method is lightweight, architecture-agnostic, and\nrobust, making it a valuable addition to the existing transfer learning\ntoolbox.",
      "published": "May 17, 2025",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.ST",
        "stat.ML",
        "stat.TH"
      ],
      "pdf_link": "http://arxiv.org/pdf/2505.11771v1",
      "arxiv_url": "http://arxiv.org/abs/2505.11771v1"
    },
    {
      "title": "Humble your Overconfident Networks: Unlearning Overfitting via\n  Sequential Monte Carlo Tempered Deep Ensembles",
      "authors": [
        "Andrew Millard",
        "Zheng Zhao",
        "Joshua Murphy",
        "Simon Maskell"
      ],
      "abstract": "Sequential Monte Carlo (SMC) methods offer a principled approach to Bayesian\nuncertainty quantification but are traditionally limited by the need for\nfull-batch gradient evaluations. We introduce a scalable variant by\nincorporating Stochastic Gradient Hamiltonian Monte Carlo (SGHMC) proposals\ninto SMC, enabling efficient mini-batch based sampling. Our resulting SMCSGHMC\nalgorithm outperforms standard stochastic gradient descent (SGD) and deep\nensembles across image classification, out-of-distribution (OOD) detection, and\ntransfer learning tasks. We further show that SMCSGHMC mitigates overfitting\nand improves calibration, providing a flexible, scalable pathway for converting\npretrained neural networks into well-calibrated Bayesian models.",
      "published": "May 16, 2025",
      "categories": [
        "stat.ML",
        "cs.LG",
        "stat.CO"
      ],
      "pdf_link": "http://arxiv.org/pdf/2505.11671v1",
      "arxiv_url": "http://arxiv.org/abs/2505.11671v1"
    },
    {
      "title": "Sample Complexity of Distributionally Robust Average-Reward\n  Reinforcement Learning",
      "authors": [
        "Zijun Chen",
        "Shengbo Wang",
        "Nian Si"
      ],
      "abstract": "Motivated by practical applications where stable long-term performance is\ncritical-such as robotics, operations research, and healthcare-we study the\nproblem of distributionally robust (DR) average-reward reinforcement learning.\nWe propose two algorithms that achieve near-optimal sample complexity. The\nfirst reduces the problem to a DR discounted Markov decision process (MDP),\nwhile the second, Anchored DR Average-Reward MDP, introduces an anchoring state\nto stabilize the controlled transition kernels within the uncertainty set.\nAssuming the nominal MDP is uniformly ergodic, we prove that both algorithms\nattain a sample complexity of $\\widetilde{O}\\left(|\\mathbf{S}||\\mathbf{A}|\nt_{\\mathrm{mix}}^2\\varepsilon^{-2}\\right)$ for estimating the optimal policy as\nwell as the robust average reward under KL and $f_k$-divergence-based\nuncertainty sets, provided the uncertainty radius is sufficiently small. Here,\n$\\varepsilon$ is the target accuracy, $|\\mathbf{S}|$ and $|\\mathbf{A}|$ denote\nthe sizes of the state and action spaces, and $t_{\\mathrm{mix}}$ is the mixing\ntime of the nominal MDP. This represents the first finite-sample convergence\nguarantee for DR average-reward reinforcement learning. We further validate the\nconvergence rates of our algorithms through numerical experiments.",
      "published": "May 15, 2025",
      "categories": [
        "cs.LG",
        "math.OC",
        "stat.ML"
      ],
      "pdf_link": "http://arxiv.org/pdf/2505.10007v1",
      "arxiv_url": "http://arxiv.org/abs/2505.10007v1"
    },
    {
      "title": "Community-based Multi-Agent Reinforcement Learning with Transfer and\n  Active Exploration",
      "authors": [
        "Zhaoyang Shi"
      ],
      "abstract": "We propose a new framework for multi-agent reinforcement learning (MARL),\nwhere the agents cooperate in a time-evolving network with latent community\nstructures and mixed memberships. Unlike traditional neighbor-based or fixed\ninteraction graphs, our community-based framework captures flexible and\nabstract coordination patterns by allowing each agent to belong to multiple\noverlapping communities. Each community maintains shared policy and value\nfunctions, which are aggregated by individual agents according to personalized\nmembership weights. We also design actor-critic algorithms that exploit this\nstructure: agents inherit community-level estimates for policy updates and\nvalue learning, enabling structured information sharing without requiring\naccess to other agents' policies. Importantly, our approach supports both\ntransfer learning by adapting to new agents or tasks via membership estimation,\nand active learning by prioritizing uncertain communities during exploration.\nTheoretically, we establish convergence guarantees under linear function\napproximation for both actor and critic updates. To our knowledge, this is the\nfirst MARL framework that integrates community structure, transferability, and\nactive learning with provable guarantees.",
      "published": "May 14, 2025",
      "categories": [
        "cs.LG",
        "cs.MA",
        "math.OC",
        "stat.ML"
      ],
      "pdf_link": "http://arxiv.org/pdf/2505.09756v1",
      "arxiv_url": "http://arxiv.org/abs/2505.09756v1"
    },
    {
      "title": "Wasserstein Distributionally Robust Nonparametric Regression",
      "authors": [
        "Changyu Liu",
        "Yuling Jiao",
        "Junhui Wang",
        "Jian Huang"
      ],
      "abstract": "Distributionally robust optimization has become a powerful tool for\nprediction and decision-making under model uncertainty. By focusing on the\nlocal worst-case risk, it enhances robustness by identifying the most\nunfavorable distribution within a predefined ambiguity set. While extensive\nresearch has been conducted in parametric settings, studies on nonparametric\nframeworks remain limited. This paper studies the generalization properties of\nWasserstein distributionally robust nonparametric estimators, with particular\nattention to the impact of model misspecification, where non-negligible\ndiscrepancies between the estimation function space and target function can\nimpair generalization performance. We establish non-asymptotic error bounds for\nthe excess local worst-case risk by analyzing the regularization effects\ninduced by distributional perturbations and employing feedforward neural\nnetworks with Lipschitz constraints. These bounds illustrate how uncertainty\nlevels and neural network structures influence generalization performance and\nare applicable to both Lipschitz and quadratic loss functions. Furthermore, we\ninvestigate the Lagrangian relaxation of the local worst-case risk and derive\ncorresponding non-asymptotic error bounds for these estimators. The robustness\nof the proposed estimator is evaluated through simulation studies and\nillustrated with an application to the MNIST dataset.",
      "published": "May 12, 2025",
      "categories": [
        "stat.ML",
        "cs.LG",
        "62G05, 62G08, 68T07"
      ],
      "pdf_link": "http://arxiv.org/pdf/2505.07967v1",
      "arxiv_url": "http://arxiv.org/abs/2505.07967v1"
    },
    {
      "title": "Transfer Learning Across Fixed-Income Product Classes",
      "authors": [
        "Nicolas Camenzind",
        "Damir Filipovic"
      ],
      "abstract": "We propose a framework for transfer learning of discount curves across\ndifferent fixed-income product classes. Motivated by challenges in estimating\ndiscount curves from sparse or noisy data, we extend kernel ridge regression\n(KR) to a vector-valued setting, formulating a convex optimization problem in a\nvector-valued reproducing kernel Hilbert space (RKHS). Each component of the\nsolution corresponds to the discount curve implied by a specific product class.\nWe introduce an additional regularization term motivated by economic\nprinciples, promoting smoothness of spread curves between product classes, and\nshow that it leads to a valid separable kernel structure. A main theoretical\ncontribution is a decomposition of the vector-valued RKHS norm induced by\nseparable kernels. We further provide a Gaussian process interpretation of\nvector-valued KR, enabling quantification of estimation uncertainty.\nIllustrative examples demonstrate that transfer learning significantly improves\nextrapolation performance and tightens confidence intervals compared to\nsingle-curve estimation.",
      "published": "May 12, 2025",
      "categories": [
        "stat.ML",
        "cs.LG",
        "q-fin.CP",
        "q-fin.MF"
      ],
      "pdf_link": "http://arxiv.org/pdf/2505.07676v1",
      "arxiv_url": "http://arxiv.org/abs/2505.07676v1"
    },
    {
      "title": "Enhancing Inference for Small Cohorts via Transfer Learning and Weighted\n  Integration of Multiple Datasets",
      "authors": [
        "Subharup Guha",
        "Mengqi Xu",
        "Yi Li"
      ],
      "abstract": "Lung sepsis remains a significant concern in the Northeastern U.S., yet the\nnational eICU Collaborative Database includes only a small number of patients\nfrom this region, highlighting underrepresentation. Understanding clinical\nvariables such as FiO2, creatinine, platelets, and lactate, which reflect\noxygenation, kidney function, coagulation, and metabolism, is crucial because\nthese markers influence sepsis outcomes and may vary by sex. Transfer learning\nhelps address small sample sizes by borrowing information from larger datasets,\nalthough differences in covariates and outcome-generating mechanisms between\nthe target and external cohorts can complicate the process. We propose a novel\nweighting method, TRANSfer LeArning wiTh wEights (TRANSLATE), to integrate data\nfrom various sources by incorporating domain-specific characteristics through\nlearned weights that align external data with the target cohort. These weights\nadjust for cohort differences, are proportional to each cohort's effective\nsample size, and downweight dissimilar cohorts. TRANSLATE offers theoretical\nguarantees for improved precision and applies to a wide range of estimands,\nincluding means, variances, and distribution functions. Simulations and a\nreal-data application to sepsis outcomes in the Northeast cohort, using a much\nlarger sample from other U.S. regions, show that the method enhances inference\nwhile accounting for regional heterogeneity.",
      "published": "May 11, 2025",
      "categories": [
        "stat.ME"
      ],
      "pdf_link": "http://arxiv.org/pdf/2505.07153v1",
      "arxiv_url": "http://arxiv.org/abs/2505.07153v1"
    },
    {
      "title": "A systematic review of challenges and proposed solutions in modeling\n  multimodal data",
      "authors": [
        "Maryam Farhadizadeh",
        "Maria Weymann",
        "Michael Bla\u00df",
        "Johann Kraus",
        "Christopher Gundler",
        "Sebastian Walter",
        "Noah Hempen",
        "Harald Binder",
        "Nadine Binder"
      ],
      "abstract": "Multimodal data modeling has emerged as a powerful approach in clinical\nresearch, enabling the integration of diverse data types such as imaging,\ngenomics, wearable sensors, and electronic health records. Despite its\npotential to improve diagnostic accuracy and support personalized care,\nmodeling such heterogeneous data presents significant technical challenges.\nThis systematic review synthesizes findings from 69 studies to identify common\nobstacles, including missing modalities, limited sample sizes, dimensionality\nimbalance, interpretability issues, and finding the optimal fusion techniques.\nWe highlight recent methodological advances, such as transfer learning,\ngenerative models, attention mechanisms, and neural architecture search that\noffer promising solutions. By mapping current trends and innovations, this\nreview provides a comprehensive overview of the field and offers practical\ninsights to guide future research and development in multimodal modeling for\nmedical applications.",
      "published": "May 11, 2025",
      "categories": [
        "cs.LG",
        "stat.ML"
      ],
      "pdf_link": "http://arxiv.org/pdf/2505.06945v2",
      "arxiv_url": "http://arxiv.org/abs/2505.06945v2"
    },
    {
      "title": "Model Steering: Learning with a Reference Model Improves Generalization\n  Bounds and Scaling Laws",
      "authors": [
        "Xiyuan Wei",
        "Ming Lin",
        "Fanjiang Ye",
        "Fengguang Song",
        "Liangliang Cao",
        "My T. Thai",
        "Tianbao Yang"
      ],
      "abstract": "This paper formalizes an emerging learning paradigm that uses a trained model\nas a reference to guide and enhance the training of a target model through\nstrategic data selection or weighting, named $\\textbf{model steering}$. While\nad-hoc methods have been used in various contexts, including the training of\nlarge foundation models, its underlying principles remain insufficiently\nunderstood, leading to sub-optimal performance. In this work, we propose a\ntheory-driven framework for model steering called $\\textbf{DRRho risk\nminimization}$, which is rooted in Distributionally Robust Optimization (DRO).\nThrough a generalization analysis, we provide theoretical insights into why\nthis approach improves generalization and data efficiency compared to training\nwithout a reference model. To the best of our knowledge, this is the first time\nsuch theoretical insights are provided for the new learning paradigm, which\nsignificantly enhance our understanding and practice of model steering.\nBuilding on these insights and the connection between contrastive learning and\nDRO, we introduce a novel method for Contrastive Language-Image Pretraining\n(CLIP) with a reference model, termed DRRho-CLIP. Extensive experiments\nvalidate the theoretical insights, reveal a superior scaling law compared to\nCLIP without a reference model, and demonstrate its strength over existing\nheuristic approaches.",
      "published": "May 10, 2025",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "stat.ML"
      ],
      "pdf_link": "http://arxiv.org/pdf/2505.06699v3",
      "arxiv_url": "http://arxiv.org/abs/2505.06699v3"
    }
  ]
}