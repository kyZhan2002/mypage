{
  "timestamp": 1742779238,
  "papers": [
    {
      "title": "An Optimization Framework for Differentially Private Sparse Fine-Tuning",
      "authors": [
        "Mehdi Makni",
        "Kayhan Behdin",
        "Gabriel Afriat",
        "Zheng Xu",
        "Sergei Vassilvitskii",
        "Natalia Ponomareva",
        "Hussein Hazimeh",
        "Rahul Mazumder"
      ],
      "abstract": "Differentially private stochastic gradient descent (DP-SGD) is broadly\nconsidered to be the gold standard for training and fine-tuning neural networks\nunder differential privacy (DP). With the increasing availability of\nhigh-quality pre-trained model checkpoints (e.g., vision and language models),\nfine-tuning has become a popular strategy. However, despite recent progress in\nunderstanding and applying DP-SGD for private transfer learning tasks,\nsignificant challenges remain -- most notably, the performance gap between\nmodels fine-tuned with DP-SGD and their non-private counterparts. Sparse\nfine-tuning on private data has emerged as an alternative to full-model\nfine-tuning; recent work has shown that privately fine-tuning only a small\nsubset of model weights and keeping the rest of the weights fixed can lead to\nbetter performance. In this work, we propose a new approach for sparse\nfine-tuning of neural networks under DP. Existing work on private sparse\nfinetuning often used fixed choice of trainable weights (e.g., updating only\nthe last layer), or relied on public model's weights to choose the subset of\nweights to modify. Such choice of weights remains suboptimal. In contrast, we\nexplore an optimization-based approach, where our selection method makes use of\nthe private gradient information, while using off the shelf privacy accounting\ntechniques. Our numerical experiments on several computer vision models and\ndatasets show that our selection method leads to better prediction accuracy,\ncompared to full-model private fine-tuning or existing private sparse\nfine-tuning approaches.",
      "published": "March 17, 2025",
      "categories": [
        "cs.LG",
        "stat.ML"
      ],
      "pdf_link": "http://arxiv.org/pdf/2503.12822v1",
      "arxiv_url": "http://arxiv.org/abs/2503.12822v1"
    },
    {
      "title": "Mixed-feature Logistic Regression Robust to Distribution Shifts",
      "authors": [
        "Qingshi Sun",
        "Nathan Justin",
        "Andres Gomez",
        "Phebe Vayanos"
      ],
      "abstract": "Logistic regression models are widely used in the social and behavioral\nsciences and in high-stakes domains, due to their simplicity and\ninterpretability properties. At the same time, such domains are permeated by\ndistribution shifts, where the distribution generating the data changes between\ntraining and deployment. In this paper, we study a distributionally robust\nlogistic regression problem that seeks the model that will perform best against\nadversarial realizations of the data distribution drawn from a suitably\nconstructed Wasserstein ambiguity set. Our model and solution approach differ\nfrom prior work in that we can capture settings where the likelihood of\ndistribution shifts can vary across features, significantly broadening the\napplicability of our model relative to the state-of-the-art. We propose a\ngraph-based solution approach that can be integrated into off-the-shelf\noptimization solvers. We evaluate the performance of our model and algorithms\non numerous publicly available datasets. Our solution achieves a 408x speed-up\nrelative to the state-of-the-art. Additionally, compared to the\nstate-of-the-art, our model reduces average calibration error by up to 36.19%\nand worst-case calibration error by up to 41.70%, while increasing the average\narea under the ROC curve (AUC) by up to 18.02% and worst-case AUC by up to\n48.37%.",
      "published": "March 15, 2025",
      "categories": [
        "cs.LG",
        "math.OC",
        "stat.ML"
      ],
      "pdf_link": "http://arxiv.org/pdf/2503.12012v1",
      "arxiv_url": "http://arxiv.org/abs/2503.12012v1"
    }
  ]
}