{
  "timestamp": 1748914004,
  "papers": [
    {
      "title": "Density Ratio Permutation Tests with connections to distributional\n  shifts and conditional two-sample testing",
      "authors": [
        "Alberto Bordino",
        "Thomas B. Berrett"
      ],
      "abstract": "We introduce novel hypothesis tests to allow for statistical inference for\ndensity ratios. More precisely, we introduce the Density Ratio Permutation Test\n(DRPT) for testing $H_0: g \\propto r f$ based on independent data drawn from\ndistributions with densities $f$ and $g$, where the hypothesised density ratio\n$r$ is a fixed function. The proposed test employs an efficient Markov Chain\nMonte Carlo algorithm to draw permutations of the combined dataset according to\na distribution determined by $r$, producing exchangeable versions of the whole\nsample and thereby establishing finite-sample validity. Regarding the test's\nbehaviour under the alternative hypothesis, we begin by demonstrating that if\nthe test statistic is chosen as an Integral Probability Metric (IPM), the DRPT\nis consistent under mild assumptions on the function class that defines the\nIPM. We then narrow our focus to the setting where the function class is a\nReproducing Kernel Hilbert Space, and introduce a generalisation of the\nclassical Maximum Mean Discrepancy (MMD), which we term Shifted-MMD. For\ncontinuous data, assuming that a normalised version of $g - rf$ lies in a\nSobolev ball, we establish the minimax optimality of the DRPT based on the\nShifted-MMD. We further extend our approach to scenarios with an unknown shift\nfactor $r$, estimating it from part of the data using Density Ratio Estimation\ntechniques, and derive Type-I error bounds based on estimation error.\nAdditionally, we demonstrate how the DRPT can be adapted for conditional\ntwo-sample testing, establishing it as a versatile tool for assessing modelling\nassumptions on importance weights, covariate shifts and related scenarios,\nwhich frequently arise in contexts such as transfer learning and causal\ninference. Finally, we validate our theoretical findings through experiments on\nboth simulated and real-world datasets.",
      "published": "May 30, 2025",
      "categories": [
        "stat.ME",
        "math.ST",
        "stat.TH",
        "62G09 62G10"
      ],
      "pdf_link": "http://arxiv.org/pdf/2505.24529v1",
      "arxiv_url": "http://arxiv.org/abs/2505.24529v1"
    },
    {
      "title": "Attractor learning for spatiotemporally chaotic dynamical systems using\n  echo state networks with transfer learning",
      "authors": [
        "Mohammad Shah Alam",
        "William Ott",
        "Ilya Timofeyev"
      ],
      "abstract": "In this paper, we explore the predictive capabilities of echo state networks\n(ESNs) for the generalized Kuramoto-Sivashinsky (gKS) equation, an archetypal\nnonlinear PDE that exhibits spatiotemporal chaos. We introduce a novel\nmethodology that integrates ESNs with transfer learning, aiming to enhance\npredictive performance across various parameter regimes of the gKS model. Our\nresearch focuses on predicting changes in long-term statistical patterns of the\ngKS model that result from varying the dispersion relation or the length of the\nspatial domain. We use transfer learning to adapt ESNs to different parameter\nsettings and successfully capture changes in the underlying chaotic attractor.",
      "published": "May 30, 2025",
      "categories": [
        "math.DS",
        "cs.AI",
        "cs.LG",
        "nlin.CD",
        "stat.ML",
        "37N99, 68T30"
      ],
      "pdf_link": "http://arxiv.org/pdf/2505.24099v1",
      "arxiv_url": "http://arxiv.org/abs/2505.24099v1"
    },
    {
      "title": "Epistemic Errors of Imperfect Multitask Learners When Distributions\n  Shift",
      "authors": [
        "Sabina J. Sloman",
        "Michele Caprio",
        "Samuel Kaski"
      ],
      "abstract": "When data are noisy, a statistical learner's goal is to resolve epistemic\nuncertainty about the data it will encounter at test-time, i.e., to identify\nthe distribution of test (target) data. Many real-world learning settings\nintroduce sources of epistemic uncertainty that can not be resolved on the\nbasis of training (source) data alone: The source data may arise from multiple\ntasks (multitask learning), the target data may differ systematically from the\nsource data tasks (distribution shift), and/or the learner may not arrive at an\naccurate characterization of the source data (imperfect learning). We introduce\na principled definition of epistemic error, and provide a generic,\ndecompositional epistemic error bound. Our error bound is the first to (i)\nconsider epistemic error specifically, (ii) accommodate all the sources of\nepistemic uncertainty above, and (iii) separately attribute the error to each\nof multiple aspects of the learning procedure and environment. As corollaries\nof the generic result, we provide (i) epistemic error bounds specialized to the\nsettings of Bayesian transfer learning and distribution shift within\n$\\epsilon$-neighborhoods, and (ii) a set of corresponding generalization\nbounds. Finally, we provide a novel definition of negative transfer, and\nvalidate its insights in a synthetic experimental setting.",
      "published": "May 29, 2025",
      "categories": [
        "cs.LG",
        "stat.ML"
      ],
      "pdf_link": "http://arxiv.org/pdf/2505.23496v1",
      "arxiv_url": "http://arxiv.org/abs/2505.23496v1"
    },
    {
      "title": "GLAMP: An Approximate Message Passing Framework for Transfer Learning\n  with Applications to Lasso-based Estimators",
      "authors": [
        "Longlin Wang",
        "Yanke Song",
        "Kuanhao Jiang",
        "Pragya Sur"
      ],
      "abstract": "Approximate Message Passing (AMP) algorithms enable precise characterization\nof certain classes of random objects in the high-dimensional limit, and have\nfound widespread applications in fields such as statistics, deep learning,\ngenetics, and communications. However, existing AMP frameworks cannot\nsimultaneously handle matrix-valued iterates and non-separable denoising\nfunctions. This limitation prevents them from precisely characterizing\nestimators that draw information from multiple data sources with distribution\nshifts. In this work, we introduce Generalized Long Approximate Message Passing\n(GLAMP), a novel extension of AMP that addresses this limitation. We rigorously\nprove state evolution for GLAMP. GLAMP significantly broadens the scope of AMP,\nenabling the analysis of transfer learning estimators that were previously out\nof reach. We demonstrate the utility of GLAMP by precisely characterizing the\nrisk of three Lasso-based transfer learning estimators: the Stacked Lasso, the\nModel Averaging Estimator, and the Second Step Estimator. We also demonstrate\nthe remarkable finite sample accuracy of our theory via extensive simulations.",
      "published": "May 28, 2025",
      "categories": [
        "math.ST",
        "stat.ML",
        "stat.TH"
      ],
      "pdf_link": "http://arxiv.org/pdf/2505.22594v1",
      "arxiv_url": "http://arxiv.org/abs/2505.22594v1"
    },
    {
      "title": "Distributionally Robust Deep Q-Learning",
      "authors": [
        "Chung I Lu",
        "Julian Sester",
        "Aijia Zhang"
      ],
      "abstract": "We propose a novel distributionally robust $Q$-learning algorithm for the\nnon-tabular case accounting for continuous state spaces where the state\ntransition of the underlying Markov decision process is subject to model\nuncertainty. The uncertainty is taken into account by considering the\nworst-case transition from a ball around a reference probability measure. To\ndetermine the optimal policy under the worst-case state transition, we solve\nthe associated non-linear Bellman equation by dualising and regularising the\nBellman operator with the Sinkhorn distance, which is then parameterized with\ndeep neural networks. This approach allows us to modify the Deep Q-Network\nalgorithm to optimise for the worst case state transition.\n  We illustrate the tractability and effectiveness of our approach through\nseveral applications, including a portfolio optimisation task based on\nS\\&{P}~500 data.",
      "published": "May 25, 2025",
      "categories": [
        "cs.LG",
        "math.OC",
        "q-fin.PM",
        "stat.ML"
      ],
      "pdf_link": "http://arxiv.org/pdf/2505.19058v1",
      "arxiv_url": "http://arxiv.org/abs/2505.19058v1"
    },
    {
      "title": "Linear Mixture Distributionally Robust Markov Decision Processes",
      "authors": [
        "Zhishuai Liu",
        "Pan Xu"
      ],
      "abstract": "Many real-world decision-making problems face the off-dynamics challenge: the\nagent learns a policy in a source domain and deploys it in a target domain with\ndifferent state transitions. The distributionally robust Markov decision\nprocess (DRMDP) addresses this challenge by finding a robust policy that\nperforms well under the worst-case environment within a pre-specified\nuncertainty set of transition dynamics. Its effectiveness heavily hinges on the\nproper design of these uncertainty sets, based on prior knowledge of the\ndynamics. In this work, we propose a novel linear mixture DRMDP framework,\nwhere the nominal dynamics is assumed to be a linear mixture model. In contrast\nwith existing uncertainty sets directly defined as a ball centered around the\nnominal kernel, linear mixture DRMDPs define the uncertainty sets based on a\nball around the mixture weighting parameter. We show that this new framework\nprovides a more refined representation of uncertainties compared to\nconventional models based on $(s,a)$-rectangularity and $d$-rectangularity,\nwhen prior knowledge about the mixture model is present. We propose a meta\nalgorithm for robust policy learning in linear mixture DRMDPs with general\n$f$-divergence defined uncertainty sets, and analyze its sample complexities\nunder three divergence metrics instantiations: total variation,\nKullback-Leibler, and $\\chi^2$ divergences. These results establish the\nstatistical learnability of linear mixture DRMDPs, laying the theoretical\nfoundation for future research on this new setting.",
      "published": "May 23, 2025",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO",
        "stat.ML"
      ],
      "pdf_link": "http://arxiv.org/pdf/2505.18044v1",
      "arxiv_url": "http://arxiv.org/abs/2505.18044v1"
    },
    {
      "title": "A Distributionally-Robust Framework for Nuisance in Causal Effect\n  Estimation",
      "authors": [
        "Akira Tanimoto"
      ],
      "abstract": "Causal inference requires evaluating models on balanced distributions between\ntreatment and control groups, while training data often exhibits imbalance due\nto historical decision-making policies. Most conventional statistical methods\naddress this distribution shift through inverse probability weighting (IPW),\nwhich requires estimating propensity scores as an intermediate step. These\nmethods face two key challenges: inaccurate propensity estimation and\ninstability from extreme weights. We decompose the generalization error to\nisolate these issues--propensity ambiguity and statistical instability--and\naddress them through an adversarial loss function. Our approach combines\ndistributionally robust optimization for handling propensity uncertainty with\nweight regularization based on weighted Rademacher complexity. Experiments on\nsynthetic and real-world datasets demonstrate consistent improvements over\nexisting methods.",
      "published": "May 23, 2025",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "pdf_link": "http://arxiv.org/pdf/2505.17717v1",
      "arxiv_url": "http://arxiv.org/abs/2505.17717v1"
    },
    {
      "title": "Wasserstein Transfer Learning",
      "authors": [
        "Kaicheng Zhang",
        "Sinian Zhang",
        "Doudou Zhou",
        "Yidong Zhou"
      ],
      "abstract": "Transfer learning is a powerful paradigm for leveraging knowledge from source\ndomains to enhance learning in a target domain. However, traditional transfer\nlearning approaches often focus on scalar or multivariate data within Euclidean\nspaces, limiting their applicability to complex data structures such as\nprobability distributions. To address this, we introduce a novel framework for\ntransfer learning in regression models, where outputs are probability\ndistributions residing in the Wasserstein space. When the informative subset of\ntransferable source domains is known, we propose an estimator with provable\nasymptotic convergence rates, quantifying the impact of domain similarity on\ntransfer efficiency. For cases where the informative subset is unknown, we\ndevelop a data-driven transfer learning procedure designed to mitigate negative\ntransfer. The proposed methods are supported by rigorous theoretical analysis\nand are validated through extensive simulations and real-world applications.",
      "published": "May 23, 2025",
      "categories": [
        "cs.LG",
        "math.ST",
        "stat.TH"
      ],
      "pdf_link": "http://arxiv.org/pdf/2505.17404v1",
      "arxiv_url": "http://arxiv.org/abs/2505.17404v1"
    },
    {
      "title": "Transfer Faster, Price Smarter: Minimax Dynamic Pricing under\n  Cross-Market Preference Shift",
      "authors": [
        "Yi Zhang",
        "Elynn Chen",
        "Yujun Yan"
      ],
      "abstract": "We study contextual dynamic pricing when a target market can leverage K\nauxiliary markets -- offline logs or concurrent streams -- whose mean utilities\ndiffer by a structured preference shift. We propose Cross-Market Transfer\nDynamic Pricing (CM-TDP), the first algorithm that provably handles such\nmodel-shift transfer and delivers minimax-optimal regret for both linear and\nnon-parametric utility models.\n  For linear utilities of dimension d, where the difference between source- and\ntarget-task coefficients is $s_{0}$-sparse, CM-TDP attains regret\n$\\tilde{O}((d*K^{-1}+s_{0})\\log T)$. For nonlinear demand residing in a\nreproducing kernel Hilbert space with effective dimension $\\alpha$, complexity\n$\\beta$ and task-similarity parameter $H$, the regret becomes\n$\\tilde{O}\\!(K^{-2\\alpha\\beta/(2\\alpha\\beta+1)}T^{1/(2\\alpha\\beta+1)} +\nH^{2/(2\\alpha+1)}T^{1/(2\\alpha+1)})$, matching information-theoretic lower\nbounds up to logarithmic factors. The RKHS bound is the first of its kind for\ntransfer pricing and is of independent interest.\n  Extensive simulations show up to 50% lower cumulative regret and 5 times\nfaster learning relative to single-market pricing baselines. By bridging\ntransfer learning, robust aggregation, and revenue optimization, CM-TDP moves\ntoward pricing systems that transfer faster, price smarter.",
      "published": "May 22, 2025",
      "categories": [
        "stat.ME",
        "cs.LG",
        "stat.AP"
      ],
      "pdf_link": "http://arxiv.org/pdf/2505.17203v1",
      "arxiv_url": "http://arxiv.org/abs/2505.17203v1"
    }
  ]
}