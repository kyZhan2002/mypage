{
  "timestamp": 1742347114,
  "papers": [
    {
      "title": "An Optimization Framework for Differentially Private Sparse Fine-Tuning",
      "authors": [
        "Mehdi Makni",
        "Kayhan Behdin",
        "Gabriel Afriat",
        "Zheng Xu",
        "Sergei Vassilvitskii",
        "Natalia Ponomareva",
        "Hussein Hazimeh",
        "Rahul Mazumder"
      ],
      "abstract": "Differentially private stochastic gradient descent (DP-SGD) is broadly\nconsidered to be the gold standard for training and fine-tuning neural networks\nunder differential privacy (DP). With the increasing availability of\nhigh-quality pre-trained model checkpoints (e.g., vision and language models),\nfine-tuning has become a popular strategy. However, despite recent progress in\nunderstanding and applying DP-SGD for private transfer learning tasks,\nsignificant challenges remain -- most notably, the performance gap between\nmodels fine-tuned with DP-SGD and their non-private counterparts. Sparse\nfine-tuning on private data has emerged as an alternative to full-model\nfine-tuning; recent work has shown that privately fine-tuning only a small\nsubset of model weights and keeping the rest of the weights fixed can lead to\nbetter performance. In this work, we propose a new approach for sparse\nfine-tuning of neural networks under DP. Existing work on private sparse\nfinetuning often used fixed choice of trainable weights (e.g., updating only\nthe last layer), or relied on public model's weights to choose the subset of\nweights to modify. Such choice of weights remains suboptimal. In contrast, we\nexplore an optimization-based approach, where our selection method makes use of\nthe private gradient information, while using off the shelf privacy accounting\ntechniques. Our numerical experiments on several computer vision models and\ndatasets show that our selection method leads to better prediction accuracy,\ncompared to full-model private fine-tuning or existing private sparse\nfine-tuning approaches.",
      "published": "March 17, 2025",
      "categories": [
        "cs.LG",
        "stat.ML"
      ],
      "pdf_link": "http://arxiv.org/pdf/2503.12822v1",
      "arxiv_url": "http://arxiv.org/abs/2503.12822v1"
    }
  ]
}