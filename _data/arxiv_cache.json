{
  "timestamp": 1753667285,
  "papers": [
    {
      "title": "On the Interaction of Compressibility and Adversarial Robustness",
      "authors": [
        "Melih Barsbey",
        "Ant\u00f4nio H. Ribeiro",
        "Umut \u015eim\u015fekli",
        "Tolga Birdal"
      ],
      "abstract": "Modern neural networks are expected to simultaneously satisfy a host of\ndesirable properties: accurate fitting to training data, generalization to\nunseen inputs, parameter and computational efficiency, and robustness to\nadversarial perturbations. While compressibility and robustness have each been\nstudied extensively, a unified understanding of their interaction still remains\nelusive. In this work, we develop a principled framework to analyze how\ndifferent forms of compressibility - such as neuron-level sparsity and spectral\ncompressibility - affect adversarial robustness. We show that these forms of\ncompression can induce a small number of highly sensitive directions in the\nrepresentation space, which adversaries can exploit to construct effective\nperturbations. Our analysis yields a simple yet instructive robustness bound,\nrevealing how neuron and spectral compressibility impact $L_\\infty$ and $L_2$\nrobustness via their effects on the learned representations. Crucially, the\nvulnerabilities we identify arise irrespective of how compression is achieved -\nwhether via regularization, architectural bias, or implicit learning dynamics.\nThrough empirical evaluations across synthetic and realistic tasks, we confirm\nour theoretical predictions, and further demonstrate that these vulnerabilities\npersist under adversarial training and transfer learning, and contribute to the\nemergence of universal adversarial perturbations. Our findings show a\nfundamental tension between structured compressibility and robustness, and\nsuggest new pathways for designing models that are both efficient and secure.",
      "published": "July 23, 2025",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "stat.ML"
      ],
      "pdf_link": "http://arxiv.org/pdf/2507.17725v1",
      "arxiv_url": "http://arxiv.org/abs/2507.17725v1"
    },
    {
      "title": "Causal Mechanism Estimation in Multi-Sensor Systems Across Multiple\n  Domains",
      "authors": [
        "Jingyi Yu",
        "Tim Pychynski",
        "Marco F. Huber"
      ],
      "abstract": "To gain deeper insights into a complex sensor system through the lens of\ncausality, we present common and individual causal mechanism estimation\n(CICME), a novel three-step approach to inferring causal mechanisms from\nheterogeneous data collected across multiple domains. By leveraging the\nprinciple of Causal Transfer Learning (CTL), CICME is able to reliably detect\ndomain-invariant causal mechanisms when provided with sufficient samples. The\nidentified common causal mechanisms are further used to guide the estimation of\nthe remaining causal mechanisms in each domain individually. The performance of\nCICME is evaluated on linear Gaussian models under scenarios inspired from a\nmanufacturing process. Building upon existing continuous optimization-based\ncausal discovery methods, we show that CICME leverages the benefits of applying\ncausal discovery on the pooled data and repeatedly on data from individual\ndomains, and it even outperforms both baseline methods under certain scenarios.",
      "published": "July 23, 2025",
      "categories": [
        "cs.LG",
        "stat.ML"
      ],
      "pdf_link": "http://arxiv.org/pdf/2507.17792v2",
      "arxiv_url": "http://arxiv.org/abs/2507.17792v2"
    },
    {
      "title": "Sufficiency-principled Transfer Learning via Model Averaging",
      "authors": [
        "Xiyuan Zhang",
        "Huihang Liu",
        "Xinyu Zhang"
      ],
      "abstract": "When the transferable set is unknowable, transfering informative knowledge as\nmuch as possible\\textemdash a principle we refer to as \\emph{sufficiency},\nbecomes crucial for enhancing transfer learning effectiveness. However,\nexisting transfer learning methods not only overlook the sufficiency principle,\nbut also rely on restrictive single-similarity assumptions (\\eg individual or\ncombinatorial similarity), leading to suboptimal performance. To address these\nlimitations, we propose a sufficiency-principled transfer learning framework\nvia unified model averaging algorithms, accommodating both individual and\ncombinatorial similarities. Theoretically, we establish the\nasymptotic/high-probability optimality, enhanced convergence rate and\nasymptotic normality for multi-source linear regression models with a diverging\nnumber of parameters, achieving sufficiency, robustness to negative transfer,\nprivacy protection and feasible statistical inference. Extensive simulations\nand an empirical data analysis of Beijing housing rental data demonstrate the\npromising superiority of our framework over conventional alternatives.",
      "published": "July 21, 2025",
      "categories": [
        "stat.ME",
        "math.ST",
        "stat.TH"
      ],
      "pdf_link": "http://arxiv.org/pdf/2507.15416v1",
      "arxiv_url": "http://arxiv.org/abs/2507.15416v1"
    },
    {
      "title": "Parameter-transfer in spatial autoregressive models via model averaging",
      "authors": [
        "Fen Jiang",
        "Wenhui Li",
        "Xinyu Zhang"
      ],
      "abstract": "Econometric modeling in spatial autoregressive models often suffers from\ninsufficient samples in practice, such as spatial analysis of infectious\ndiseases at the country level with limited data. Transfer learning offers a\npromising solution by leveraging information from regions or domains with\nsimilar spatial spillover effects to improve the analysis of the target data.\nIn this paper, we propose a parameter-transfer approach based on Mallows model\naveraging for spatial autoregressive models to improve the prediction accuracy.\nOur approach does not require sharing multi-source spatial data and can be\ncombined with various parameter estimation methods, such as the maximum\nlikelihood and the two-stage least squares. Theoretical analyses demonstrate\nthat our method achieves asymptotic optimality and ensures weight convergence\nwith an explicit convergence rate. Simulation studies and the application of\ninfection count prediction in Africa further demonstrate the effectiveness of\nour approach.",
      "published": "July 19, 2025",
      "categories": [
        "stat.ME"
      ],
      "pdf_link": "http://arxiv.org/pdf/2507.14453v1",
      "arxiv_url": "http://arxiv.org/abs/2507.14453v1"
    },
    {
      "title": "Improving physics-informed neural network extrapolation via transfer\n  learning and adaptive activation functions",
      "authors": [
        "Athanasios Papastathopoulos-Katsaros",
        "Alexandra Stavrianidi",
        "Zhandong Liu"
      ],
      "abstract": "Physics-Informed Neural Networks (PINNs) are deep learning models that\nincorporate the governing physical laws of a system into the learning process,\nmaking them well-suited for solving complex scientific and engineering\nproblems. Recently, PINNs have gained widespread attention as a powerful\nframework for combining physical principles with data-driven modeling to\nimprove prediction accuracy. Despite their successes, however, PINNs often\nexhibit poor extrapolation performance outside the training domain and are\nhighly sensitive to the choice of activation functions (AFs). In this paper, we\nintroduce a transfer learning (TL) method to improve the extrapolation\ncapability of PINNs. Our approach applies transfer learning (TL) within an\nextended training domain, using only a small number of carefully selected\ncollocation points. Additionally, we propose an adaptive AF that takes the form\nof a linear combination of standard AFs, which improves both the robustness and\naccuracy of the model. Through a series of experiments, we demonstrate that our\nmethod achieves an average of 40% reduction in relative L2 error and an average\nof 50% reduction in mean absolute error in the extrapolation domain, all\nwithout a significant increase in computational cost. The code is available at\nhttps://github.com/LiuzLab/PINN-extrapolation .",
      "published": "July 16, 2025",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NA",
        "math.DS",
        "math.NA",
        "stat.ML"
      ],
      "pdf_link": "http://arxiv.org/pdf/2507.12659v1",
      "arxiv_url": "http://arxiv.org/abs/2507.12659v1"
    },
    {
      "title": "Statistical Inference for Conditional Group Distributionally Robust\n  Optimization with Cross-Entropy Loss",
      "authors": [
        "Zijian Guo",
        "Zhenyu Wang",
        "Yifan Hu",
        "Francis Bach"
      ],
      "abstract": "In multi-source learning with discrete labels, distributional heterogeneity\nacross domains poses a central challenge to developing predictive models that\ntransfer reliably to unseen domains. We study multi-source unsupervised domain\nadaptation, where labeled data are drawn from multiple source domains and only\nunlabeled data from a target domain. To address potential distribution shifts,\nwe propose a novel Conditional Group Distributionally Robust Optimization\n(CG-DRO) framework that learns a classifier by minimizing the worst-case\ncross-entropy loss over the convex combinations of the conditional outcome\ndistributions from the sources. To solve the resulting minimax problem, we\ndevelop an efficient Mirror Prox algorithm, where we employ a double machine\nlearning procedure to estimate the risk function. This ensures that the errors\nof the machine learning estimators for the nuisance models enter only at\nhigher-order rates, thereby preserving statistical efficiency under covariate\nshift. We establish fast statistical convergence rates for the estimator by\nconstructing two surrogate minimax optimization problems that serve as\ntheoretical bridges. A distinguishing challenge for CG-DRO is the emergence of\nnonstandard asymptotics: the empirical estimator may fail to converge to a\nstandard limiting distribution due to boundary effects and system instability.\nTo address this, we introduce a perturbation-based inference procedure that\nenables uniformly valid inference, including confidence interval construction\nand hypothesis testing.",
      "published": "July 14, 2025",
      "categories": [
        "stat.ME",
        "math.OC",
        "math.ST",
        "stat.ML",
        "stat.TH"
      ],
      "pdf_link": "http://arxiv.org/pdf/2507.09905v1",
      "arxiv_url": "http://arxiv.org/abs/2507.09905v1"
    }
  ]
}