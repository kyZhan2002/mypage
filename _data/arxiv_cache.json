{
  "timestamp": 1751592435,
  "papers": [
    {
      "title": "Phase Transition in Nonparametric Minimax Rates for Covariate Shifts on\n  Approximate Manifolds",
      "authors": [
        "Yuyao Wang",
        "Nabarun Deb",
        "Debarghya Mukherjee"
      ],
      "abstract": "We study nonparametric regression under covariate shift with structured data,\nwhere a small amount of labeled target data is supplemented by a large labeled\nsource dataset. In many real-world settings, the covariates in the target\ndomain lie near a low-dimensional manifold within the support of the source,\ne.g., personalized handwritten digits (target) within a large, high-dimensional\nimage repository (source). Since density ratios may not exist in these\nsettings, standard transfer learning techniques often fail to leverage such\nstructure. This necessitates the development of methods that exploit both the\nsize of the source dataset and the structured nature of the target.\n  Motivated by this, we establish new minimax rates under covariate shift for\nestimating a regression function in a general H\\\"older class, assuming the\ntarget distribution lies near -- but not exactly on -- a smooth submanifold of\nthe source. General smoothness helps reduce the curse of dimensionality when\nthe target function is highly regular, while approximate manifolds capture\nrealistic, noisy data. We identify a phase transition in the minimax rate of\nestimation governed by the distance to the manifold, source and target sample\nsizes, function smoothness, and intrinsic versus ambient dimensions. We propose\na local polynomial regression estimator that achieves optimal rates on either\nside of the phase transition boundary. Additionally, we construct a fully\nadaptive procedure that adjusts to unknown smoothness and intrinsic dimension,\nand attains nearly optimal rates. Our results unify and extend key threads in\ncovariate shift, manifold learning, and adaptive nonparametric inference.",
      "published": "July 01, 2025",
      "categories": [
        "math.ST",
        "stat.TH",
        "62G05, 62H12"
      ],
      "pdf_link": "http://arxiv.org/pdf/2507.00889v1",
      "arxiv_url": "http://arxiv.org/abs/2507.00889v1"
    },
    {
      "title": "CoMMiT: Co-informed inference of microbiome-metabolome interactions via\n  transfer learning",
      "authors": [
        "Leiyue Li",
        "Chenglong Ye",
        "Tim Randolph",
        "Meredith Hullar",
        "Johanna Lampe",
        "Marian Neuhouser",
        "Daniel Raftery",
        "Yue Wang"
      ],
      "abstract": "Recent multi-omic microbiome studies enable integrative analysis of microbes\nand metabolites, uncovering their associations with various host conditions.\nSuch analyses require multivariate models capable of accounting for the complex\ncorrelation structures between microbes and metabolites. However, existing\nmultivariate models often suffer from low statistical power for detecting\nmicrobiome-metabolome interactions due to small sample sizes and weak\nbiological signals. To address these challenges, we introduce CoMMiT,\nCo-informed inference of Microbiome-Metabolome Interactions via novel Transfer\nlearning models. Unlike conventional transfer-learning methods that borrow\ninformation from external datasets, CoMMiT leverages similarities across\nmetabolites within a single cohort, reducing the risk of negative transfer\noften caused by differences in sequencing platforms and bioinformatic pipelines\nacross studies. CoMMiT operates under the flexible assumption that auxiliary\nmetabolites are collectively informative for the target metabolite, without\nrequiring individual auxiliary metabolites to be informative. CoMMiT uses a\nnovel data-driven approach to selecting the optimal set of auxiliary\nmetabolites. Using this optimal set, CoMMiT employs a de-biasing framework to\nenable efficient calculation of p-values, facilitating the identification of\nstatistically significant microbiome-metabolome interactions. Applying CoMMiT\nto a feeding study reveals biologically meaningful microbiome-metabolome\ninteractions under a low glycemic load diet, demonstrating the diet-host link\nthrough gut metabolism.",
      "published": "June 30, 2025",
      "categories": [
        "stat.ME",
        "q-bio.GN",
        "stat.AP"
      ],
      "pdf_link": "http://arxiv.org/pdf/2506.24013v1",
      "arxiv_url": "http://arxiv.org/abs/2506.24013v1"
    },
    {
      "title": "Are Fast Methods Stable in Adversarially Robust Transfer Learning?",
      "authors": [
        "Joshua C. Zhao",
        "Saurabh Bagchi"
      ],
      "abstract": "Transfer learning is often used to decrease the computational cost of model\ntraining, as fine-tuning a model allows a downstream task to leverage the\nfeatures learned from the pre-training dataset and quickly adapt them to a new\ntask. This is particularly useful for achieving adversarial robustness, as\nadversarially training models from scratch is very computationally expensive.\nHowever, high robustness in transfer learning still requires adversarial\ntraining during the fine-tuning phase, which requires up to an order of\nmagnitude more time than standard fine-tuning. In this work, we revisit the use\nof the fast gradient sign method (FGSM) in robust transfer learning to improve\nthe computational cost of adversarial fine-tuning. We surprisingly find that\nFGSM is much more stable in adversarial fine-tuning than when training from\nscratch. In particular, FGSM fine-tuning does not suffer from any issues with\ncatastrophic overfitting at standard perturbation budgets of $\\varepsilon=4$ or\n$\\varepsilon=8$. This stability is further enhanced with parameter-efficient\nfine-tuning methods, where FGSM remains stable even up to $\\varepsilon=32$ for\nlinear probing. We demonstrate how this stability translates into performance\nacross multiple datasets. Compared to fine-tuning with the more commonly used\nmethod of projected gradient descent (PGD), on average, FGSM only loses 0.39%\nand 1.39% test robustness for $\\varepsilon=4$ and $\\varepsilon=8$ while using\n$4\\times$ less training time. Surprisingly, FGSM may not only be a\nsignificantly more efficient alternative to PGD in adversarially robust\ntransfer learning but also a well-performing one.",
      "published": "June 27, 2025",
      "categories": [
        "cs.LG",
        "stat.ML"
      ],
      "pdf_link": "http://arxiv.org/pdf/2506.22602v1",
      "arxiv_url": "http://arxiv.org/abs/2506.22602v1"
    },
    {
      "title": "Duality and Policy Evaluation in Distributionally Robust Bayesian\n  Diffusion Control",
      "authors": [
        "Jose Blanchet",
        "Jiayi Cheng",
        "Hao Liu",
        "Yang Liu"
      ],
      "abstract": "We consider a Bayesian diffusion control problem of expected terminal utility\nmaximization. The controller imposes a prior distribution on the unknown drift\nof an underlying diffusion. The Bayesian optimal control, tracking the\nposterior distribution of the unknown drift, can be characterized explicitly.\nHowever, in practice, the prior will generally be incorrectly specified, and\nthe degree of model misspecification can have a significant impact on policy\nperformance. To mitigate this and reduce overpessimism, we introduce a\ndistributionally robust Bayesian control (DRBC) formulation in which the\ncontroller plays a game against an adversary who selects a prior in divergence\nneighborhood of a baseline prior. The adversarial approach has been studied in\neconomics and efficient algorithms have been proposed in static optimization\nsettings. We develop a strong duality result for our DRBC formulation.\nCombining these results together with tools from stochastic analysis, we are\nable to derive a loss that can be efficiently trained (as we demonstrate in our\nnumerical experiments) using a suitable neural network architecture. As a\nresult, we obtain an effective algorithm for computing the DRBC optimal\nstrategy. The methodology for computing the DRBC optimal strategy is greatly\nsimplified, as we show, in the important case in which the adversary chooses a\nprior from a Kullback-Leibler distributional uncertainty set.",
      "published": "June 24, 2025",
      "categories": [
        "math.OC",
        "math.PR",
        "q-fin.PM",
        "stat.ML"
      ],
      "pdf_link": "http://arxiv.org/pdf/2506.19294v2",
      "arxiv_url": "http://arxiv.org/abs/2506.19294v2"
    },
    {
      "title": "These Are Not All the Features You Are Looking For: A Fundamental\n  Bottleneck in Supervised Pretraining",
      "authors": [
        "Xingyu Alice Yang",
        "Jianyu Zhang",
        "L\u00e9on Bottou"
      ],
      "abstract": "Transfer learning is a cornerstone of modern machine learning, promising a\nway to adapt models pretrained on a broad mix of data to new tasks with minimal\nnew data. However, a significant challenge remains in ensuring that transferred\nfeatures are sufficient to handle unseen datasets, amplified by the difficulty\nof quantifying whether two tasks are \"related\". To address these challenges, we\nevaluate model transfer from a pretraining mixture to each of its component\ntasks, assessing whether pretrained features can match the performance of\ntask-specific direct training. We identify a fundamental limitation in deep\nlearning models -- an \"information saturation bottleneck\" -- where networks\nfail to learn new features once they encode similar competing features during\ntraining. When restricted to learning only a subset of key features during\npretraining, models will permanently lose critical features for transfer and\nperform inconsistently on data distributions, even components of the training\nmixture. Empirical evidence from published studies suggests that this\nphenomenon is pervasive in deep learning architectures -- factors such as data\ndistribution or ordering affect the features that current representation\nlearning methods can learn over time. This study suggests that relying solely\non large-scale networks may not be as effective as focusing on task-specific\ntraining, when available. We propose richer feature representations as a\npotential solution to better generalize across new datasets and, specifically,\npresent existing methods alongside a novel approach, the initial steps towards\naddressing this challenge.",
      "published": "June 23, 2025",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "pdf_link": "http://arxiv.org/pdf/2506.18221v2",
      "arxiv_url": "http://arxiv.org/abs/2506.18221v2"
    },
    {
      "title": "DRO-Augment Framework: Robustness by Synergizing Wasserstein\n  Distributionally Robust Optimization and Data Augmentation",
      "authors": [
        "Jiaming Hu",
        "Debarghya Mukherjee",
        "Ioannis Ch. Paschalidis"
      ],
      "abstract": "In many real-world applications, ensuring the robustness and stability of\ndeep neural networks (DNNs) is crucial, particularly for image classification\ntasks that encounter various input perturbations. While data augmentation\ntechniques have been widely adopted to enhance the resilience of a trained\nmodel against such perturbations, there remains significant room for\nimprovement in robustness against corrupted data and adversarial attacks\nsimultaneously. To address this challenge, we introduce DRO-Augment, a novel\nframework that integrates Wasserstein Distributionally Robust Optimization\n(W-DRO) with various data augmentation strategies to improve the robustness of\nthe models significantly across a broad spectrum of corruptions. Our method\noutperforms existing augmentation methods under severe data perturbations and\nadversarial attack scenarios while maintaining the accuracy on the clean\ndatasets on a range of benchmark datasets, including but not limited to\nCIFAR-10-C, CIFAR-100-C, MNIST, and Fashion-MNIST. On the theoretical side, we\nestablish novel generalization error bounds for neural networks trained using a\ncomputationally efficient, variation-regularized loss function closely related\nto the W-DRO problem.",
      "published": "June 22, 2025",
      "categories": [
        "stat.ML",
        "cs.CV",
        "cs.LG"
      ],
      "pdf_link": "http://arxiv.org/pdf/2506.17874v2",
      "arxiv_url": "http://arxiv.org/abs/2506.17874v2"
    },
    {
      "title": "On Design of Representative Distributionally Robust Formulations for\n  Evaluation of Tail Risk Measures",
      "authors": [
        "Anand Deo"
      ],
      "abstract": "Conditional Value-at-Risk (CVaR) is a risk measure widely used to quantify\nthe impact of extreme losses. Owing to the lack of representative samples CVaR\nis sensitive to the tails of the underlying distribution. In order to combat\nthis sensitivity, Distributionally Robust Optimization (DRO), which evaluates\nthe worst-case CVaR measure over a set of plausible data distributions is often\ndeployed. Unfortunately, an improper choice of the DRO formulation can lead to\na severe underestimation of tail risk. This paper aims at leveraging extreme\nvalue theory to arrive at a DRO formulation which leads to representative\nworst-case CVaR evaluations in that the above pitfall is avoided while\nsimultaneously, the worst case evaluation is not a gross over-estimate of the\ntrue CVaR. We demonstrate theoretically that even when there is paucity of\nsamples in the tail of the distribution, our formulation is readily\nimplementable from data, only requiring calibration of a single scalar\nparameter. We showcase that our formulation can be easily extended to provide\nrobustness to tail risk in multivariate applications as well as in the\nevaluation of other commonly used risk measures. Numerical illustrations on\nsynthetic and real-world data showcase the practical utility of our approach.",
      "published": "June 19, 2025",
      "categories": [
        "q-fin.RM",
        "math.PR",
        "stat.ME",
        "stat.ML"
      ],
      "pdf_link": "http://arxiv.org/pdf/2506.16230v1",
      "arxiv_url": "http://arxiv.org/abs/2506.16230v1"
    }
  ]
}