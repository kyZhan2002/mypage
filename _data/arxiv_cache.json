{
  "timestamp": 1765503496,
  "papers": [
    {
      "title": "Worst-case generation via minimax optimization in Wasserstein space",
      "authors": [
        "Xiuyuan Cheng",
        "Yao Xie",
        "Linglingzhi Zhu",
        "Yunqin Zhu"
      ],
      "abstract": "Worst-case generation plays a critical role in evaluating robustness and stress-testing systems under distribution shifts, in applications ranging from machine learning models to power grids and medical prediction systems. We develop a generative modeling framework for worst-case generation for a pre-specified risk, based on min-max optimization over continuous probability distributions, namely the Wasserstein space. Unlike traditional discrete distributionally robust optimization approaches, which often suffer from scalability issues, limited generalization, and costly worst-case inference, our framework exploits the Brenier theorem to characterize the least favorable (worst-case) distribution as the pushforward of a transport map from a continuous reference measure, enabling a continuous and expressive notion of risk-induced generation beyond classical discrete DRO formulations. Based on the min-max formulation, we propose a Gradient Descent Ascent (GDA)-type scheme that updates the decision model and the transport map in a single loop, establishing global convergence guarantees under mild regularity assumptions and possibly without convexity-concavity. We also propose to parameterize the transport map using a neural network that can be trained simultaneously with the GDA iterations by matching the transported training samples, thereby achieving a simulation-free approach. The efficiency of the proposed method as a risk-induced worst-case generator is validated by numerical experiments on synthetic and image data.",
      "published": "December 09, 2025",
      "categories": [
        "stat.ML",
        "cs.LG",
        "math.OC"
      ],
      "pdf_link": "https://arxiv.org/pdf/2512.08176v1",
      "arxiv_url": "https://arxiv.org/abs/2512.08176v1"
    },
    {
      "title": "Diagnosis-based mortality prediction for intensive care unit patients via transfer learning",
      "authors": [
        "Mengqi Xu",
        "Subha Maity",
        "Joel Dubin"
      ],
      "abstract": "In the intensive care unit, the underlying causes of critical illness vary substantially across diagnoses, yet prediction models accounting for diagnostic heterogeneity have not been systematically studied. To address the gap, we evaluate transfer learning approaches for diagnosis-specific mortality prediction and apply both GLM- and XGBoost-based models to the eICU Collaborative Research Database. Our results demonstrate that transfer learning consistently outperforms models trained only on diagnosis-specific data and those using a well-known ICU severity-of-illness score, i.e., APACHE IVa, alone, while also achieving better calibration than models trained on the pooled data. Our findings also suggest that the Youden cutoff is a more appropriate decision threshold than the conventional 0.5 for binary outcomes, and that transfer learning maintains consistently high predictive performance across various cutoff criteria.",
      "published": "December 06, 2025",
      "categories": [
        "cs.LG",
        "stat.AP"
      ],
      "pdf_link": "https://arxiv.org/pdf/2512.06511v1",
      "arxiv_url": "https://arxiv.org/abs/2512.06511v1"
    },
    {
      "title": "Spatiotemporal Satellite Image Downscaling with Transfer Encoders and Autoregressive Generative Models",
      "authors": [
        "Yang Xiang",
        "Jingwen Zhong",
        "Yige Yan",
        "Petros Koutrakis",
        "Eric Garshick",
        "Meredith Franklin"
      ],
      "abstract": "We present a transfer-learning generative downscaling framework to reconstruct fine resolution satellite images from coarse scale inputs. Our approach combines a lightweight U-Net transfer encoder with a diffusion-based generative model. The simpler U-Net is first pretrained on a long time series of coarse resolution data to learn spatiotemporal representations; its encoder is then frozen and transferred to a larger downscaling model as physically meaningful latent features. Our application uses NASA's MERRA-2 reanalysis as the low resolution source domain (50 km) and the GEOS-5 Nature Run (G5NR) as the high resolution target (7 km). Our study area included a large area in Asia, which was made computationally tractable by splitting into two subregions and four seasons. We conducted domain similarity analysis using Wasserstein distances confirmed minimal distributional shift between MERRA-2 and G5NR, validating the safety of parameter frozen transfer. Across seasonal regional splits, our model achieved excellent performance (R2 = 0.65 to 0.94), outperforming comparison models including deterministic U-Nets, variational autoencoders, and prior transfer learning baselines. Out of data evaluations using semivariograms, ACF/PACF, and lag-based RMSE/R2 demonstrated that the predicted downscaled images preserved physically consistent spatial variability and temporal autocorrelation, enabling stable autoregressive reconstruction beyond the G5NR record. These results show that transfer enhanced diffusion models provide a robust and physically coherent solution for downscaling a long time series of coarse resolution images with limited training periods. This advancement has significant implications for improving environmental exposure assessment and long term environmental monitoring.",
      "published": "December 01, 2025",
      "categories": [
        "cs.CV",
        "cs.LG",
        "stat.ML"
      ],
      "pdf_link": "https://arxiv.org/pdf/2512.05139v1",
      "arxiv_url": "https://arxiv.org/abs/2512.05139v1"
    },
    {
      "title": "Self-Supervised Dynamical System Representations for Physiological Time-Series",
      "authors": [
        "Yenho Chen",
        "Maxwell A. Xu",
        "James M. Rehg",
        "Christopher J. Rozell"
      ],
      "abstract": "The effectiveness of self-supervised learning (SSL) for physiological time series depends on the ability of a pretraining objective to preserve information about the underlying physiological state while filtering out unrelated noise. However, existing strategies are limited due to reliance on heuristic principles or poorly constrained generative tasks. To address this limitation, we propose a pretraining framework that exploits the information structure of a dynamical systems generative model across multiple time-series. This framework reveals our key insight that class identity can be efficiently captured by extracting information about the generative variables related to the system parameters shared across similar time series samples, while noise unique to individual samples should be discarded. Building on this insight, we propose PULSE, a cross-reconstruction-based pretraining objective for physiological time series datasets that explicitly extracts system information while discarding non-transferrable sample-specific ones. We establish theory that provides sufficient conditions for the system information to be recovered, and empirically validate it using a synthetic dynamical systems experiment. Furthermore, we apply our method to diverse real-world datasets, demonstrating that PULSE learns representations that can broadly distinguish semantic classes, increase label efficiency, and improve transfer learning.",
      "published": "November 28, 2025",
      "categories": [
        "cs.LG",
        "stat.ML"
      ],
      "pdf_link": "https://arxiv.org/pdf/2512.00239v1",
      "arxiv_url": "https://arxiv.org/abs/2512.00239v1"
    },
    {
      "title": "Portfolio Optimization via Transfer Learning",
      "authors": [
        "Kexin Wang",
        "Xiaomeng Zhang",
        "Xinyu Zhang"
      ],
      "abstract": "Recognizing that asset markets generally exhibit shared informational characteristics, we develop a portfolio strategy based on transfer learning that leverages cross-market information to enhance the investment performance in the market of interest by forward validation. Our strategy asymptotically identifies and utilizes the informative datasets, selectively incorporating valid information while discarding the misleading information. This enables our strategy to achieve the maximum Sharpe ratio asymptotically. The promising performance is demonstrated by numerical studies and case studies of two portfolios: one consisting of stocks dual-listed in A-shares and H-shares, and another comprising equities from various industries of the United States.",
      "published": "November 26, 2025",
      "categories": [
        "q-fin.PM",
        "stat.AP"
      ],
      "pdf_link": "https://arxiv.org/pdf/2511.21221v1",
      "arxiv_url": "https://arxiv.org/abs/2511.21221v1"
    }
  ]
}