{
  "timestamp": 1752976156,
  "papers": [
    {
      "title": "Improving physics-informed neural network extrapolation via transfer\n  learning and adaptive activation functions",
      "authors": [
        "Athanasios Papastathopoulos-Katsaros",
        "Alexandra Stavrianidi",
        "Zhandong Liu"
      ],
      "abstract": "Physics-Informed Neural Networks (PINNs) are deep learning models that\nincorporate the governing physical laws of a system into the learning process,\nmaking them well-suited for solving complex scientific and engineering\nproblems. Recently, PINNs have gained widespread attention as a powerful\nframework for combining physical principles with data-driven modeling to\nimprove prediction accuracy. Despite their successes, however, PINNs often\nexhibit poor extrapolation performance outside the training domain and are\nhighly sensitive to the choice of activation functions (AFs). In this paper, we\nintroduce a transfer learning (TL) method to improve the extrapolation\ncapability of PINNs. Our approach applies transfer learning (TL) within an\nextended training domain, using only a small number of carefully selected\ncollocation points. Additionally, we propose an adaptive AF that takes the form\nof a linear combination of standard AFs, which improves both the robustness and\naccuracy of the model. Through a series of experiments, we demonstrate that our\nmethod achieves an average of 40% reduction in relative L2 error and an average\nof 50% reduction in mean absolute error in the extrapolation domain, all\nwithout a significant increase in computational cost. The code is available at\nhttps://github.com/LiuzLab/PINN-extrapolation .",
      "published": "July 16, 2025",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NA",
        "math.DS",
        "math.NA",
        "stat.ML"
      ],
      "pdf_link": "http://arxiv.org/pdf/2507.12659v1",
      "arxiv_url": "http://arxiv.org/abs/2507.12659v1"
    },
    {
      "title": "Statistical Inference for Conditional Group Distributionally Robust\n  Optimization with Cross-Entropy Loss",
      "authors": [
        "Zijian Guo",
        "Zhenyu Wang",
        "Yifan Hu",
        "Francis Bach"
      ],
      "abstract": "In multi-source learning with discrete labels, distributional heterogeneity\nacross domains poses a central challenge to developing predictive models that\ntransfer reliably to unseen domains. We study multi-source unsupervised domain\nadaptation, where labeled data are drawn from multiple source domains and only\nunlabeled data from a target domain. To address potential distribution shifts,\nwe propose a novel Conditional Group Distributionally Robust Optimization\n(CG-DRO) framework that learns a classifier by minimizing the worst-case\ncross-entropy loss over the convex combinations of the conditional outcome\ndistributions from the sources. To solve the resulting minimax problem, we\ndevelop an efficient Mirror Prox algorithm, where we employ a double machine\nlearning procedure to estimate the risk function. This ensures that the errors\nof the machine learning estimators for the nuisance models enter only at\nhigher-order rates, thereby preserving statistical efficiency under covariate\nshift. We establish fast statistical convergence rates for the estimator by\nconstructing two surrogate minimax optimization problems that serve as\ntheoretical bridges. A distinguishing challenge for CG-DRO is the emergence of\nnonstandard asymptotics: the empirical estimator may fail to converge to a\nstandard limiting distribution due to boundary effects and system instability.\nTo address this, we introduce a perturbation-based inference procedure that\nenables uniformly valid inference, including confidence interval construction\nand hypothesis testing.",
      "published": "July 14, 2025",
      "categories": [
        "stat.ME",
        "math.OC",
        "math.ST",
        "stat.ML",
        "stat.TH"
      ],
      "pdf_link": "http://arxiv.org/pdf/2507.09905v1",
      "arxiv_url": "http://arxiv.org/abs/2507.09905v1"
    },
    {
      "title": "The Bayesian Approach to Continual Learning: An Overview",
      "authors": [
        "Tameem Adel"
      ],
      "abstract": "Continual learning is an online paradigm where a learner continually\naccumulates knowledge from different tasks encountered over sequential time\nsteps. Importantly, the learner is required to extend and update its knowledge\nwithout forgetting about the learning experience acquired from the past, and\nwhile avoiding the need to retrain from scratch. Given its sequential nature\nand its resemblance to the way humans think, continual learning offers an\nopportunity to address several challenges which currently stand in the way of\nwidening the range of applicability of deep models to further real-world\nproblems. The continual need to update the learner with data arriving\nsequentially strikes inherent congruence between continual learning and\nBayesian inference which provides a principal platform to keep updating the\nprior beliefs of a model given new data, without completely forgetting the\nknowledge acquired from the old data. This survey inspects different settings\nof Bayesian continual learning, namely task-incremental learning and\nclass-incremental learning. We begin by discussing definitions of continual\nlearning along with its Bayesian setting, as well as the links with related\nfields, such as domain adaptation, transfer learning and meta-learning.\nAfterwards, we introduce a taxonomy offering a comprehensive categorization of\nalgorithms belonging to the Bayesian continual learning paradigm. Meanwhile, we\nanalyze the state-of-the-art while zooming in on some of the most prominent\nBayesian continual learning algorithms to date. Furthermore, we shed some light\non links between continual learning and developmental psychology, and\ncorrespondingly introduce analogies between both fields. We follow that with a\ndiscussion of current challenges, and finally conclude with potential areas for\nfuture research on Bayesian continual learning.",
      "published": "July 11, 2025",
      "categories": [
        "stat.ML",
        "cs.LG"
      ],
      "pdf_link": "http://arxiv.org/pdf/2507.08922v1",
      "arxiv_url": "http://arxiv.org/abs/2507.08922v1"
    },
    {
      "title": "Transfer Learning in Infinite Width Feature Learning Networks",
      "authors": [
        "Clarissa Lauditi",
        "Blake Bordelon",
        "Cengiz Pehlevan"
      ],
      "abstract": "We develop a theory of transfer learning in infinitely wide neural networks\nwhere both the pretraining (source) and downstream (target) task can operate in\na feature learning regime. We analyze both the Bayesian framework, where\nlearning is described by a posterior distribution over the weights, and\ngradient flow training of randomly initialized networks trained with weight\ndecay. Both settings track how representations evolve in both source and target\ntasks. The summary statistics of these theories are adapted feature kernels\nwhich, after transfer learning, depend on data and labels from both source and\ntarget tasks. Reuse of features during transfer learning is controlled by an\nelastic weight coupling which controls the reliance of the network on features\nlearned during training on the source task. We apply our theory to linear and\npolynomial regression tasks as well as real datasets. Our theory and\nexperiments reveal interesting interplays between elastic weight coupling,\nfeature learning strength, dataset size, and source and target task alignment\non the utility of transfer learning.",
      "published": "July 06, 2025",
      "categories": [
        "cs.LG",
        "cond-mat.dis-nn",
        "stat.ML"
      ],
      "pdf_link": "http://arxiv.org/pdf/2507.04448v1",
      "arxiv_url": "http://arxiv.org/abs/2507.04448v1"
    },
    {
      "title": "Mixed-Sample SGD: an End-to-end Analysis of Supervised Transfer Learning",
      "authors": [
        "Yuyang Deng",
        "Samory Kpotufe"
      ],
      "abstract": "Theoretical works on supervised transfer learning (STL) -- where the learner\nhas access to labeled samples from both source and target distributions -- have\nfor the most part focused on statistical aspects of the problem, while\nefficient optimization has received less attention. We consider the problem of\ndesigning an SGD procedure for STL that alternates sampling between source and\ntarget data, while maintaining statistical transfer guarantees without prior\nknowledge of the quality of the source data. A main algorithmic difficulty is\nin understanding how to design such an adaptive sub-sampling mechanism at each\nSGD step, to automatically gain from the source when it is informative, or bias\ntowards the target and avoid negative transfer when the source is less\ninformative.\n  We show that, such a mixed-sample SGD procedure is feasible for general\nprediction tasks with convex losses, rooted in tracking an abstract sequence of\nconstrained convex programs that serve to maintain the desired transfer\nguarantees.\n  We instantiate these results in the concrete setting of linear regression\nwith square loss, and show that the procedure converges, with $1/\\sqrt{T}$\nrate, to a solution whose statistical performance on the target is adaptive to\nthe a priori unknown quality of the source. Experiments with synthetic and real\ndatasets support the theory.",
      "published": "July 06, 2025",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "pdf_link": "http://arxiv.org/pdf/2507.04194v1",
      "arxiv_url": "http://arxiv.org/abs/2507.04194v1"
    }
  ]
}