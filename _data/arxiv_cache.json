{
  "timestamp": 1766021164,
  "papers": [
    {
      "title": "Multi-fidelity aerodynamic data fusion by autoencoder transfer learning",
      "authors": [
        "Javier Nieto-Centenero",
        "Esther Andr\u00e9s",
        "Rodrigo Castellanos"
      ],
      "abstract": "Accurate aerodynamic prediction often relies on high-fidelity simulations; however, their prohibitive computational costs severely limit their applicability in data-driven modeling. This limitation motivates the development of multi-fidelity strategies that leverage inexpensive low-fidelity information without compromising accuracy. Addressing this challenge, this work presents a multi-fidelity deep learning framework that combines autoencoder-based transfer learning with a newly developed Multi-Split Conformal Prediction (MSCP) strategy to achieve uncertainty-aware aerodynamic data fusion under extreme data scarcity. The methodology leverages abundant Low-Fidelity (LF) data to learn a compact latent physics representation, which acts as a frozen knowledge base for a decoder that is subsequently fine-tuned using scarce HF samples. Tested on surface-pressure distributions for NACA airfoils (2D) and a transonic wing (3D) databases, the model successfully corrects LF deviations and achieves high-accuracy pressure predictions using minimal HF training data. Furthermore, the MSCP framework produces robust, actionable uncertainty bands with pointwise coverage exceeding 95%. By combining extreme data efficiency with uncertainty quantification, this work offers a scalable and reliable solution for aerodynamic regression in data-scarce environments.",
      "published": "December 15, 2025",
      "categories": [
        "cs.LG",
        "physics.flu-dyn",
        "stat.ML"
      ],
      "pdf_link": "https://arxiv.org/pdf/2512.13069v1",
      "arxiv_url": "https://arxiv.org/abs/2512.13069v1"
    },
    {
      "title": "TRACER: Transfer Learning based Real-time Adaptation for Clinical Evolving Risk",
      "authors": [
        "Mengying Yan",
        "Ziye Tian",
        "Siqi Li",
        "Nan Liu",
        "Benjamin A. Goldstein",
        "Molei Liu",
        "Chuan Hong"
      ],
      "abstract": "Clinical decision support tools built on electronic health records often experience performance drift due to temporal population shifts, particularly when changes in the clinical environment initially affect only a subset of patients, resulting in a transition to mixed populations. Such case-mix changes commonly arise following system-level operational updates or the emergence of new diseases, such as COVID-19. We propose TRACER (Transfer Learning-based Real-time Adaptation for Clinical Evolving Risk), a framework that identifies encounter-level transition membership and adapts predictive models using transfer learning without full retraining. In simulation studies, TRACER outperformed static models trained on historical or contemporary data. In a real-world application predicting hospital admission following emergency department visits across the COVID-19 transition, TRACER improved both discrimination and calibration. TRACER provides a scalable approach for maintaining robust predictive performance under evolving and heterogeneous clinical conditions.",
      "published": "December 14, 2025",
      "categories": [
        "cs.LG",
        "stat.ME"
      ],
      "pdf_link": "https://arxiv.org/pdf/2512.12795v1",
      "arxiv_url": "https://arxiv.org/abs/2512.12795v1"
    },
    {
      "title": "Iterative Sampling Methods for Sinkhorn Distributionally Robust Optimization",
      "authors": [
        "Jie Wang"
      ],
      "abstract": "Distributionally robust optimization (DRO) has emerged as a powerful paradigm for reliable decision-making under uncertainty. This paper focuses on DRO with ambiguity sets defined via the Sinkhorn discrepancy: an entropy-regularized Wasserstein distance, referred to as Sinkhorn DRO. Existing work primarily addresses Sinkhorn DRO from a dual perspective, leveraging its formulation as a conditional stochastic optimization problem, for which many stochastic gradient methods are applicable. However, the theoretical analyses of such methods often rely on the boundedness of the loss function, and it is indirect to obtain the worst-case distribution associated with Sinkhorn DRO. In contrast, we study Sinkhorn DRO from the primal perspective, by reformulating it as a bilevel program with several infinite-dimensional lower-level subproblems over probability space. This formulation enables us to simultaneously obtain the optimal robust decision and the worst-case distribution, which is valuable in practical settings, such as generating stress-test scenarios or designing robust learning algorithms. We propose both double-loop and single-loop sampling-based algorithms with theoretical guarantees to solve this bilevel program. Finally, we demonstrate the effectiveness of our approach through a numerical study on adversarial classification.",
      "published": "December 14, 2025",
      "categories": [
        "stat.ML",
        "cs.LG"
      ],
      "pdf_link": "https://arxiv.org/pdf/2512.12550v1",
      "arxiv_url": "https://arxiv.org/abs/2512.12550v1"
    },
    {
      "title": "Worst-case generation via minimax optimization in Wasserstein space",
      "authors": [
        "Xiuyuan Cheng",
        "Yao Xie",
        "Linglingzhi Zhu",
        "Yunqin Zhu"
      ],
      "abstract": "Worst-case generation plays a critical role in evaluating robustness and stress-testing systems under distribution shifts, in applications ranging from machine learning models to power grids and medical prediction systems. We develop a generative modeling framework for worst-case generation for a pre-specified risk, based on min-max optimization over continuous probability distributions, namely the Wasserstein space. Unlike traditional discrete distributionally robust optimization approaches, which often suffer from scalability issues, limited generalization, and costly worst-case inference, our framework exploits the Brenier theorem to characterize the least favorable (worst-case) distribution as the pushforward of a transport map from a continuous reference measure, enabling a continuous and expressive notion of risk-induced generation beyond classical discrete DRO formulations. Based on the min-max formulation, we propose a Gradient Descent Ascent (GDA)-type scheme that updates the decision model and the transport map in a single loop, establishing global convergence guarantees under mild regularity assumptions and possibly without convexity-concavity. We also propose to parameterize the transport map using a neural network that can be trained simultaneously with the GDA iterations by matching the transported training samples, thereby achieving a simulation-free approach. The efficiency of the proposed method as a risk-induced worst-case generator is validated by numerical experiments on synthetic and image data.",
      "published": "December 09, 2025",
      "categories": [
        "stat.ML",
        "cs.LG",
        "math.OC"
      ],
      "pdf_link": "https://arxiv.org/pdf/2512.08176v1",
      "arxiv_url": "https://arxiv.org/abs/2512.08176v1"
    },
    {
      "title": "Diagnosis-based mortality prediction for intensive care unit patients via transfer learning",
      "authors": [
        "Mengqi Xu",
        "Subha Maity",
        "Joel Dubin"
      ],
      "abstract": "In the intensive care unit, the underlying causes of critical illness vary substantially across diagnoses, yet prediction models accounting for diagnostic heterogeneity have not been systematically studied. To address the gap, we evaluate transfer learning approaches for diagnosis-specific mortality prediction and apply both GLM- and XGBoost-based models to the eICU Collaborative Research Database. Our results demonstrate that transfer learning consistently outperforms models trained only on diagnosis-specific data and those using a well-known ICU severity-of-illness score, i.e., APACHE IVa, alone, while also achieving better calibration than models trained on the pooled data. Our findings also suggest that the Youden cutoff is a more appropriate decision threshold than the conventional 0.5 for binary outcomes, and that transfer learning maintains consistently high predictive performance across various cutoff criteria.",
      "published": "December 06, 2025",
      "categories": [
        "cs.LG",
        "stat.AP"
      ],
      "pdf_link": "https://arxiv.org/pdf/2512.06511v1",
      "arxiv_url": "https://arxiv.org/abs/2512.06511v1"
    }
  ]
}