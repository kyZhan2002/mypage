{
  "timestamp": 1757035115,
  "papers": [
    {
      "title": "Speech transformer models for extracting information from baby cries",
      "authors": [
        "Guillem Bonafos",
        "J\u00e9remy Rouch",
        "L\u00e9ny Lego",
        "David Reby",
        "Hugues Patural",
        "Nicolas Mathevon",
        "R\u00e9my Emonet"
      ],
      "abstract": "Transfer learning using latent representations from pre-trained speech models\nachieves outstanding performance in tasks where labeled data is scarce.\nHowever, their applicability to non-speech data and the specific acoustic\nproperties encoded in these representations remain largely unexplored. In this\nstudy, we investigate both aspects. We evaluate five pre-trained speech models\non eight baby cries datasets, encompassing 115 hours of audio from 960 babies.\nFor each dataset, we assess the latent representations of each model across all\navailable classification tasks. Our results demonstrate that the latent\nrepresentations of these models can effectively classify human baby cries and\nencode key information related to vocal source instability and identity of the\ncrying baby. In addition, a comparison of the architectures and training\nstrategies of these models offers valuable insights for the design of future\nmodels tailored to similar tasks, such as emotion detection.",
      "published": "September 02, 2025",
      "categories": [
        "cs.SD",
        "cs.LG",
        "stat.AP"
      ],
      "pdf_link": "http://arxiv.org/pdf/2509.02259v1",
      "arxiv_url": "http://arxiv.org/abs/2509.02259v1"
    },
    {
      "title": "Transfer Learning for Classification under Decision Rule Drift with\n  Application to Optimal Individualized Treatment Rule Estimation",
      "authors": [
        "Xiaohan Wang",
        "Yang Ning"
      ],
      "abstract": "In this paper, we extend the transfer learning classification framework from\nregression function-based methods to decision rules. We propose a novel\nmethodology for modeling posterior drift through Bayes decision rules. By\nexploiting the geometric transformation of the Bayes decision boundary, our\nmethod reformulates the problem as a low-dimensional empirical risk\nminimization problem. Under mild regularity conditions, we establish the\nconsistency of our estimators and derive the risk bounds. Moreover, we\nillustrate the broad applicability of our method by adapting it to the\nestimation of optimal individualized treatment rules. Extensive simulation\nstudies and analyses of real-world data further demonstrate both superior\nperformance and robustness of our approach.",
      "published": "August 28, 2025",
      "categories": [
        "stat.ML",
        "cs.LG",
        "math.ST",
        "stat.ME",
        "stat.TH"
      ],
      "pdf_link": "http://arxiv.org/pdf/2508.20942v1",
      "arxiv_url": "http://arxiv.org/abs/2508.20942v1"
    },
    {
      "title": "A nonstationary spatial model of PM2.5 with localized transfer learning\n  from numerical model output",
      "authors": [
        "Wenlong Gong",
        "Brian J. Reich",
        "Joseph Guinness"
      ],
      "abstract": "Ambient air pollution measurements from regulatory monitoring networks are\nroutinely used to support epidemiologic studies and environmental policy\ndecision making. However, regulatory monitors are spatially sparse and\npreferentially located in areas with large populations. Numerical air pollution\nmodel output can be leveraged into the inference and prediction of air\npollution data combining with measurements from monitors. Nonstationary\ncovariance functions allow the model to adapt to spatial surfaces whose\nvariability changes with location like air pollution data. In the paper, we\nemploy localized covariance parameters learned from the numerical output model\nto knit together into a global nonstationary covariance, to incorporate in a\nfully Bayesian model. We model the nonstationary structure in a computationally\nefficient way to make the Bayesian model scalable.",
      "published": "August 21, 2025",
      "categories": [
        "stat.AP",
        "stat.CO",
        "stat.ME"
      ],
      "pdf_link": "http://arxiv.org/pdf/2508.15978v1",
      "arxiv_url": "http://arxiv.org/abs/2508.15978v1"
    },
    {
      "title": "Diffusion-Driven High-Dimensional Variable Selection",
      "authors": [
        "Minjie Wang",
        "Xiaotong Shen",
        "Wei Pan"
      ],
      "abstract": "Variable selection for high-dimensional, highly correlated data has long been\na challenging problem, often yielding unstable and unreliable models. We\npropose a resample-aggregate framework that exploits diffusion models' ability\nto generate high-fidelity synthetic data. Specifically, we draw multiple\npseudo-data sets from a diffusion model fitted to the original data, apply any\noff-the-shelf selector (e.g., lasso or SCAD), and store the resulting inclusion\nindicators and coefficients. Aggregating across replicas produces a stable\nsubset of predictors with calibrated stability scores for variable selection.\nTheoretically, we show that the proposed method is selection consistent under\nmild assumptions. Because the generative model imports knowledge from large\npre-trained weights, the procedure naturally benefits from transfer learning,\nboosting power when the observed sample is small or noisy. We also extend the\nframework of aggregating synthetic data to other model selection problems,\nincluding graphical model selection, and statistical inference that supports\nvalid confidence intervals and hypothesis tests. Extensive simulations show\nconsistent gains over the lasso, stability selection, and knockoff baselines,\nespecially when predictors are strongly correlated, achieving higher\ntrue-positive rates and lower false-discovery proportions. By coupling\ndiffusion-based data augmentation with principled aggregation, our method\nadvances variable selection methodology and broadens the toolkit for\ninterpretable, statistically rigorous analysis in complex scientific\napplications.",
      "published": "August 19, 2025",
      "categories": [
        "stat.ME",
        "stat.ML"
      ],
      "pdf_link": "http://arxiv.org/pdf/2508.13890v1",
      "arxiv_url": "http://arxiv.org/abs/2508.13890v1"
    }
  ]
}