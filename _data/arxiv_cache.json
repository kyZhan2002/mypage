{
  "timestamp": 1739927634,
  "papers": [
    {
      "title": "PreAdaptFWI: Pretrained-Based Adaptive Residual Learning for\n  Full-Waveform Inversion Without Dataset Dependency",
      "authors": [
        "Xintong Dong",
        "Zhengyi Yuan",
        "Jun Lin",
        "Shiqi Dong",
        "Xunqian Tong",
        "Yue Li"
      ],
      "abstract": "Full-waveform inversion (FWI) is a method that utilizes seismic data to\ninvert the physical parameters of subsurface media by minimizing the difference\nbetween simulated and observed waveforms. Due to its ill-posed nature, FWI is\nsusceptible to getting trapped in local minima. Consequently, various research\nefforts have attempted to combine neural networks with FWI to stabilize the\ninversion process. This study presents a simple yet effective training\nframework that is independent of dataset reliance and requires only moderate\npre-training on a simple initial model to stabilize network outputs. During the\ntransfer learning phase, the conventional FWI gradients will simultaneously\nupdate both the neural network and the proposed adaptive residual learning\nmodule, which learns the residual mapping of large-scale distribution features\nin the network's output, rather than directly fitting the target mapping.\nThrough this synergistic training paradigm, the proposed algorithm effectively\ninfers the physically-informed prior knowledge into a global representation of\nstratigraphic distribution, as well as capturing subtle variations in\ninter-layer velocities within local details, thereby escaping local optima.\nEvaluating the method on two benchmark models under various conditions,\nincluding absent low-frequency data, noise interference, and differing initial\nmodels, along with corresponding ablation experiments, consistently\ndemonstrates the superiority of the proposed approach.",
      "published": "February 17, 2025",
      "categories": [
        "physics.geo-ph",
        "cs.LG"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.11913v1",
      "arxiv_url": "http://arxiv.org/abs/2502.11913v1"
    },
    {
      "title": "On Data-Driven Robust Optimization With Multiple Uncertainty Subsets:\n  Unified Uncertainty Set Representation and Mitigating Conservatism",
      "authors": [
        "Yun Li",
        "Neil Yorke-Smith",
        "Tamas Keviczky"
      ],
      "abstract": "Constructing uncertainty sets as unions of multiple subsets has emerged as an\neffective approach for creating compact and flexible uncertainty\nrepresentations in data-driven robust optimization (RO). This paper focuses on\ntwo separate research questions. The first concerns the computational challenge\nin applying these uncertainty sets in RO-based predictive control. To address\nthis, a monolithic mixed-integer representation of the uncertainty set is\nproposed to uniformly describe the union of multiple subsets, enabling the\ncomputation of the worst-case uncertainty scenario across all subsets within a\nsingle mixed-integer linear programming (MILP) problem. The second research\nquestion focuses on mitigating the conservatism of conventional RO formulations\nby leveraging the structure of the uncertainty set. To achieve this, a novel\nobjective function is proposed to exploit the uncertainty set structure and\nintegrate the existing RO and distributionally robust optimization (DRO)\nformulations, yielding less conservative solutions than conventional RO\nformulations while avoiding the high-dimensional continuous uncertainty\ndistributions and incurring high computational burden typically associated with\nexisting DRO formulations. Given the proposed formulations, numerically\nefficient computation methods based on column-and-constraint generation (CCG)\nare also developed. Extensive simulations across three case studies are\nperformed to demonstrate the effectiveness of the proposed schemes.",
      "published": "February 17, 2025",
      "categories": [
        "math.OC",
        "cs.SY",
        "eess.SY"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.11867v1",
      "arxiv_url": "http://arxiv.org/abs/2502.11867v1"
    },
    {
      "title": "M-ABSA: A Multilingual Dataset for Aspect-Based Sentiment Analysis",
      "authors": [
        "Chengyan Wu",
        "Bolei Ma",
        "Yihong Liu",
        "Zheyu Zhang",
        "Ningyuan Deng",
        "Yanshu Li",
        "Baolan Chen",
        "Yi Zhang",
        "Barbara Plank",
        "Yun Xue"
      ],
      "abstract": "Aspect-based sentiment analysis (ABSA) is a crucial task in information\nextraction and sentiment analysis, aiming to identify aspects with associated\nsentiment elements in text. However, existing ABSA datasets are predominantly\nEnglish-centric, limiting the scope for multilingual evaluation and research.\nTo bridge this gap, we present M-ABSA, a comprehensive dataset spanning 7\ndomains and 21 languages, making it the most extensive multilingual parallel\ndataset for ABSA to date. Our primary focus is on triplet extraction, which\ninvolves identifying aspect terms, aspect categories, and sentiment polarities.\nThe dataset is constructed through an automatic translation process with human\nreview to ensure quality. We perform extensive experiments using various\nbaselines to assess performance and compatibility on M-ABSA. Our empirical\nfindings highlight that the dataset enables diverse evaluation tasks, such as\nmultilingual and multi-domain transfer learning, and large language model\nevaluation, underscoring its inclusivity and its potential to drive\nadvancements in multilingual ABSA research.",
      "published": "February 17, 2025",
      "categories": [
        "cs.CL"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.11824v1",
      "arxiv_url": "http://arxiv.org/abs/2502.11824v1"
    },
    {
      "title": "Robust Optimization of Rank-Dependent Models with Uncertain\n  Probabilities",
      "authors": [
        "Guanyu Jin",
        "Roger J. A. Laeven",
        "Dick den Hertog"
      ],
      "abstract": "This paper studies distributionally robust optimization for a large class of\nrisk measures with ambiguity sets defined by $\\phi$-divergences. The risk\nmeasures are allowed to be non-linear in probabilities, are represented by a\nChoquet integral possibly induced by a probability weighting function, and\ninclude many well-known examples (for example, CVaR, Mean-Median Deviation,\nGini-type). Optimization for this class of robust risk measures is challenging\ndue to their rank-dependent nature. We show that for many types of probability\nweighting functions including concave, convex and inverse $S$-shaped, the\nrobust optimization problem can be reformulated into a rank-independent\nproblem. In the case of a concave probability weighting function, the problem\ncan be further reformulated into a convex optimization problem with finitely\nmany constraints that admits explicit conic representability for a collection\nof canonical examples. While the number of constraints in general scales\nexponentially with the dimension of the state space, we circumvent this\ndimensionality curse and provide two types of upper and lower bounds\nalgorithms.They yield tight upper and lower bounds on the exact optimal value\nand are formally shown to converge asymptotically. This is illustrated\nnumerically in two examples given by a robust newsvendor problem and a robust\nportfolio choice problem.",
      "published": "February 17, 2025",
      "categories": [
        "math.OC",
        "econ.TH",
        "90C17, 91B06"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.11780v1",
      "arxiv_url": "http://arxiv.org/abs/2502.11780v1"
    },
    {
      "title": "Transfer Learning of CATE with Kernel Ridge Regression",
      "authors": [
        "Seok-Jin Kim",
        "Hongjie Liu",
        "Molei Liu",
        "Kaizheng Wang"
      ],
      "abstract": "The proliferation of data has sparked significant interest in leveraging\nfindings from one study to estimate treatment effects in a different target\npopulation without direct outcome observations. However, the transfer learning\nprocess is frequently hindered by substantial covariate shift and limited\noverlap between (i) the source and target populations, as well as (ii) the\ntreatment and control groups within the source. We propose a novel method for\noverlap-adaptive transfer learning of conditional average treatment effect\n(CATE) using kernel ridge regression (KRR). Our approach involves partitioning\nthe labeled source data into two subsets. The first one is used to train\ncandidate CATE models based on regression adjustment and pseudo-outcomes. An\noptimal model is then selected using the second subset and unlabeled target\ndata, employing another pseudo-outcome-based strategy. We provide a theoretical\njustification for our method through sharp non-asymptotic MSE bounds,\nhighlighting its adaptivity to both weak overlaps and the complexity of CATE\nfunction. Extensive numerical studies confirm that our method achieves superior\nfinite-sample efficiency and adaptability. We conclude by demonstrating the\neffectiveness of our approach using a 401(k) eligibility dataset.",
      "published": "February 17, 2025",
      "categories": [
        "stat.ME",
        "cs.LG",
        "stat.ML"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.11331v1",
      "arxiv_url": "http://arxiv.org/abs/2502.11331v1"
    },
    {
      "title": "Detecting Cadastral Boundary from Satellite Images Using U-Net model",
      "authors": [
        "Neda Rahimpour Anaraki",
        "Maryam Tahmasbi",
        "Saeed Reza Kheradpisheh"
      ],
      "abstract": "Finding the cadastral boundaries of farmlands is a crucial concern for land\nadministration. Therefore, using deep learning methods to expedite and simplify\nthe extraction of cadastral boundaries from satellite and unmanned aerial\nvehicle (UAV) images is critical. In this paper, we employ transfer learning to\ntrain a U-Net model with a ResNet34 backbone to detect cadastral boundaries\nthrough three-class semantic segmentation: \"boundary\", \"field\", and\n\"background\". We evaluate the performance on two satellite images from\nfarmlands in Iran using \"precision\", \"recall\", and \"F-score\", achieving high\nvalues of 88%, 75%, and 81%, respectively, which indicate promising results.",
      "published": "February 16, 2025",
      "categories": [
        "cs.CV",
        "cs.LG"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.11044v1",
      "arxiv_url": "http://arxiv.org/abs/2502.11044v1"
    },
    {
      "title": "Controlling Neural Collapse Enhances Out-of-Distribution Detection and\n  Transfer Learning",
      "authors": [
        "Md Yousuf Harun",
        "Jhair Gallardo",
        "Christopher Kanan"
      ],
      "abstract": "Out-of-distribution (OOD) detection and OOD generalization are widely studied\nin Deep Neural Networks (DNNs), yet their relationship remains poorly\nunderstood. We empirically show that the degree of Neural Collapse (NC) in a\nnetwork layer is inversely related with these objectives: stronger NC improves\nOOD detection but degrades generalization, while weaker NC enhances\ngeneralization at the cost of detection. This trade-off suggests that a single\nfeature space cannot simultaneously achieve both tasks. To address this, we\ndevelop a theoretical framework linking NC to OOD detection and generalization.\nWe show that entropy regularization mitigates NC to improve generalization,\nwhile a fixed Simplex Equiangular Tight Frame (ETF) projector enforces NC for\nbetter detection. Based on these insights, we propose a method to control NC at\ndifferent DNN layers. In experiments, our method excels at both tasks across\nOOD datasets and DNN architectures.",
      "published": "February 15, 2025",
      "categories": [
        "cs.LG"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.10691v1",
      "arxiv_url": "http://arxiv.org/abs/2502.10691v1"
    },
    {
      "title": "SPIRIT: Short-term Prediction of solar IRradIance for zero-shot Transfer\n  learning using Foundation Models",
      "authors": [
        "Aditya Mishra",
        "Ravindra T",
        "Srinivasan Iyengar",
        "Shivkumar Kalyanaraman",
        "Ponnurangam Kumaraguru"
      ],
      "abstract": "Traditional solar forecasting models are based on several years of\nsite-specific historical irradiance data, often spanning five or more years,\nwhich are unavailable for newer photovoltaic farms. As renewable energy is\nhighly intermittent, building accurate solar irradiance forecasting systems is\nessential for efficient grid management and enabling the ongoing proliferation\nof solar energy, which is crucial to achieve the United Nations' net zero\ngoals. In this work, we propose SPIRIT, a novel approach leveraging foundation\nmodels for solar irradiance forecasting, making it applicable to newer solar\ninstallations. Our approach outperforms state-of-the-art models in zero-shot\ntransfer learning by about 70%, enabling effective performance at new locations\nwithout relying on any historical data. Further improvements in performance are\nachieved through fine-tuning, as more location-specific data becomes available.\nThese findings are supported by statistical significance, further validating\nour approach. SPIRIT represents a pivotal step towards rapid, scalable, and\nadaptable solar forecasting solutions, advancing the integration of renewable\nenergy into global power systems.",
      "published": "February 14, 2025",
      "categories": [
        "cs.LG",
        "cs.CV"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.10307v1",
      "arxiv_url": "http://arxiv.org/abs/2502.10307v1"
    },
    {
      "title": "ExoMiner++ on TESS with Transfer Learning from Kepler: Transit\n  Classification and Vetting Catalog for 2-min Data",
      "authors": [
        "Hamed Valizadegan",
        "Miguel J. S. Martinho",
        "Jon M. Jenkins",
        "Joseph D. Twicken",
        "Douglas A. Caldwell",
        "Patrick Maynard",
        "Hongbo Wei",
        "William Zhong",
        "Charles Yates",
        "Sam Donald",
        "Karen A. Collins",
        "David Latham",
        "Khalid Barkaoui",
        "Perry Berlind",
        "Michael L. Calkins",
        "Kylee Carden",
        "Nikita Chazov",
        "Gilbert A. Esquerdo",
        "Tristan Guillot",
        "Vadim Krushinsky",
        "Grzegorz Nowak",
        "Benjamin V. Rackham",
        "Amaury Triaud",
        "Richard P. Schwarz",
        "Denise Stephens",
        "Chris Stockdale",
        "Jiaqi Wang",
        "Cristilyn N. Watkins",
        "Francis P. Wilkin"
      ],
      "abstract": "We present ExoMiner++, an enhanced deep learning model that builds on the\nsuccess of ExoMiner to improve transit signal classification in 2-minute TESS\ndata. ExoMiner++ incorporates additional diagnostic inputs, including\nperiodogram, flux trend, difference image, unfolded flux, and spacecraft\nattitude control data, all of which are crucial for effectively distinguishing\ntransit signals from more challenging sources of false positives. To further\nenhance performance, we leverage transfer learning from high-quality labeled\ndata from the Kepler space telescope, mitigating the impact of TESS's noisier\nand more ambiguous labels. ExoMiner++ achieves high accuracy across various\nclassification and ranking metrics, significantly narrowing the search space\nfor follow-up investigations to confirm new planets. To serve the exoplanet\ncommunity, we introduce new TESS catalogs containing ExoMiner++ classifications\nand confidence scores for each transit signal. Among the 147,568 unlabeled\nTCEs, ExoMiner++ identifies 7,330 as planet candidates, with the remainder\nclassified as false positives. These 7,330 planet candidates correspond to\n1,868 existing TESS Objects of Interest (TOIs), 69 Community TESS Objects of\nInterest (CTOIs), and 50 newly introduced CTOIs. 1,797 out of the 2,506 TOIs\npreviously labeled as planet candidates in ExoFOP are classified as planet\ncandidates by ExoMiner++. This reduction in plausible candidates combined with\nthe excellent ranking quality of ExoMiner++ allows the follow-up efforts to be\nfocused on the most likely candidates, increasing the overall planet yield.",
      "published": "February 13, 2025",
      "categories": [
        "astro-ph.EP",
        "astro-ph.IM",
        "cs.LG"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.09790v1",
      "arxiv_url": "http://arxiv.org/abs/2502.09790v1"
    },
    {
      "title": "NeuralCFD: Deep Learning on High-Fidelity Automotive Aerodynamics\n  Simulations",
      "authors": [
        "Maurits Bleeker",
        "Matthias Dorfer",
        "Tobias Kronlachner",
        "Reinhard Sonnleitner",
        "Benedikt Alkin",
        "Johannes Brandstetter"
      ],
      "abstract": "Recent advancements in neural operator learning are paving the way for\ntransformative innovations in fields such as automotive aerodynamics. However,\nkey challenges must be overcome before neural network-based simulation\nsurrogates can be implemented at an industry scale. First, surrogates must\nbecome scalable to large surface and volume meshes, especially when using raw\ngeometry inputs only, i.e., without relying on the simulation mesh. Second,\nsurrogates must be trainable with a limited number of high-fidelity numerical\nsimulation samples while still reaching the required performance levels. To\nthis end, we introduce Geometry-preserving Universal Physics Transformer\n(GP-UPT), which separates geometry encoding and physics predictions, ensuring\nflexibility with respect to geometry representations and surface sampling\nstrategies. GP-UPT enables independent scaling of the respective parts of the\nmodel according to practical requirements, offering scalable solutions to open\nchallenges. GP-UPT circumvents the creation of high-quality simulation meshes,\nenables accurate 3D velocity field predictions at 20 million mesh cells, and\nexcels in transfer learning from low-fidelity to high-fidelity simulation\ndatasets, requiring less than half of the high-fidelity data to match the\nperformance of models trained from scratch.",
      "published": "February 13, 2025",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.09692v1",
      "arxiv_url": "http://arxiv.org/abs/2502.09692v1"
    },
    {
      "title": "A Survey of Reinforcement Learning for Optimization in Automation",
      "authors": [
        "Ahmad Farooq",
        "Kamran Iqbal"
      ],
      "abstract": "Reinforcement Learning (RL) has become a critical tool for optimization\nchallenges within automation, leading to significant advancements in several\nareas. This review article examines the current landscape of RL within\nautomation, with a particular focus on its roles in manufacturing, energy\nsystems, and robotics. It discusses state-of-the-art methods, major challenges,\nand upcoming avenues of research within each sector, highlighting RL's capacity\nto solve intricate optimization challenges. The paper reviews the advantages\nand constraints of RL-driven optimization methods in automation. It points out\nprevalent challenges encountered in RL optimization, including issues related\nto sample efficiency and scalability; safety and robustness; interpretability\nand trustworthiness; transfer learning and meta-learning; and real-world\ndeployment and integration. It further explores prospective strategies and\nfuture research pathways to navigate these challenges. Additionally, the survey\nincludes a comprehensive list of relevant research papers, making it an\nindispensable guide for scholars and practitioners keen on exploring this\ndomain.",
      "published": "February 13, 2025",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE",
        "cs.RO",
        "cs.SY",
        "eess.SY",
        "68T05, 90C40, 49M37",
        "I.2.6; I.2.8; I.2.9; G.1.6; C.4; J.6"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.09417v1",
      "arxiv_url": "http://arxiv.org/abs/2502.09417v1"
    },
    {
      "title": "Wasserstein distributional adversarial training for deep neural networks",
      "authors": [
        "Xingjian Bai",
        "Guangyi He",
        "Yifan Jiang",
        "Jan Obloj"
      ],
      "abstract": "Design of adversarial attacks for deep neural networks, as well as methods of\nadversarial training against them, are subject of intense research. In this\npaper, we propose methods to train against distributional attack threats,\nextending the TRADES method used for pointwise attacks. Our approach leverages\nrecent contributions and relies on sensitivity analysis for Wasserstein\ndistributionally robust optimization problems. We introduce an efficient\nfine-tuning method which can be deployed on a previously trained model. We test\nour methods on a range of pre-trained models on RobustBench. These experimental\nresults demonstrate the additional training enhances Wasserstein distributional\nrobustness, while maintaining original levels of pointwise robustness, even for\nalready very successful networks. The improvements are less marked for models\npre-trained using huge synthetic datasets of 20-100M images. However,\nremarkably, sometimes our methods are still able to improve their performance\neven when trained using only the original training dataset (50k images).",
      "published": "February 13, 2025",
      "categories": [
        "cs.LG",
        "cs.CV",
        "math.OC"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.09352v1",
      "arxiv_url": "http://arxiv.org/abs/2502.09352v1"
    },
    {
      "title": "Revisiting Euclidean Alignment for Transfer Learning in EEG-Based\n  Brain-Computer Interfaces",
      "authors": [
        "Dongrui Wu"
      ],
      "abstract": "Due to the non-stationarity and large individual differences of EEG signals,\nEEG-based brain-computer interfaces (BCIs) usually need subject-specific\ncalibration to tailor the decoding algorithm for each new subject, which is\ntime-consuming and user-unfriendly, hindering their real-world applications.\nTransfer learning (TL) has been extensively used to expedite the calibration,\nby making use of EEG data from other subjects/sessions. An important\nconsideration in TL for EEG-based BCIs is to reduce the data distribution\ndiscrepancies among different subjects/session, to avoid negative transfer.\nEuclidean alignment (EA) was proposed in 2020 to address this challenge.\nNumerous experiments from 10 different BCI paradigms demonstrated its\neffectiveness and efficiency. This paper revisits the EA, explaining its\nprocedure and correct usage, introducing its applications and extensions, and\npointing out potential new research directions. It should be very helpful to\nBCI researchers, especially those who are working on EEG signal decoding.",
      "published": "February 13, 2025",
      "categories": [
        "cs.HC",
        "cs.LG"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.09203v1",
      "arxiv_url": "http://arxiv.org/abs/2502.09203v1"
    },
    {
      "title": "A Hybrid Model for Few-Shot Text Classification Using Transfer and\n  Meta-Learning",
      "authors": [
        "Jia Gao",
        "Shuangquan Lyu",
        "Guiran Liu",
        "Binrong Zhu",
        "Hongye Zheng",
        "Xiaoxuan Liao"
      ],
      "abstract": "With the continuous development of natural language processing (NLP)\ntechnology, text classification tasks have been widely used in multiple\napplication fields. However, obtaining labeled data is often expensive and\ndifficult, especially in few-shot learning scenarios. To solve this problem,\nthis paper proposes a few-shot text classification model based on transfer\nlearning and meta-learning. The model uses the knowledge of the pre-trained\nmodel for transfer and optimizes the model's rapid adaptability in few-sample\ntasks through a meta-learning mechanism. Through a series of comparative\nexperiments and ablation experiments, we verified the effectiveness of the\nproposed method. The experimental results show that under the conditions of few\nsamples and medium samples, the model based on transfer learning and\nmeta-learning significantly outperforms traditional machine learning and deep\nlearning methods. In addition, ablation experiments further analyzed the\ncontribution of each component to the model performance and confirmed the key\nrole of transfer learning and meta-learning in improving model accuracy.\nFinally, this paper discusses future research directions and looks forward to\nthe potential of this method in practical applications.",
      "published": "February 13, 2025",
      "categories": [
        "cs.CL"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.09086v1",
      "arxiv_url": "http://arxiv.org/abs/2502.09086v1"
    },
    {
      "title": "Multifidelity Simulation-based Inference for Computationally Expensive\n  Simulators",
      "authors": [
        "Anastasia N. Krouglova",
        "Hayden R. Johnson",
        "Basile Confavreux",
        "Michael Deistler",
        "Pedro J. Gon\u00e7alves"
      ],
      "abstract": "Across many domains of science, stochastic models are an essential tool to\nunderstand the mechanisms underlying empirically observed data. Models can be\nof different levels of detail and accuracy, with models of high-fidelity (i.e.,\nhigh accuracy) to the phenomena under study being often preferable. However,\ninferring parameters of high-fidelity models via simulation-based inference is\nchallenging, especially when the simulator is computationally expensive. We\nintroduce MF-NPE, a multifidelity approach to neural posterior estimation that\nleverages inexpensive low-fidelity simulations to infer parameters of\nhigh-fidelity simulators within a limited simulation budget. MF-NPE performs\nneural posterior estimation with limited high-fidelity resources by virtue of\ntransfer learning, with the ability to prioritize individual observations using\nactive learning. On one statistical task with analytical ground-truth and two\nreal-world tasks, MF-NPE shows comparable performance to current approaches\nwhile requiring up to two orders of magnitude fewer high-fidelity simulations.\nOverall, MF-NPE opens new opportunities to perform efficient Bayesian inference\non computationally expensive simulators.",
      "published": "February 12, 2025",
      "categories": [
        "stat.ML",
        "cs.LG"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.08416v2",
      "arxiv_url": "http://arxiv.org/abs/2502.08416v2"
    },
    {
      "title": "Advancing machine fault diagnosis: A detailed examination of\n  convolutional neural networks",
      "authors": [
        "Govind Vashishtha",
        "Sumika Chauhan",
        "Mert Sehri",
        "Justyna Hebda-Sobkowicz",
        "Radoslaw Zimroz",
        "Patrick Dumond",
        "Rajesh Kumar"
      ],
      "abstract": "The growing complexity of machinery and the increasing demand for operational\nefficiency and safety have driven the development of advanced fault diagnosis\ntechniques. Among these, convolutional neural networks (CNNs) have emerged as a\npowerful tool, offering robust and accurate fault detection and classification\ncapabilities. This comprehensive review delves into the application of CNNs in\nmachine fault diagnosis, covering its theoretical foundation, architectural\nvariations, and practical implementations. The strengths and limitations of\nCNNs are analyzed in this domain, discussing their effectiveness in handling\nvarious fault types, data complexities, and operational environments.\nFurthermore, we explore the evolving landscape of CNN-based fault diagnosis,\nexamining recent advancements in data augmentation, transfer learning, and\nhybrid architectures. Finally, we highlight future research directions and\npotential challenges to further enhance the application of CNNs for reliable\nand proactive machine fault diagnosis.",
      "published": "February 12, 2025",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.08689v1",
      "arxiv_url": "http://arxiv.org/abs/2502.08689v1"
    },
    {
      "title": "Hi-End-MAE: Hierarchical encoder-driven masked autoencoders are stronger\n  vision learners for medical image segmentation",
      "authors": [
        "Fenghe Tang",
        "Qingsong Yao",
        "Wenxin Ma",
        "Chenxu Wu",
        "Zihang Jiang",
        "S. Kevin Zhou"
      ],
      "abstract": "Medical image segmentation remains a formidable challenge due to the label\nscarcity. Pre-training Vision Transformer (ViT) through masked image modeling\n(MIM) on large-scale unlabeled medical datasets presents a promising solution,\nproviding both computational efficiency and model generalization for various\ndownstream tasks. However, current ViT-based MIM pre-training frameworks\npredominantly emphasize local aggregation representations in output layers and\nfail to exploit the rich representations across different ViT layers that\nbetter capture fine-grained semantic information needed for more precise\nmedical downstream tasks. To fill the above gap, we hereby present Hierarchical\nEncoder-driven MAE (Hi-End-MAE), a simple yet effective ViT-based pre-training\nsolution, which centers on two key innovations: (1) Encoder-driven\nreconstruction, which encourages the encoder to learn more informative features\nto guide the reconstruction of masked patches; and (2) Hierarchical dense\ndecoding, which implements a hierarchical decoding structure to capture rich\nrepresentations across different layers. We pre-train Hi-End-MAE on a\nlarge-scale dataset of 10K CT scans and evaluated its performance across seven\npublic medical image segmentation benchmarks. Extensive experiments demonstrate\nthat Hi-End-MAE achieves superior transfer learning capabilities across various\ndownstream tasks, revealing the potential of ViT in medical imaging\napplications. The code is available at:\nhttps://github.com/FengheTan9/Hi-End-MAE",
      "published": "February 12, 2025",
      "categories": [
        "cs.CV"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.08347v1",
      "arxiv_url": "http://arxiv.org/abs/2502.08347v1"
    },
    {
      "title": "Knowledge-Guided Wasserstein Distributionally Robust Optimization",
      "authors": [
        "Zitao Wang",
        "Ziyuan Wang",
        "Molei Liu",
        "Nian Si"
      ],
      "abstract": "Transfer learning is a popular strategy to leverage external knowledge and\nimprove statistical efficiency, particularly with a limited target sample. We\npropose a novel knowledge-guided Wasserstein Distributionally Robust\nOptimization (KG-WDRO) framework that adaptively incorporates multiple sources\nof external knowledge to overcome the conservativeness of vanilla WDRO, which\noften results in overly pessimistic shrinkage toward zero. Our method\nconstructs smaller Wasserstein ambiguity sets by controlling the transportation\nalong directions informed by the source knowledge. This strategy can alleviate\nperturbations on the predictive projection of the covariates and protect\nagainst information loss. Theoretically, we establish the equivalence between\nour WDRO formulation and the knowledge-guided shrinkage estimation based on\ncollinear similarity, ensuring tractability and geometrizing the feasible set.\nThis also reveals a novel and general interpretation for recent shrinkage-based\ntransfer learning approaches from the perspective of distributional robustness.\nIn addition, our framework can adjust for scaling differences in the regression\nmodels between the source and target and accommodates general types of\nregularization such as lasso and ridge. Extensive simulations demonstrate the\nsuperior performance and adaptivity of KG-WDRO in enhancing small-sample\ntransfer learning.",
      "published": "February 12, 2025",
      "categories": [
        "cs.LG",
        "stat.ME",
        "stat.ML"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.08146v1",
      "arxiv_url": "http://arxiv.org/abs/2502.08146v1"
    },
    {
      "title": "Instance-dependent Early Stopping",
      "authors": [
        "Suqin Yuan",
        "Runqi Lin",
        "Lei Feng",
        "Bo Han",
        "Tongliang Liu"
      ],
      "abstract": "In machine learning practice, early stopping has been widely used to\nregularize models and can save computational costs by halting the training\nprocess when the model's performance on a validation set stops improving.\nHowever, conventional early stopping applies the same stopping criterion to all\ninstances without considering their individual learning statuses, which leads\nto redundant computations on instances that are already well-learned. To\nfurther improve the efficiency, we propose an Instance-dependent Early Stopping\n(IES) method that adapts the early stopping mechanism from the entire training\nset to the instance level, based on the core principle that once the model has\nmastered an instance, the training on it should stop. IES considers an instance\nas mastered if the second-order differences of its loss value remain within a\nsmall range around zero. This offers a more consistent measure of an instance's\nlearning status compared with directly using the loss value, and thus allows\nfor a unified threshold to determine when an instance can be excluded from\nfurther backpropagation. We show that excluding mastered instances from\nbackpropagation can increase the gradient norms, thereby accelerating the\ndecrease of the training loss and speeding up the training process. Extensive\nexperiments on benchmarks demonstrate that IES method can reduce\nbackpropagation instances by 10%-50% while maintaining or even slightly\nimproving the test accuracy and transfer learning performance of a model.",
      "published": "February 11, 2025",
      "categories": [
        "cs.LG"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.07547v1",
      "arxiv_url": "http://arxiv.org/abs/2502.07547v1"
    },
    {
      "title": "Music for All: Exploring Multicultural Representations in Music\n  Generation Models",
      "authors": [
        "Atharva Mehta",
        "Shivam Chauhan",
        "Amirbek Djanibekov",
        "Atharva Kulkarni",
        "Gus Xia",
        "Monojit Choudhury"
      ],
      "abstract": "The advent of Music-Language Models has greatly enhanced the automatic music\ngeneration capability of AI systems, but they are also limited in their\ncoverage of the musical genres and cultures of the world. We present a study of\nthe datasets and research papers for music generation and quantify the bias and\nunder-representation of genres. We find that only 5.7% of the total hours of\nexisting music datasets come from non-Western genres, which naturally leads to\ndisparate performance of the models across genres. We then investigate the\nefficacy of Parameter-Efficient Fine-Tuning (PEFT) techniques in mitigating\nthis bias. Our experiments with two popular models -- MusicGen and Mustango,\nfor two underrepresented non-Western music traditions -- Hindustani Classical\nand Turkish Makam music, highlight the promises as well as the non-triviality\nof cross-genre adaptation of music through small datasets, implying the need\nfor more equitable baseline music-language models that are designed for\ncross-cultural transfer learning.",
      "published": "February 11, 2025",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.MM"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.07328v2",
      "arxiv_url": "http://arxiv.org/abs/2502.07328v2"
    },
    {
      "title": "Long-term simulation of physical and mechanical behaviors using\n  curriculum-transfer-learning based physics-informed neural networks",
      "authors": [
        "Yuan Guo",
        "Zhuojia Fu",
        "Jian Min",
        "Shiyu Lin",
        "Xiaoting Liu",
        "Youssef F. Rashed",
        "Xiaoying Zhuang"
      ],
      "abstract": "This paper proposes a Curriculum-Transfer-Learning based physics-informed\nneural network (CTL-PINN) for long-term simulation of physical and mechanical\nbehaviors. The main innovation of CTL-PINN lies in decomposing long-term\nproblems into a sequence of short-term subproblems. Initially, the standard\nPINN is employed to solve the first sub-problem. As the simulation progresses,\nsubsequent time-domain problems are addressed using a curriculum learning\napproach that integrates information from previous steps. Furthermore, transfer\nlearning techniques are incorporated, allowing the model to effectively utilize\nprior training data and solve sequential time domain transfer problems.\nCTL-PINN combines the strengths of curriculum learning and transfer learning,\novercoming the limitations of standard PINNs, such as local optimization\nissues, and addressing the inaccuracies over extended time domains encountered\nin CL-PINN and the low computational efficiency of TL-PINN. The efficacy and\nrobustness of CTL-PINN are demonstrated through applications to nonlinear wave\npropagation, Kirchhoff plate dynamic response, and the hydrodynamic model of\nthe Three Gorges Reservoir Area, showcasing its superior capability in\naddressing long-term computational challenges.",
      "published": "February 11, 2025",
      "categories": [
        "cs.LG",
        "cs.NA",
        "math.NA"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.07325v1",
      "arxiv_url": "http://arxiv.org/abs/2502.07325v1"
    },
    {
      "title": "Robust Indoor Localization in Dynamic Environments: A Multi-source\n  Unsupervised Domain Adaptation Framework",
      "authors": [
        "Jiyu Jiao",
        "Xiaojun Wang",
        "Chengpei Han"
      ],
      "abstract": "Fingerprint localization has gained significant attention due to its\ncost-effective deployment, low complexity, and high efficacy. However,\ntraditional methods, while effective for static data, often struggle in dynamic\nenvironments where data distributions and feature spaces evolve-a common\noccurrence in real-world scenarios. To address the challenges of robustness and\nadaptability in fingerprint localization for dynamic indoor environments, this\npaper proposes DF-Loc, an end-to-end dynamic fingerprint localization system\nbased on multi-source unsupervised domain adaptation (MUDA). DF-Loc leverages\nhistorical data from multiple time scales to facilitate knowledge transfer in\nspecific feature spaces, thereby enhancing generalization capabilities in the\ntarget domain and reducing reliance on labeled data. Specifically, the system\nincorporates a Quality Control (QC) module for CSI data preprocessing and\nemploys image processing techniques for CSI fingerprint feature reconstruction.\nAdditionally, a multi-scale attention-based feature fusion backbone network is\ndesigned to extract multi-level transferable fingerprint features. Finally, a\ndual-stage alignment model aligns the distributions of multiple source-target\ndomain pairs, improving regression characteristics in the target domain.\nExtensive experiments conducted in office and classroom environments\ndemonstrate that DF-Loc outperforms comparative methods in terms of both\nlocalization accuracy and robustness. With 60% of reference points used for\ntraining, DF-Loc achieves average localization errors of 0.79m and 3.72m in\n\"same-test\" scenarios, and 0.94m and 4.39m in \"different-test\" scenarios,\nrespectively. This work pioneers an end-to-end multi-source transfer learning\napproach for fingerprint localization, providing valuable insights for future\nresearch in dynamic environments.",
      "published": "February 11, 2025",
      "categories": [
        "cs.CV",
        "physics.pop-ph"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.07246v1",
      "arxiv_url": "http://arxiv.org/abs/2502.07246v1"
    },
    {
      "title": "Tab2Visual: Overcoming Limited Data in Tabular Data Classification Using\n  Deep Learning with Visual Representations",
      "authors": [
        "Ahmed Mamdouh",
        "Moumen El-Melegy",
        "Samia Ali",
        "Ron Kikinis"
      ],
      "abstract": "This research addresses the challenge of limited data in tabular data\nclassification, particularly prevalent in domains with constraints like\nhealthcare. We propose Tab2Visual, a novel approach that transforms\nheterogeneous tabular data into visual representations, enabling the\napplication of powerful deep learning models. Tab2Visual effectively addresses\ndata scarcity by incorporating novel image augmentation techniques and\nfacilitating transfer learning. We extensively evaluate the proposed approach\non diverse tabular datasets, comparing its performance against a wide range of\nmachine learning algorithms, including classical methods, tree-based ensembles,\nand state-of-the-art deep learning models specifically designed for tabular\ndata. We also perform an in-depth analysis of factors influencing Tab2Visual's\nperformance. Our experimental results demonstrate that Tab2Visual outperforms\nother methods in classification problems with limited tabular data.",
      "published": "February 11, 2025",
      "categories": [
        "cs.LG",
        "cs.CV"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.07181v1",
      "arxiv_url": "http://arxiv.org/abs/2502.07181v1"
    },
    {
      "title": "Cross-platform Learning-based Fault Tolerant Surfacing Controller for\n  Underwater Robots",
      "authors": [
        "Yuya Hamamatsu",
        "Walid Remmas",
        "Jaan Rebane",
        "Maarja Kruusmaa",
        "Asko Ristolainen"
      ],
      "abstract": "In this paper, we propose a novel cross-platform fault-tolerant surfacing\ncontroller for underwater robots, based on reinforcement learning (RL). Unlike\nconventional approaches, which require explicit identification of\nmalfunctioning actuators, our method allows the robot to surface using only the\nremaining operational actuators without needing to pinpoint the failures. The\nproposed controller learns a robust policy capable of handling diverse failure\nscenarios across different actuator configurations. Moreover, we introduce a\ntransfer learning mechanism that shares a part of the control policy across\nvarious underwater robots with different actuators, thus improving learning\nefficiency and generalization across platforms. To validate our approach, we\nconduct simulations on three different types of underwater robots: a\nhovering-type AUV, a torpedo shaped AUV, and a turtle-shaped robot (U-CAT).\nAdditionally, real-world experiments are performed, successfully transferring\nthe learned policy from simulation to a physical U-CAT in a controlled\nenvironment. Our RL-based controller demonstrates superior performance in terms\nof stability and success rate compared to a baseline controller, achieving an\n85.7 percent success rate in real-world tests compared to 57.1 percent with a\nbaseline controller. This research provides a scalable and efficient solution\nfor fault-tolerant control for diverse underwater platforms, with potential\napplications in real-world aquatic missions.",
      "published": "February 10, 2025",
      "categories": [
        "cs.RO"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.07133v1",
      "arxiv_url": "http://arxiv.org/abs/2502.07133v1"
    },
    {
      "title": "Generative Distribution Prediction: A Unified Approach to Multimodal\n  Learning",
      "authors": [
        "Xinyu Tian",
        "Xiaotong Shen"
      ],
      "abstract": "Accurate prediction with multimodal data-encompassing tabular, textual, and\nvisual inputs or outputs-is fundamental to advancing analytics in diverse\napplication domains. Traditional approaches often struggle to integrate\nheterogeneous data types while maintaining high predictive accuracy. We\nintroduce Generative Distribution Prediction (GDP), a novel framework that\nleverages multimodal synthetic data generation-such as conditional diffusion\nmodels-to enhance predictive performance across structured and unstructured\nmodalities. GDP is model-agnostic, compatible with any high-fidelity generative\nmodel, and supports transfer learning for domain adaptation. We establish a\nrigorous theoretical foundation for GDP, providing statistical guarantees on\nits predictive accuracy when using diffusion models as the generative backbone.\nBy estimating the data-generating distribution and adapting to various loss\nfunctions for risk minimization, GDP enables accurate point predictions across\nmultimodal settings. We empirically validate GDP on four supervised learning\ntasks-tabular data prediction, question answering, image captioning, and\nadaptive quantile regression-demonstrating its versatility and effectiveness\nacross diverse domains.",
      "published": "February 10, 2025",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.07090v1",
      "arxiv_url": "http://arxiv.org/abs/2502.07090v1"
    },
    {
      "title": "Model Diffusion for Certifiable Few-shot Transfer Learning",
      "authors": [
        "Fady Rezk",
        "Royson Lee",
        "Henry Gouk",
        "Timothy Hospedales",
        "Minyoung Kim"
      ],
      "abstract": "In modern large-scale deep learning, a prevalent and effective workflow for\nsolving low-data problems is adapting powerful pre-trained foundation models\n(FMs) to new tasks via parameter-efficient fine-tuning (PEFT). However, while\nempirically effective, the resulting solutions lack generalisation guarantees\nto certify their accuracy - which may be required for ethical or legal reasons\nprior to deployment in high-importance applications. In this paper we develop a\nnovel transfer learning approach that is designed to facilitate non-vacuous\nlearning theoretic generalisation guarantees for downstream tasks, even in the\nlow-shot regime. Specifically, we first use upstream tasks to train a\ndistribution over PEFT parameters. We then learn the downstream task by a\nsample-and-evaluate procedure -- sampling plausible PEFTs from the trained\ndiffusion model and selecting the one with the highest likelihood on the\ndownstream data. Crucially, this confines our model hypothesis to a finite set\nof PEFT samples. In contrast to learning in the typical continuous hypothesis\nspaces of neural network weights, this facilitates tighter risk certificates.\nWe instantiate our bound and show non-trivial generalization guarantees\ncompared to existing learning approaches which lead to vacuous bounds in the\nlow-shot regime.",
      "published": "February 10, 2025",
      "categories": [
        "cs.LG",
        "stat.ML"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.06970v1",
      "arxiv_url": "http://arxiv.org/abs/2502.06970v1"
    },
    {
      "title": "Institutional Preferences in the Laboratory",
      "authors": [
        "Qiankun Zhong",
        "Nori Jacoby",
        "Ofer Tchernichovski",
        "Seth Frey"
      ],
      "abstract": "Getting a group to adopt cooperative norms is an enduring challenge. But in\nreal-world settings, individuals don't just passively accept static\nenvironments, they act both within and upon the social systems that structure\ntheir interactions. Should we expect the dynamism of player-driven changes to\nthe \"rules of the game\" to hinder cooperation -- because of the substantial\nadded complexity -- or help it, as prosocial agents tweak their environment\ntoward non-zero-sum games? We introduce a laboratory setting to test whether\ngroups can guide themselves to cooperative outcomes by manipulating the\nenvironmental parameters that shape their emergent cooperation process. We test\nfor cooperation in a set of economic games that impose different social\ndilemmas. These games vary independently in the institutional features of\nstability, efficiency, and fairness. By offering agency over behavior along\nwith second-order agency over the rules of the game, we understand emergent\ncooperation in naturalistic settings in which the rules of the game are\nthemselves dynamic and subject to choice. The literature on transfer learning\nin games suggests that interactions between features are important and might\naid or hinder the transfer of cooperative learning to new settings.",
      "published": "February 10, 2025",
      "categories": [
        "cs.SI",
        "cs.GT"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.06748v1",
      "arxiv_url": "http://arxiv.org/abs/2502.06748v1"
    },
    {
      "title": "Hyperparameters in Score-Based Membership Inference Attacks",
      "authors": [
        "Gauri Pradhan",
        "Joonas J\u00e4lk\u00f6",
        "Marlon Tobaben",
        "Antti Honkela"
      ],
      "abstract": "Membership Inference Attacks (MIAs) have emerged as a valuable framework for\nevaluating privacy leakage by machine learning models. Score-based MIAs are\ndistinguished, in particular, by their ability to exploit the confidence scores\nthat the model generates for particular inputs. Existing score-based MIAs\nimplicitly assume that the adversary has access to the target model's\nhyperparameters, which can be used to train the shadow models for the attack.\nIn this work, we demonstrate that the knowledge of target hyperparameters is\nnot a prerequisite for MIA in the transfer learning setting. Based on this, we\npropose a novel approach to select the hyperparameters for training the shadow\nmodels for MIA when the attacker has no prior knowledge about them by matching\nthe output distributions of target and shadow models. We demonstrate that using\nthe new approach yields hyperparameters that lead to an attack near\nindistinguishable in performance from an attack that uses target\nhyperparameters to train the shadow models. Furthermore, we study the empirical\nprivacy risk of unaccounted use of training data for hyperparameter\noptimization (HPO) in differentially private (DP) transfer learning. We find no\nstatistically significant evidence that performing HPO using training data\nwould increase vulnerability to MIA.",
      "published": "February 10, 2025",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.06374v1",
      "arxiv_url": "http://arxiv.org/abs/2502.06374v1"
    },
    {
      "title": "A Data-Efficient Pan-Tumor Foundation Model for Oncology CT\n  Interpretation",
      "authors": [
        "Wenhui Lei",
        "Hanyu Chen",
        "Zitian Zhang",
        "Luyang Luo",
        "Qiong Xiao",
        "Yannian Gu",
        "Peng Gao",
        "Yankai Jiang",
        "Ci Wang",
        "Guangtao Wu",
        "Tongjia Xu",
        "Yingjie Zhang",
        "Xiaofan Zhang",
        "Pranav Rajpurkar",
        "Shaoting Zhang",
        "Zhenning Wang"
      ],
      "abstract": "Artificial intelligence-assisted imaging analysis has made substantial\nstrides in tumor diagnosis and management. Here we present PASTA, a pan-tumor\nCT foundation model that achieves state-of-the-art performance on 45 of 46\nrepresentative oncology tasks -- including lesion segmentation, tumor detection\nin plain CT, tumor staging, survival prediction, structured report generation,\nand cross-modality transfer learning, significantly outperforming the\nsecond-best models on 35 tasks. This remarkable advancement is driven by our\ndevelopment of PASTA-Gen, an innovative synthetic tumor generation framework\nthat produces a comprehensive dataset of 30,000 CT scans with pixel-level\nannotated lesions and paired structured reports, encompassing malignancies\nacross ten organs and five benign lesion types. By leveraging this rich,\nhigh-quality synthetic data, we overcome a longstanding bottleneck in the\ndevelopment of CT foundation models -- specifically, the scarcity of publicly\navailable, high-quality annotated datasets due to privacy constraints and the\nsubstantial labor required for scaling precise data annotation. Encouragingly,\nPASTA demonstrates exceptional data efficiency with promising practical value,\nmarkedly improving performance on various tasks with only a small amount of\nreal-world data. The open release of both the synthetic dataset and PASTA\nfoundation model effectively addresses the challenge of data scarcity, thereby\nadvancing oncological research and clinical translation.",
      "published": "February 10, 2025",
      "categories": [
        "eess.IV",
        "cs.CV"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.06171v1",
      "arxiv_url": "http://arxiv.org/abs/2502.06171v1"
    },
    {
      "title": "Low Tensor-Rank Adaptation of Kolmogorov--Arnold Networks",
      "authors": [
        "Yihang Gao",
        "Michael K. Ng",
        "Vincent Y. F. Tan"
      ],
      "abstract": "Kolmogorov--Arnold networks (KANs) have demonstrated their potential as an\nalternative to multi-layer perceptions (MLPs) in various domains, especially\nfor science-related tasks. However, transfer learning of KANs remains a\nrelatively unexplored area. In this paper, inspired by Tucker decomposition of\ntensors and evidence on the low tensor-rank structure in KAN parameter updates,\nwe develop low tensor-rank adaptation (LoTRA) for fine-tuning KANs. We study\nthe expressiveness of LoTRA based on Tucker decomposition approximations.\nFurthermore, we provide a theoretical analysis to select the learning rates for\neach LoTRA component to enable efficient training. Our analysis also shows that\nusing identical learning rates across all components leads to inefficient\ntraining, highlighting the need for an adaptive learning rate strategy. Beyond\ntheoretical insights, we explore the application of LoTRA for efficiently\nsolving various partial differential equations (PDEs) by fine-tuning KANs.\nAdditionally, we propose Slim KANs that incorporate the inherent\nlow-tensor-rank properties of KAN parameter tensors to reduce model size while\nmaintaining superior performance. Experimental results validate the efficacy of\nthe proposed learning rate selection strategy and demonstrate the effectiveness\nof LoTRA for transfer learning of KANs in solving PDEs. Further evaluations on\nSlim KANs for function representation and image classification tasks highlight\nthe expressiveness of LoTRA and the potential for parameter reduction through\nlow tensor-rank decomposition.",
      "published": "February 10, 2025",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.06153v2",
      "arxiv_url": "http://arxiv.org/abs/2502.06153v2"
    },
    {
      "title": "Protecting Intellectual Property of EEG-based Neural Networks with\n  Watermarking",
      "authors": [
        "Ahmed Abdelaziz",
        "Ahmed Fathi",
        "Ahmed Fares"
      ],
      "abstract": "EEG-based neural networks, pivotal in medical diagnosis and brain-computer\ninterfaces, face significant intellectual property (IP) risks due to their\nreliance on sensitive neurophysiological data and resource-intensive\ndevelopment. Current watermarking methods, particularly those using abstract\ntrigger sets, lack robust authentication and fail to address the unique\nchallenges of EEG models. This paper introduces a cryptographic wonder\nfilter-based watermarking framework tailored for EEG-based neural networks.\nLeveraging collision-resistant hashing and public-key encryption, the wonder\nfilter embeds the watermark during training, ensuring minimal distortion ($\\leq\n5\\%$ drop in EEG task accuracy) and high reliability (100\\% watermark\ndetection). The framework is rigorously evaluated against adversarial attacks,\nincluding fine-tuning, transfer learning, and neuron pruning. Results\ndemonstrate persistent watermark retention, with classification accuracy for\nwatermarked states remaining above 90\\% even after aggressive pruning, while\nprimary task performance degrades faster, deterring removal attempts. Piracy\nresistance is validated by the inability to embed secondary watermarks without\nsevere accuracy loss ( $>10\\%$ in EEGNet and CCNN models). Cryptographic\nhashing ensures authentication, reducing brute-force attack success\nprobabilities. Evaluated on the DEAP dataset across models (CCNN, EEGNet,\nTSception), the method achieves $>99.4\\%$ null-embedding accuracy, effectively\neliminating false positives. By integrating wonder filters with EEG-specific\nadaptations, this work bridges a critical gap in IP protection for\nneurophysiological models, offering a secure, tamper-proof solution for\nhealthcare and biometric applications. The framework's robustness against\nadversarial modifications underscores its potential to safeguard sensitive EEG\nmodels while maintaining diagnostic utility.",
      "published": "February 09, 2025",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "94A60, 68P25",
        "H.1.2; I.2.6; J.3; K.5.1"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.05931v1",
      "arxiv_url": "http://arxiv.org/abs/2502.05931v1"
    },
    {
      "title": "Target Speaker Lipreading by Audio-Visual Self-Distillation Pretraining\n  and Speaker Adaptation",
      "authors": [
        "Jing-Xuan Zhang",
        "Tingzhi Mao",
        "Longjiang Guo",
        "Jin Li",
        "Lichen Zhang"
      ],
      "abstract": "Lipreading is an important technique for facilitating human-computer\ninteraction in noisy environments. Our previously developed self-supervised\nlearning method, AV2vec, which leverages multimodal self-distillation, has\ndemonstrated promising performance in speaker-independent lipreading on the\nEnglish LRS3 dataset. However, AV2vec faces challenges such as high training\ncosts and a potential scarcity of audio-visual data for lipreading in languages\nother than English, such as Chinese. Additionally, most studies concentrate on\nspeakerindependent lipreading models, which struggle to account for the\nsubstantial variation in speaking styles across di?erent speakers. To address\nthese issues, we propose a comprehensive approach. First, we investigate\ncross-lingual transfer learning, adapting a pre-trained AV2vec model from a\nsource language and optimizing it for the lipreading task in a target language.\nSecond, we enhance the accuracy of lipreading for specific target speakers\nthrough a speaker adaptation strategy, which is not extensively explored in\nprevious research. Third, after analyzing the complementary performance of\nlipreading with lip region-of-interest (ROI) and face inputs, we introduce a\nmodel ensembling strategy that integrates both, signi?cantly boosting model\nperformance. Our method achieved a character error rate (CER) of 77.3% on the\nevaluation set of the ChatCLR dataset, which is lower than the top result from\nthe 2024 Chat-scenario Chinese Lipreading Challenge.",
      "published": "February 09, 2025",
      "categories": [
        "eess.AS"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.05758v1",
      "arxiv_url": "http://arxiv.org/abs/2502.05758v1"
    },
    {
      "title": "Topological derivative approach for deep neural network architecture\n  adaptation",
      "authors": [
        "C G Krishnanunni",
        "Tan Bui-Thanh",
        "Clint Dawson"
      ],
      "abstract": "This work presents a novel algorithm for progressively adapting neural\nnetwork architecture along the depth. In particular, we attempt to address the\nfollowing questions in a mathematically principled way: i) Where to add a new\ncapacity (layer) during the training process? ii) How to initialize the new\ncapacity? At the heart of our approach are two key ingredients: i) the\nintroduction of a ``shape functional\" to be minimized, which depends on neural\nnetwork topology, and ii) the introduction of a topological derivative of the\nshape functional with respect to the neural network topology. Using an optimal\ncontrol viewpoint, we show that the network topological derivative exists under\ncertain conditions, and its closed-form expression is derived. In particular,\nwe explore, for the first time, the connection between the topological\nderivative from a topology optimization framework with the Hamiltonian from\noptimal control theory. Further, we show that the optimality condition for the\nshape functional leads to an eigenvalue problem for deep neural architecture\nadaptation. Our approach thus determines the most sensitive location along the\ndepth where a new layer needs to be inserted during the training phase and the\nassociated parametric initialization for the newly added layer. We also\ndemonstrate that our layer insertion strategy can be derived from an optimal\ntransport viewpoint as a solution to maximizing a topological derivative in\n$p$-Wasserstein space, where $p>= 1$. Numerical investigations with fully\nconnected network, convolutional neural network, and vision transformer on\nvarious regression and classification problems demonstrate that our proposed\napproach can outperform an ad-hoc baseline network and other architecture\nadaptation strategies. Further, we also demonstrate other applications of\ntopological derivative in fields such as transfer learning.",
      "published": "February 08, 2025",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.06885v1",
      "arxiv_url": "http://arxiv.org/abs/2502.06885v1"
    },
    {
      "title": "Data-Driven Distributionally Robust Mixed-Integer Control through Lifted\n  Control Policy",
      "authors": [
        "Xutao Ma",
        "Chao Ning",
        "Wenli Du",
        "Yang Shi"
      ],
      "abstract": "This paper investigates the finite-horizon distributionally robust\nmixed-integer control (DRMIC) of uncertain linear systems. However, deriving an\noptimal causal feedback control policy to this DRMIC problem is computationally\nformidable for most ambiguity sets. To address the computational challenge, we\npropose a novel distributionally robust lifted control policy (DR-LCP) method\nto derive a high-quality approximate solution to this DRMIC problem for a rich\nclass of Wasserstein metric-based ambiguity sets, including the Wasserstein\nambiguity set and its variants. In theory, we analyze the asymptotic\nperformance and establish a tight non-asymptotic bound of the proposed method.\nIn numerical experiments, the proposed DR-LCP method empirically demonstrates\nsuperior performance compared with existing methods in the literature.",
      "published": "February 08, 2025",
      "categories": [
        "math.OC",
        "cs.SY",
        "eess.SY"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.05469v1",
      "arxiv_url": "http://arxiv.org/abs/2502.05469v1"
    },
    {
      "title": "Distributionally Robust Model Predictive Control with Mixture of\n  Gaussian Processes",
      "authors": [
        "Jingyi Wu",
        "Chao Ning"
      ],
      "abstract": "Despite the success of Gaussian process based Model Predictive Control (MPC)\nin robotic control, its applicability scope is greatly hindered by multimodal\ndisturbances that are prevalent in real-world settings. Here we propose a novel\nMixture of Gaussian Processes based Distributionally Robust MPC (MoGP-DR-MPC)\nframework for linear time invariant systems subject to potentially multimodal\nstate-dependent disturbances. This framework utilizes MoGP to automatically\ndetermine the number of modes from disturbance data. Using the mean and\nvariance information provided by each mode-specific predictive distribution, it\nconstructs a data-driven state-dependent ambiguity set, which allows for\nflexible and fine-grained disturbance modeling. Based on this ambiguity set, we\nimpose Distributionally Robust Conditional Value-at Risk (DR-CVaR) constraints\nto effectively achieve distributional robustness against errors in the\npredictive distributions. To address the computational challenge posed by these\nconstraints in the resulting MPC problem, we equivalently reformulate the\nDR-CVaR constraints into tractable second-order cone constraints. Furthermore,\nwe provide theoretical guarantees on the recursive feasibility and stability of\nthe proposed framework. The enhanced control performance of MoGP-DR-MPC is\nvalidated through both numerical experiments and simulations on a quadrotor\nsystem, demonstrating notable reductions in closed-loop cost by 17% and 4%\nrespectively compared against Gaussian process based MPC.",
      "published": "February 08, 2025",
      "categories": [
        "eess.SY",
        "cs.SY",
        "math.OC"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.05448v1",
      "arxiv_url": "http://arxiv.org/abs/2502.05448v1"
    },
    {
      "title": "Evaluating Standard and Dialectal Frisian ASR: Multilingual Fine-tuning\n  and Language Identification for Improved Low-resource Performance",
      "authors": [
        "Reihaneh Amooie",
        "Wietse de Vries",
        "Yun Hao",
        "Jelske Dijkstra",
        "Matt Coler",
        "Martijn Wieling"
      ],
      "abstract": "Automatic Speech Recognition (ASR) performance for low-resource languages is\nstill far behind that of higher-resource languages such as English, due to a\nlack of sufficient labeled data. State-of-the-art methods deploy\nself-supervised transfer learning where a model pre-trained on large amounts of\ndata is fine-tuned using little labeled data in a target low-resource language.\nIn this paper, we present and examine a method for fine-tuning an SSL-based\nmodel in order to improve the performance for Frisian and its regional dialects\n(Clay Frisian, Wood Frisian, and South Frisian). We show that Frisian ASR\nperformance can be improved by using multilingual (Frisian, Dutch, English and\nGerman) fine-tuning data and an auxiliary language identification task. In\naddition, our findings show that performance on dialectal speech suffers\nsubstantially, and, importantly, that this effect is moderated by the\nelicitation approach used to collect the dialectal data. Our findings also\nparticularly suggest that relying solely on standard language data for ASR\nevaluation may underestimate real-world performance, particularly in languages\nwith substantial dialectal variation.",
      "published": "February 07, 2025",
      "categories": [
        "cs.CL",
        "cs.LG",
        "cs.SD",
        "eess.AS"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.04883v1",
      "arxiv_url": "http://arxiv.org/abs/2502.04883v1"
    },
    {
      "title": "Self-Supervised Learning for Pre-training Capsule Networks: Overcoming\n  Medical Imaging Dataset Challenges",
      "authors": [
        "Heba El-Shimy",
        "Hind Zantout",
        "Michael A. Lones",
        "Neamat El Gayar"
      ],
      "abstract": "Deep learning techniques are increasingly being adopted in diagnostic medical\nimaging. However, the limited availability of high-quality, large-scale medical\ndatasets presents a significant challenge, often necessitating the use of\ntransfer learning approaches. This study investigates self-supervised learning\nmethods for pre-training capsule networks in polyp diagnostics for colon\ncancer. We used the PICCOLO dataset, comprising 3,433 samples, which\nexemplifies typical challenges in medical datasets: small size, class\nimbalance, and distribution shifts between data splits. Capsule networks offer\ninherent interpretability due to their architecture and inter-layer information\nrouting mechanism. However, their limited native implementation in mainstream\ndeep learning frameworks and the lack of pre-trained versions pose a\nsignificant challenge. This is particularly true if aiming to train them on\nsmall medical datasets, where leveraging pre-trained weights as initial\nparameters would be beneficial. We explored two auxiliary self-supervised\nlearning tasks, colourisation and contrastive learning, for capsule network\npre-training. We compared self-supervised pre-trained models against\nalternative initialisation strategies. Our findings suggest that contrastive\nlearning and in-painting techniques are suitable auxiliary tasks for\nself-supervised learning in the medical domain. These techniques helped guide\nthe model to capture important visual features that are beneficial for the\ndownstream task of polyp classification, increasing its accuracy by 5.26%\ncompared to other weight initialisation methods.",
      "published": "February 07, 2025",
      "categories": [
        "cs.CV",
        "cs.LG"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.04748v1",
      "arxiv_url": "http://arxiv.org/abs/2502.04748v1"
    },
    {
      "title": "Transfer learning in Scalable Graph Neural Network for Improved Physical\n  Simulation",
      "authors": [
        "Siqi Shen",
        "Yu Liu",
        "Daniel Biggs",
        "Omar Hafez",
        "Jiandong Yu",
        "Wentao Zhang",
        "Bin Cui",
        "Jiulong Shan"
      ],
      "abstract": "In recent years, Graph Neural Network (GNN) based models have shown promising\nresults in simulating physics of complex systems. However, training dedicated\ngraph network based physics simulators can be costly, as most models are\nconfined to fully supervised training, which requires extensive data generated\nfrom traditional physics simulators. To date, how transfer learning could\nimprove the model performance and training efficiency has remained unexplored.\nIn this work, we introduce a pre-training and transfer learning paradigm for\ngraph network simulators. We propose the scalable graph U-net (SGUNET).\nIncorporating an innovative depth-first search (DFS) pooling, the SGUNET is\nadaptable to different mesh sizes and resolutions for various simulation tasks.\nTo enable the transfer learning between differently configured SGUNETs, we\npropose a set of mapping functions to align the parameters between the\npre-trained model and the target model. An extra normalization term is also\nadded into the loss to constrain the difference between the pre-trained weights\nand target model weights for better generalization performance. To pre-train\nour physics simulator we created a dataset which includes 20,000 physical\nsimulations of randomly selected 3D shapes from the open source A Big CAD (ABC)\ndataset. We show that our proposed transfer learning methods allow the model to\nperform even better when fine-tuned with small amounts of training data than\nwhen it is trained from scratch with full extensive dataset. On the 2D\nDeformable Plate benchmark dataset, our pre-trained model fine-tuned on 1/16 of\nthe training data achieved an 11.05\\% improvement in position RMSE compared to\nthe model trained from scratch.",
      "published": "February 07, 2025",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.06848v1",
      "arxiv_url": "http://arxiv.org/abs/2502.06848v1"
    },
    {
      "title": "Performance Evaluation of Image Enhancement Techniques on Transfer\n  Learning for Touchless Fingerprint Recognition",
      "authors": [
        "S Sreehari",
        "Dilavar P D",
        "S M Anzar",
        "Alavikunhu Panthakkan",
        "Saad Ali Amin"
      ],
      "abstract": "Fingerprint recognition remains one of the most reliable biometric\ntechnologies due to its high accuracy and uniqueness. Traditional systems rely\non contact-based scanners, which are prone to issues such as image degradation\nfrom surface contamination and inconsistent user interaction. To address these\nlimitations, contactless fingerprint recognition has emerged as a promising\nalternative, providing non-intrusive and hygienic authentication. This study\nevaluates the impact of image enhancement tech-niques on the performance of\npre-trained deep learning models using transfer learning for touchless\nfingerprint recognition. The IIT-Bombay Touchless and Touch-Based Fingerprint\nDatabase, containing data from 200 subjects, was employed to test the\nper-formance of deep learning architectures such as VGG-16, VGG-19,\nInception-V3, and ResNet-50. Experimental results reveal that transfer learning\nmethods with fingerprint image enhance-ment (indirect method) significantly\noutperform those without enhancement (direct method). Specifically, VGG-16\nachieved an accuracy of 98% in training and 93% in testing when using the\nenhanced images, demonstrating superior performance compared to the direct\nmethod.\n  This paper provides a detailed comparison of the effectiveness of image\nenhancement in improving the accuracy of transfer learning models for touchless\nfingerprint recognition, offering key insights for developing more efficient\nbiometric systems.",
      "published": "February 07, 2025",
      "categories": [
        "cs.CV",
        "cs.LG"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.04680v1",
      "arxiv_url": "http://arxiv.org/abs/2502.04680v1"
    },
    {
      "title": "Provable Sample-Efficient Transfer Learning Conditional Diffusion Models\n  via Representation Learning",
      "authors": [
        "Ziheng Cheng",
        "Tianyu Xie",
        "Shiyue Zhang",
        "Cheng Zhang"
      ],
      "abstract": "While conditional diffusion models have achieved remarkable success in\nvarious applications, they require abundant data to train from scratch, which\nis often infeasible in practice. To address this issue, transfer learning has\nemerged as an essential paradigm in small data regimes. Despite its empirical\nsuccess, the theoretical underpinnings of transfer learning conditional\ndiffusion models remain unexplored. In this paper, we take the first step\ntowards understanding the sample efficiency of transfer learning conditional\ndiffusion models through the lens of representation learning. Inspired by\npractical training procedures, we assume that there exists a low-dimensional\nrepresentation of conditions shared across all tasks. Our analysis shows that\nwith a well-learned representation from source tasks, the samplecomplexity of\ntarget tasks can be reduced substantially. In addition, we investigate the\npractical implications of our theoretical results in several real-world\napplications of conditional diffusion models. Numerical experiments are also\nconducted to verify our results.",
      "published": "February 06, 2025",
      "categories": [
        "cs.LG",
        "math.ST",
        "stat.ML",
        "stat.TH"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.04491v1",
      "arxiv_url": "http://arxiv.org/abs/2502.04491v1"
    },
    {
      "title": "Multi-fidelity emulator for large-scale 21 cm lightcone images: a\n  few-shot transfer learning approach with generative adversarial network",
      "authors": [
        "Kangning Diao",
        "Yi Mao"
      ],
      "abstract": "Emulators using machine learning techniques have emerged to efficiently\ngenerate mock data matching the large survey volume for upcoming experiments,\nas an alternative approach to large-scale numerical simulations. However,\nhigh-fidelity emulators have become computationally expensive as the simulation\nvolume grows to hundreds of megaparsecs. Here, we present a {\\it\nmulti-fidelity} emulation of large-scale 21~cm lightcone images from the epoch\nof reionization, which is realized by applying the {\\it few-shot transfer\nlearning} to training generative adversarial networks (GAN) from small-scale to\nlarge-scale simulations. Specifically, a GAN emulator is first trained with a\nhuge number of small-scale simulations, and then transfer-learned with only a\nlimited number of large-scale simulations, to emulate large-scale 21~cm\nlightcone images. We test the precision of our transfer-learned GAN emulator in\nterms of representative statistics including global 21~cm brightness\ntemperature history, 2D power spectrum, and scattering transform coefficients.\nWe demonstrate that the lightcone images generated by the transfer-learned GAN\nemulator can reach the percentage level precision in most cases on small\nscales, and the error on large scales only increases mildly to the level of a\nfew tens of per cent. Nevertheless, our multi-fidelity emulation technique\nsaves a significant portion of computational resources that are mostly consumed\nfor generating training samples for GAN. On estimate, the computational\nresource by training GAN completely with large-scale simulations would be one\nto two orders of magnitude larger than using our multi-fidelity technique. This\nimplies that our technique allows for emulating high-fidelity, traditionally\ncomputationally prohibitive, images in an economic manner.",
      "published": "February 06, 2025",
      "categories": [
        "astro-ph.IM",
        "astro-ph.CO"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.04246v1",
      "arxiv_url": "http://arxiv.org/abs/2502.04246v1"
    },
    {
      "title": "A Theoretical Framework for Data Efficient Multi-Source Transfer\n  Learning Based on Cram\u00e9r-Rao Bound",
      "authors": [
        "Qingyue Zhang",
        "Haohao Fu",
        "Guanbo Huang",
        "Yaoyuan Liang",
        "Chang Chu",
        "Tianren Peng",
        "Yanru Wu",
        "Qi Li",
        "Yang Li",
        "Shao-Lun Huang"
      ],
      "abstract": "Multi-source transfer learning provides an effective solution to data\nscarcity in real-world supervised learning scenarios by leveraging multiple\nsource tasks. In this field, existing works typically use all available samples\nfrom sources in training, which constrains their training efficiency and may\nlead to suboptimal results. To address this, we propose a theoretical framework\nthat answers the question: what is the optimal quantity of source samples\nneeded from each source task to jointly train the target model? Specifically,\nwe introduce a generalization error measure that aligns with cross-entropy\nloss, and minimize it based on the Cram\\'er-Rao Bound to determine the optimal\ntransfer quantity for each source task. Additionally, we develop an\narchitecture-agnostic and data-efficient algorithm OTQMS to implement our\ntheoretical results for training deep multi-source transfer learning models.\nExperimental studies on diverse architectures and two real-world benchmark\ndatasets show that our proposed algorithm significantly outperforms\nstate-of-the-art approaches in both accuracy and data efficiency. The code and\nsupplementary materials are available in\nhttps://anonymous.4open.science/r/Materials.",
      "published": "February 06, 2025",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.04242v1",
      "arxiv_url": "http://arxiv.org/abs/2502.04242v1"
    },
    {
      "title": "Transfer Learning for Covert Speech Classification Using EEG Hilbert\n  Envelope and Temporal Fine Structure",
      "authors": [
        "Saravanakumar Duraisamy",
        "Mateusz Dubiel",
        "Maurice Rekrut",
        "Luis A. Leiva"
      ],
      "abstract": "Brain-Computer Interfaces (BCIs) can decode imagined speech from neural\nactivity. However, these systems typically require extensive training sessions\nwhere participants imaginedly repeat words, leading to mental fatigue and\ndifficulties identifying the onset of words, especially when imagining\nsequences of words. This paper addresses these challenges by transferring a\nclassifier trained in overt speech data to covert speech classification. We\nused electroencephalogram (EEG) features derived from the Hilbert envelope and\ntemporal fine structure, and used them to train a bidirectional long-short-term\nmemory (BiLSTM) model for classification. Our method reduces the burden of\nextensive training and achieves state-of-the-art classification accuracy:\n86.44% for overt speech and 79.82% for covert speech using the overt speech\nclassifier.",
      "published": "February 06, 2025",
      "categories": [
        "cs.LG"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.04132v1",
      "arxiv_url": "http://arxiv.org/abs/2502.04132v1"
    },
    {
      "title": "Generalize Drug Response Prediction by Latent Independent Projection for\n  Asymmetric Constrained Domain Generalization",
      "authors": [
        "Ran Song",
        "Yinpu Bai",
        "Hui Liu"
      ],
      "abstract": "The accurate prediction of drug responses remains a formidable challenge,\nparticularly at the single-cell level and in clinical treatment contexts. Some\nstudies employ transfer learning techniques to predict drug responses in\nindividual cells and patients, but they require access to target-domain data\nduring training, which is often unavailable or only obtainable in future. In\nthis study, we propose a novel domain generalization framework, termed\npanCancerDR, to address this challenge. We conceptualize each cancer type as a\ndistinct source domain, with its cell lines serving as domain-specific samples.\nOur primary objective is to extract domain-invariant features from the\nexpression profiles of cell lines across diverse cancer types, thereby\ngeneralize the predictive capacity to out-of-distribution samples. To enhance\nrobustness, we introduce a latent independence projection (LIP) module that\nencourages the encoder to extract informative yet non-redundant features. Also,\nwe propose an asymmetric adaptive clustering constraint, which clusters\ndrug-sensitive samples into a compact group while drives resistant samples\ndispersed across separate clusters in the latent space. Our empirical\nexperiments demonstrate that panCancerDR effectively learns task-relevant\nfeatures from diverse source domains, and achieves accurate predictions of drug\nresponse for unseen cancer type during training. Furthermore, when evaluated on\nsingle-cell and patient-level prediction tasks, our model-trained solely on in\nvitro cell line data without access to target-domain information-consistently\noutperforms and matched current state-of-the-art methods. These findings\nhighlights the potential of our method for real-world clinical applications.",
      "published": "February 06, 2025",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.04034v1",
      "arxiv_url": "http://arxiv.org/abs/2502.04034v1"
    },
    {
      "title": "ICGNN: Graph Neural Network Enabled Scalable Beamforming for MISO\n  Interference Channels",
      "authors": [
        "Changpeng He",
        "Yang Lu",
        "Bo Ai",
        "Octavia A. Dobre",
        "Zhiguo Ding",
        "Dusit Niyato"
      ],
      "abstract": "This paper investigates the graph neural network (GNN)-enabled beamforming\ndesign for interference channels. We propose a model termed interference\nchannel GNN (ICGNN) to solve a quality-of-service constrained energy efficiency\nmaximization problem. The ICGNN is two-stage, where the direction and power\nparts of beamforming vectors are learned separately but trained jointly via\nunsupervised learning. By formulating the dimensionality of features\nindependent of the transceiver pairs, the ICGNN is scalable with the number of\ntransceiver pairs. Besides, to improve the performance of the ICGNN, the hybrid\nmaximum ratio transmission and zero-forcing scheme reduces the output ports,\nthe feature enhancement module unifies the two types of links into one type,\nthe subgraph representation enhances the message passing efficiency, and the\nmulti-head attention and residual connection facilitate the feature extracting.\nFurthermore, we present the over-the-air distributed implementation of the\nICGNN. Ablation studies validate the effectiveness of key components in the\nICGNN. Numerical results also demonstrate the capability of ICGNN in achieving\nnear-optimal performance with an average inference time less than 0.1 ms. The\nscalability of ICGNN for unseen problem sizes is evaluated and enhanced by\ntransfer learning with limited fine-tuning cost. The results of the centralized\nand distributed implementations of ICGNN are illustrated.",
      "published": "February 06, 2025",
      "categories": [
        "eess.SP"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.03936v1",
      "arxiv_url": "http://arxiv.org/abs/2502.03936v1"
    },
    {
      "title": "SWIPTNet: A Unified Deep Learning Framework for SWIPT based on GNN and\n  Transfer Learning",
      "authors": [
        "Hong Han",
        "Yang Lu",
        "Zihan Song",
        "Ruichen Zhang",
        "Wei Chen",
        "Bo Ai",
        "Dusit Niyato",
        "Dong In Kim"
      ],
      "abstract": "This paper investigates the deep learning based approaches for simultaneous\nwireless information and power transfer (SWIPT). The quality-of-service (QoS)\nconstrained sum-rate maximization problems are, respectively, formulated for\npower-splitting (PS) receivers and time-switching (TS) receivers and solved by\na unified graph neural network (GNN) based model termed SWIPT net (SWIPTNet).\nTo improve the performance of SWIPTNet, we first propose a single-type output\nmethod to reduce the learning complexity and facilitate the satisfaction of QoS\nconstraints, and then, utilize the Laplace transform to enhance input features\nwith the structural information. Besides, we adopt the multi-head attention and\nlayer connection to enhance feature extracting. Furthermore, we present the\nimplementation of transfer learning to the SWIPTNet between PS and TS\nreceivers. Ablation studies show the effectiveness of key components in the\nSWIPTNet. Numerical results also demonstrate the capability of SWIPTNet in\nachieving near-optimal performance with millisecond-level inference speed which\nis much faster than the traditional optimization algorithms. We also show the\neffectiveness of transfer learning via fast convergence and expressive\ncapability improvement.",
      "published": "February 06, 2025",
      "categories": [
        "eess.SP"
      ],
      "pdf_link": "http://arxiv.org/pdf/2502.03928v1",
      "arxiv_url": "http://arxiv.org/abs/2502.03928v1"
    }
  ]
}