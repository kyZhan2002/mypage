{
  "timestamp": 1762738046,
  "papers": [
    {
      "title": "Where to Experiment? Site Selection Under Distribution Shift via Optimal\n  Transport and Wasserstein DRO",
      "authors": [
        "Adam Bouyamourn"
      ],
      "abstract": "How should researchers select experimental sites when the deployment\npopulation differs from observed data? I formulate the problem of experimental\nsite selection as an optimal transport problem, developing methods to minimize\ndownstream estimation error by choosing sites that minimize the Wasserstein\ndistance between population and sample covariate distributions. I develop new\ntheoretical upper bounds on PATE and CATE estimation errors, and show that\nthese different objectives lead to different site selection strategies. I\nextend this approach by using Wasserstein Distributionally Robust Optimization\nto develop a site selection procedure robust to adversarial perturbations of\ncovariate information: a specific model of distribution shift. I also propose a\nnovel data-driven procedure for selecting the uncertainty radius the\nWasserstein DRO problem, which allows the user to benchmark robustness levels\nagainst observed variation in their data. Simulation evidence, and a reanalysis\nof a randomized microcredit experiment in Morocco (Cr\\'epon et al.), show that\nthese methods outperform random and stratified sampling of sites when\ncovariates have prognostic R-squared > .5, and alternative optimization methods\ni) for moderate-to-large size problem instances ii) when covariates are\nmoderately informative about treatment effects, and iii) under induced\ndistribution shift.",
      "published": "November 06, 2025",
      "categories": [
        "stat.ME",
        "econ.EM"
      ],
      "pdf_link": "http://arxiv.org/pdf/2511.04658v1",
      "arxiv_url": "http://arxiv.org/abs/2511.04658v1"
    },
    {
      "title": "Distributionally Robust Synthetic Control: Ensuring Robustness Against\n  Highly Correlated Controls and Weight Shifts",
      "authors": [
        "Taehyeon Koo",
        "Zijian Guo"
      ],
      "abstract": "The synthetic control method estimates the causal effect by comparing the\noutcomes of a treated unit to a weighted average of control units that closely\nmatch the pre-treatment outcomes of the treated unit. This method presumes that\nthe relationship between the potential outcomes of the treated and control\nunits remains consistent before and after treatment. However, the estimator may\nbecome unreliable when these relationships shift or when control units are\nhighly correlated. To address these challenges, we introduce the\nDistributionally Robust Synthetic Control (DRoSC) method by accommodating\npotential shifts in relationships and addressing high correlations among\ncontrol units. The DRoSC method targets a new causal estimand defined as the\noptimizer of a worst-case optimization problem that checks through all possible\nsynthetic weights that comply with the pre-treatment period. When the\nidentification conditions for the classical synthetic control method hold, the\nDRoSC method targets the same causal effect as the synthetic control. When\nthese conditions are violated, we show that this new causal estimand is a\nconservative proxy of the non-identifiable causal effect. We further show that\nthe limiting distribution of the DRoSC estimator is non-normal and propose a\nnovel inferential approach to characterize this non-normal limiting\ndistribution. We demonstrate its finite-sample performance through numerical\nstudies and an analysis of the economic impact of terrorism in the Basque\nCountry.",
      "published": "November 04, 2025",
      "categories": [
        "stat.ME",
        "econ.EM"
      ],
      "pdf_link": "http://arxiv.org/pdf/2511.02632v1",
      "arxiv_url": "http://arxiv.org/abs/2511.02632v1"
    },
    {
      "title": "Few-Shot Multimodal Medical Imaging: A Theoretical Framework",
      "authors": [
        "Md Talha Mohsin",
        "Ismail Abdulrashid"
      ],
      "abstract": "Medical imaging relies heavily on large, labeled datasets. But,\nunfortunately, they are not always easily accessible in clinical settings.\nAdditionally, many practitioners often face various structural obstacles like\nlimited data availability, fragmented data systems, and unbalanced datasets.\nThese barriers often lead to the increased diagnostic uncertainty,\nunderrepresentation of certain conditions, reduced model robustness, and biased\ndiagnostic decisions. In response to these challenges, approaches such as\ntransfer learning, meta-learning, and multimodal fusion have made great\nstrides. However, they still need a solid theoretical justification for why\nthey succeed or fail in situations where data is scarce. To address this gap,\nwe propose a unified theoretical framework that characterizes learning and\ninference under low-resource medical imaging conditions. We first formalize the\nlearning objective under few-shot conditions and compute sample complexity\nconstraints to estimate the smallest quantity of data needed to achieve\nclinically reliable accuracy. Then based on ideas from PAC-learning and\nPAC-Bayesian theory, we explain how multimodal integration encourages\ngeneralization and quantifies uncertainty under sparse supervision. We further\npropose a formal metric for explanation stability, offering interpretability\nguarantees under low-data conditions. Taken together, the proposed framework\nestablishes a principled foundation for constructing dependable, data-efficient\ndiagnostic systems by jointly characterizing sample efficiency, uncertainty\nquantification, and interpretability in a unified theoretical setting.",
      "published": "November 03, 2025",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "eess.IV"
      ],
      "pdf_link": "http://arxiv.org/pdf/2511.01140v1",
      "arxiv_url": "http://arxiv.org/abs/2511.01140v1"
    },
    {
      "title": "Learning an Efficient Optimizer via Hybrid-Policy Sub-Trajectory Balance",
      "authors": [
        "Yunchuan Guan",
        "Yu Liu",
        "Ke Zhou",
        "Hui Li",
        "Sen Jia",
        "Zhiqi Shen",
        "Ziyang Wang",
        "Xinglin Zhang",
        "Tao Chen",
        "Jenq-Neng Hwang",
        "Lei Li"
      ],
      "abstract": "Recent advances in generative modeling enable neural networks to generate\nweights without relying on gradient-based optimization. However, current\nmethods are limited by issues of over-coupling and long-horizon. The former\ntightly binds weight generation with task-specific objectives, thereby limiting\nthe flexibility of the learned optimizer. The latter leads to inefficiency and\nlow accuracy during inference, caused by the lack of local constraints. In this\npaper, we propose Lo-Hp, a decoupled two-stage weight generation framework that\nenhances flexibility through learning various optimization policies. It adopts\na hybrid-policy sub-trajectory balance objective, which integrates on-policy\nand off-policy learning to capture local optimization policies. Theoretically,\nwe demonstrate that learning solely local optimization policies can address the\nlong-horizon issue while enhancing the generation of global optimal weights. In\naddition, we validate Lo-Hp's superior accuracy and inference efficiency in\ntasks that require frequent weight updates, such as transfer learning, few-shot\nlearning, domain generalization, and large language model adaptation.",
      "published": "November 01, 2025",
      "categories": [
        "cs.LG",
        "cs.CV",
        "stat.ML"
      ],
      "pdf_link": "http://arxiv.org/pdf/2511.00543v1",
      "arxiv_url": "http://arxiv.org/abs/2511.00543v1"
    }
  ]
}