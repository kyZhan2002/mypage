{
  "last_fetch_timestamp": 1771466680,
  "papers": [
    {
      "arxiv_id": "2602.08470",
      "title": "Learning Credal Ensembles via Distributionally Robust Optimization",
      "authors": [
        "Kaizheng Wang",
        "Ghifari Adam Faza",
        "Fabio Cuzzolin",
        "Siu Lun Chau",
        "David Moens",
        "Hans Hallez"
      ],
      "abstract": "Credal predictors are models that are aware of epistemic uncertainty and produce a convex set of probabilistic predictions. They offer a principled way to quantify predictive epistemic uncertainty (EU) and have been shown to improve model robustness in various settings. However, most state-of-the-art methods mainly define EU as disagreement caused by random training initializations, which mostly reflects sensitivity to optimization randomness rather than uncertainty from deeper sources. To address this, we define EU as disagreement among models trained with varying relaxations of the i.i.d. assumption between training and test data. Based on this idea, we propose CreDRO, which learns an ensemble of plausible models through distributionally robust optimization. As a result, CreDRO captures EU not only from training randomness but also from meaningful disagreement due to potential distribution shifts between training and test data. Empirical results show that CreDRO consistently outperforms existing credal methods on tasks such as out-of-distribution detection across multiple benchmarks and selective classification in medical applications.",
      "published": "February 09, 2026",
      "published_raw": "2026-02-09T10:16:43Z",
      "categories": [
        "cs.LG",
        "stat.ML"
      ],
      "pdf_link": "https://arxiv.org/pdf/2602.08470v1",
      "arxiv_url": "https://arxiv.org/abs/2602.08470v1",
      "added_timestamp": 1770775964
    },
    {
      "arxiv_id": "2602.01825",
      "title": "Learning Sequential Decisions from Multiple Sources via Group-Robust Markov Decision Processes",
      "authors": [
        "Mingyuan Xu",
        "Zongqi Xia",
        "Tianxi Cai",
        "Doudou Zhou",
        "Nian Si"
      ],
      "abstract": "We often collect data from multiple sites (e.g., hospitals) that share common structure but also exhibit heterogeneity. This paper aims to learn robust sequential decision-making policies from such offline, multi-site datasets. To model cross-site uncertainty, we study distributionally robust MDPs with a group-linear structure: all sites share a common feature map, and both the transition kernels and expected reward functions are linear in these shared features. We introduce feature-wise (d-rectangular) uncertainty sets, which preserve tractable robust Bellman recursions while maintaining key cross-site structure. Building on this, we then develop an offline algorithm based on pessimistic value iteration that includes: (i) per-site ridge regression for Bellman targets, (ii) feature-wise worst-case (row-wise minimization) aggregation, and (iii) a data-dependent pessimism penalty computed from the diagonals of the inverse design matrices. We further propose a cluster-level extension that pools similar sites to improve sample efficiency, guided by prior knowledge of site similarity. Under a robust partial coverage assumption, we prove a suboptimality bound for the resulting policy. Overall, our framework addresses multi-site learning with heterogeneous data sources and provides a principled approach to robust planning without relying on strong state-action rectangularity assumptions.",
      "published": "February 02, 2026",
      "published_raw": "2026-02-02T08:58:55Z",
      "categories": [
        "stat.ME",
        "cs.LG",
        "math.OC",
        "stat.ML"
      ],
      "pdf_link": "https://arxiv.org/pdf/2602.01825v1",
      "arxiv_url": "https://arxiv.org/abs/2602.01825v1",
      "added_timestamp": 1770170317
    },
    {
      "arxiv_id": "2602.01427",
      "title": "Robust Generalization with Adaptive Optimal Transport Priors for Decision-Focused Learning",
      "authors": [
        "Haixiang Sun",
        "Andrew L. Liu"
      ],
      "abstract": "Few-shot learning requires models to generalize under limited supervision while remaining robust to distribution shifts. Existing Sinkhorn Distributionally Robust Optimization (DRO) methods provide theoretical guarantees but rely on a fixed reference distribution, which limits their adaptability. We propose a Prototype-Guided Distributionally Robust Optimization (PG-DRO) framework that learns class-adaptive priors from abundant base data via hierarchical optimal transport and embeds them into the Sinkhorn DRO formulation. This design enables few-shot information to be organically integrated into producing class-specific robust decisions that are both theoretically grounded and efficient, and further aligns the uncertainty set with transferable structural knowledge. Experiments show that PG-DRO achieves stronger robust generalization in few-shot scenarios, outperforming both standard learners and DRO baselines.",
      "published": "February 01, 2026",
      "published_raw": "2026-02-01T20:22:41Z",
      "categories": [
        "stat.ML",
        "cs.LG",
        "stat.AP"
      ],
      "pdf_link": "https://arxiv.org/pdf/2602.01427v1",
      "arxiv_url": "https://arxiv.org/abs/2602.01427v1",
      "added_timestamp": 1770170317
    },
    {
      "arxiv_id": "2602.00844",
      "title": "Multivariate Time Series Data Imputation via Distributionally Robust Regularization",
      "authors": [
        "Che-Yi Liao",
        "Zheng Dong",
        "Gian-Gabriel Garcia",
        "Kamran Paynabar"
      ],
      "abstract": "Multivariate time series (MTS) imputation is often compromised by mismatch between observed and true data distributions -- a bias exacerbated by non-stationarity and systematic missingness. Standard methods that minimize reconstruction error or encourage distributional alignment risk overfitting these biased observations. We propose the Distributionally Robust Regularized Imputer Objective (DRIO), which jointly minimizes reconstruction error and the divergence between the imputer and a worst-case distribution within a Wasserstein ambiguity set. We derive a tractable dual formulation that reduces infinite-dimensional optimization over measures to adversarial search over sample trajectories, and propose an adversarial learning algorithm compatible with flexible deep learning backbones. Comprehensive experiments on diverse real-world datasets show DRIO consistently improves imputation under both missing-completely-at-random and missing-not-at-random settings, reaching Pareto-optimal trade-offs between reconstruction accuracy and distributional alignment.",
      "published": "January 31, 2026",
      "published_raw": "2026-01-31T18:15:03Z",
      "categories": [
        "stat.ML",
        "cs.LG",
        "stat.AP"
      ],
      "pdf_link": "https://arxiv.org/pdf/2602.00844v1",
      "arxiv_url": "https://arxiv.org/abs/2602.00844v1",
      "added_timestamp": 1770084228
    },
    {
      "arxiv_id": "2601.21324",
      "title": "Bulk-Calibrated Credal Ambiguity Sets: Fast, Tractable Decision Making under Out-of-Sample Contamination",
      "authors": [
        "Mengqi Chen",
        "Thomas B. Berrett",
        "Theodoros Damoulas",
        "Michele Caprio"
      ],
      "abstract": "Distributionally robust optimisation (DRO) minimises the worst-case expected loss over an ambiguity set that can capture distributional shifts in out-of-sample environments. While Huber (linear-vacuous) contamination is a classical minimal-assumption model for an $\\varepsilon$-fraction of arbitrary perturbations, including it in an ambiguity set can make the worst-case risk infinite and the DRO objective vacuous unless one imposes strong boundedness or support assumptions. We address these challenges by introducing bulk-calibrated credal ambiguity sets: we learn a high-mass bulk set from data while considering contamination inside the bulk and bounding the remaining tail contribution separately. This leads to a closed-form, finite $\\mathrm{mean}+\\sup$ robust objective and tractable linear or second-order cone programs for common losses and bulk geometries. Through this framework, we highlight and exploit the equivalence between the imprecise probability (IP) notion of upper expectation and the worst-case risk, demonstrating how IP credal sets translate into DRO objectives with interpretable tolerance levels. Experiments on heavy-tailed inventory control, geographically shifted house-price regression, and demographically shifted text classification show competitive robustness-accuracy trade-offs and efficient optimisation times, using Bayesian, frequentist, or empirical reference distributions.",
      "published": "January 29, 2026",
      "published_raw": "2026-01-29T06:37:36Z",
      "categories": [
        "stat.ML",
        "cs.LG"
      ],
      "pdf_link": "https://arxiv.org/pdf/2601.21324v1",
      "arxiv_url": "https://arxiv.org/abs/2601.21324v1",
      "added_timestamp": 1769824413
    }
  ]
}